{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2S10 TD3 v5 with 40x40 front and orientation from ac3_1M.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXu1r8qvSzWf",
        "colab_type": "text"
      },
      "source": [
        "# Twin-Delayed DDPG\n",
        "\n",
        "On a custom car env\n",
        "state: \n",
        "1. 40x40 cutout: 25 embeddings || car is at 1/2 ( grid embeddings)\n",
        "2. 25 cnn embeddings + 2 orientations + 2 angle of the car from X + diistance\n",
        "NOte: Embeddings are actually 9 rectangles\n",
        "Action space: 1 with range[-20,20]: action angle  + speed//2 to clip between [3,6]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "TODO: add Dabba delivery system in place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2-D5ZDv8cF7",
        "colab_type": "code",
        "outputId": "12cd1764-69d2-4904-ec6a-4387049ea618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "#env render is made using pygame\n",
        "!pip install pygame"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pygame\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/ede6428359f913ed9cd1643dd5533aefeb5a2699cc95bea089de50ead586/pygame-1.9.6-cp36-cp36m-manylinux1_x86_64.whl (11.4MB)\n",
            "\u001b[K     |████████████████████████████████| 11.4MB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3buLkkYSlj8z",
        "colab_type": "code",
        "outputId": "50050915-3f4d-413d-f5ba-4c1cf486695c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkrmeIqq2k6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjm2onHdT-Av",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ikr2p0Js8iB4",
        "colab_type": "code",
        "outputId": "8a7553ff-4ab3-4f11-a9b8-83131e840d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from collections import deque\n",
        "import math\n",
        "\n",
        "from PIL import Image as PILImage\n",
        "import gym\n",
        "from gym import wrappers\n",
        "# import gym_dabbewala\n",
        "\n",
        "import pygame\n",
        "\n",
        "import torch\n",
        "print(torch.__version__) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "1.5.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnCpTxXO9Nvu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the env file to path\n",
        "import os\n",
        "import sys\n",
        "env_dir ='/content/drive/My Drive/EVA2019/Phase2/Session10 EndGame/dabbewala_v3'\n",
        "sys.path.append(env_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2nGdtlKVydr",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: We initialize the Experience Replay memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5rW0IDB8nTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "\n",
        "  def __init__(self, max_size=1e5):\n",
        "    self.storage = []\n",
        "    self.max_size = max_size\n",
        "    self.ptr = 0\n",
        "\n",
        "  def add(self, transition):\n",
        "    if len(self.storage) == self.max_size:\n",
        "      self.storage[int(self.ptr)] = transition\n",
        "      self.ptr = (self.ptr + 1) % self.max_size\n",
        "    else:\n",
        "      self.storage.append(transition)\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
        "    batch_states1, batch_states2, batch_next_states1, batch_next_states2, batch_actions, batch_rewards, batch_dones = [], [], [], [], [], [], []\n",
        "    for i in ind: \n",
        "      state1, state2, next_state1, next_state2, action, reward, done = self.storage[i]\n",
        "      batch_states1.append(state1)\n",
        "      batch_states2.append(np.array(state2, copy=False))\n",
        "      batch_next_states1.append(next_state1)\n",
        "      batch_next_states2.append(np.array(next_state2, copy=False))\n",
        "      batch_actions.append(np.array(action, copy=False))\n",
        "      batch_rewards.append(np.array(reward, copy=False))\n",
        "      batch_dones.append(np.array(done, copy=False))\n",
        "    return np.array(batch_states1), np.array(batch_states2), np.array(batch_next_states1), np.array(batch_next_states2), np.array(batch_actions), np.array(batch_rewards).reshape(-1, 1), np.array(batch_dones).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb7TTaHxWbQD",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: We build one neural network for the Actor model and one neural network for the Actor target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRL4boKIGkwm",
        "colab_type": "code",
        "outputId": "0877ff55-a3d0-4c35-ea8e-f6fbe3d954a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def conv2d_size_out(size, kernel_size = 3, stride = 2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
        "conv2d_size_out(conv2d_size_out(conv2d_size_out(40), stride=1), stride=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEr8sOEXW4WS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AC_conv(nn.Module):\n",
        "  \n",
        "  def __init__(self, state_dim=1):\n",
        "    super(AC_conv, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(state_dim, 16, kernel_size=3, stride=2) #16\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1) #16\n",
        "    self.bn2 = nn.BatchNorm2d(16)\n",
        "    self.conv3 = nn.Conv2d(16, 9, kernel_size=3, stride=1) # 9 : 15x15\n",
        "    self.bn3 = nn.BatchNorm2d(9) # sq of an odd number, because just!\n",
        "    self.conv4 = nn.Conv2d(9, 1, kernel_size=1) # 1 : 15x15\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    x = F.relu(self.conv4(x)) # 1: 15x15\n",
        "    # print(x.shape)\n",
        "    return torch.nn.functional.avg_pool2d(x, kernel_size=3, stride = 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGgVyKD_Avmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Actor(AC_conv):\n",
        "  def __init__(self, state_dim, action_dim, max_action):\n",
        "    AC_conv.__init__(self)\n",
        "    super(Actor, self).__init__()\n",
        "    \n",
        "    linear_input_size = 25+5\n",
        "\n",
        "    self.layer_1 = nn.Linear(linear_input_size, 30)# if on road or sand\n",
        "    self.layer_2 = nn.Linear(30, 50)\n",
        "    self.layer_3 = nn.Linear(50, action_dim)\n",
        "\n",
        "    self.max_action = max_action\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    x1 = AC_conv.forward(self, x1)\n",
        "    \n",
        "    x = torch.cat(((x1.view(x1.size(0), -1)),\n",
        "                   x2),1)\n",
        "\n",
        "    x = F.relu(self.layer_1(x))\n",
        "    x = F.relu(self.layer_2(x))\n",
        "    return self.max_action * torch.tanh(self.layer_3(x))\n",
        "    # return self.layer_3(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRDDce8FXef7",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: We build two neural networks for the two Critic models and two neural networks for the two Critic targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yrERwbQzA2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(AC_conv):\n",
        "  \n",
        "  def __init__(self, state_dim, action_dim):\n",
        "    AC_conv.__init__(self)\n",
        "    super(Critic, self).__init__()\n",
        "    # Defining the first Critic neural network\n",
        "\n",
        "    linear_input_size = 25+5  # add state[\"orientation\"]\n",
        "\n",
        "    self.layer_1 = nn.Linear(linear_input_size + action_dim, 30)# if on road or sand\n",
        "    self.layer_2 = nn.Linear(30, 50)\n",
        "    self.layer_3 = nn.Linear(50, 1)\n",
        "\n",
        "    # Defining the second Critic neural network\n",
        "\n",
        "    self.layer_4 = nn.Linear(linear_input_size + action_dim, 30)# if on road or sand\n",
        "    self.layer_5 = nn.Linear(30, 50)\n",
        "    self.layer_6 = nn.Linear(50, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x1, x2, u):\n",
        "    # Forward-Propagation on the first Critic Neural Network\n",
        "    x1_1 = AC_conv.forward(self,x1)\n",
        "    \n",
        "    xu_1 = torch.cat(((x1_1.view(x1_1.size(0), -1)),\n",
        "                   x2, u),1)\n",
        "\n",
        "    x_1 = F.relu(self.layer_1(xu_1))\n",
        "    x_1 = F.relu(self.layer_2(x_1))\n",
        "    x_1 = self.layer_3(x_1)\n",
        "\n",
        "    # Forward-Propagation on the second Critic Neural Network\n",
        "    # x1_2 = self.mp2(x1)\n",
        "\n",
        "    x1_2 = AC_conv.forward(self,x1)\n",
        "\n",
        "\n",
        "    xu_2 = torch.cat(((x1_2.view(x1_1.size(0), -1)),\n",
        "                   x2, u),1)\n",
        "    \n",
        "    x_2 = F.relu(self.layer_4(xu_2))\n",
        "    x_2 = F.relu(self.layer_5(x_2))\n",
        "    x_2 = self.layer_6(x_2)\n",
        "    return x_1, x_2\n",
        "\n",
        "  def Q1(self, x1, x2, u):\n",
        "    x1_1 = AC_conv.forward(self,x1)\n",
        "    \n",
        "    xu_1 = torch.cat(((x1_1.view(x1_1.size(0), -1)),\n",
        "                   x2, u),1)\n",
        "\n",
        "    x_1 = F.relu(self.layer_1(xu_1))\n",
        "    x_1 = F.relu(self.layer_2(x_1))\n",
        "    x_1 = self.layer_3(x_1)\n",
        "    return x_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzIDuONodenW",
        "colab_type": "text"
      },
      "source": [
        "## Steps 4 to 15: Training Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zzd0H1xukdKe",
        "colab": {}
      },
      "source": [
        "# Selecting the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Building the whole Training Process into a class\n",
        "\n",
        "class TD3(object):\n",
        "  \n",
        "  def __init__(self, state_dim, action_dim, max_action):\n",
        "    self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
        "    self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
        "    self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "    \n",
        "    # for name, p in self.actor.named_parameters():\n",
        "    #   if \"layer\" not in name:\n",
        "    #     p.requires_grad = False\n",
        "    # self.actor_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.actor.parameters()), lr = 0.001245)\n",
        "    self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr = 0.0007)\n",
        "\n",
        "    self.critic = Critic(state_dim, action_dim).to(device)\n",
        "    self.critic_target = Critic(state_dim, action_dim).to(device)\n",
        "    self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "    # for name, p in self.critic.named_parameters():\n",
        "    #   if \"layer\" not in name:\n",
        "    #     p.requires_grad = False\n",
        "    # self.critic_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.critic.parameters()), lr = 0.001245)\n",
        "    self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr = 0.0007)\n",
        "    self.max_action = max_action\n",
        "\n",
        "  def select_action(self, state1, state2):\n",
        "    state1 = torch.from_numpy(state1).float().permute(2, 0, 1).unsqueeze(0).to(device)\n",
        "    state2 = torch.Tensor(state2).unsqueeze(0).to(device)\n",
        "    # print(f'shape of state1: {state1.shape}; state2{state2.shape}')\n",
        "    return self.actor(state1, state2).cpu().data.numpy().flatten()\n",
        "\n",
        "  def train(self, replay_buffer, iterations, batch_size=100, discount=0.99, tau=0.005, policy_noise=0.2, noise_clip=0.5, policy_freq=2):\n",
        "    \n",
        "    for it in range(iterations):\n",
        "      \n",
        "      # Step 4: We sample a batch of transitions (s, s’, a, r) from the memory\n",
        "      batch_states1, batch_states2, batch_next_states1, batch_next_states2, batch_actions, batch_rewards, batch_dones = replay_buffer.sample(batch_size)\n",
        "      state1 = torch.from_numpy(batch_states1).float().permute(0, 3, 1, 2).to(device)    \n",
        "      state2 = torch.Tensor(batch_states2).to(device)\n",
        "      next_state1 = torch.from_numpy(batch_next_states1).float().permute(0, 3, 1, 2).to(device)\n",
        "      next_state2 = torch.Tensor(batch_next_states2).to(device)\n",
        "      action = torch.Tensor(batch_actions).to(device)\n",
        "      reward = torch.Tensor(batch_rewards).to(device)\n",
        "      done = torch.Tensor(batch_dones).to(device)\n",
        "      \n",
        "      # Step 5: From the next state s’, the Actor target plays the next action a’\n",
        "      next_action = self.actor_target(next_state1, next_state2)\n",
        "            \n",
        "      # Step 6: We add Gaussian noise to this next action a’ and we clamp it in a range of values supported by the environment\n",
        "      noise = torch.Tensor(batch_actions).data.normal_(0, policy_noise).to(device)\n",
        "      noise = noise.clamp(-noise_clip, noise_clip)\n",
        "      next_action = (next_action + noise).clamp(-self.max_action, self.max_action)\n",
        "      next_action = next_action + noise\n",
        "      \n",
        "      # Step 7: The two Critic targets take each the couple (s’, a’) as input and return two Q-values Qt1(s’,a’) and Qt2(s’,a’) as outputs\n",
        "      target_Q1, target_Q2 = self.critic_target(next_state1, next_state2, next_action)\n",
        "      \n",
        "      # Step 8: We keep the minimum of these two Q-values: min(Qt1, Qt2)\n",
        "      target_Q = torch.min(target_Q1, target_Q2)\n",
        "      \n",
        "      # Step 9: We get the final target of the two Critic models, which is: Qt = r + γ * min(Qt1, Qt2), where γ is the discount factor\n",
        "      target_Q = reward + ((1 - done) * discount * target_Q).detach()\n",
        "      \n",
        "      # Step 10: The two Critic models take each the couple (s, a) as input and return two Q-values Q1(s,a) and Q2(s,a) as outputs\n",
        "      current_Q1, current_Q2 = self.critic(state1, state2, action)\n",
        "      \n",
        "      # Step 11: We compute the loss coming from the two Critic models: Critic Loss = MSE_Loss(Q1(s,a), Qt) + MSE_Loss(Q2(s,a), Qt)\n",
        "      critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
        "      \n",
        "      # Step 12: We backpropagate this Critic loss and update the parameters of the two Critic models with a SGD optimizer\n",
        "      self.critic_optimizer.zero_grad()\n",
        "      critic_loss.backward()\n",
        "      self.critic_optimizer.step()\n",
        "      \n",
        "      # Step 13: Once every two iterations, we update our Actor model by performing gradient ascent on the output of the first Critic model\n",
        "      if it % policy_freq == 0:\n",
        "        actor_loss = -self.critic.Q1(state1, state2, self.actor(state1, state2)).mean()\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "        \n",
        "        # Step 14: Still once every two iterations, we update the weights of the Actor target by polyak averaging\n",
        "        for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "        \n",
        "        # Step 15: Still once every two iterations, we update the weights of the Critic target by polyak averaging\n",
        "        for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "  \n",
        "  # Making a save method to save a trained model\n",
        "  def save(self, filename, directory):\n",
        "    torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
        "    torch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
        "  \n",
        "  # Making a load method to load a pre-trained model\n",
        "  def load(self, filename, directory):\n",
        "    self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
        "    self.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka-ZRtQvjBex",
        "colab_type": "text"
      },
      "source": [
        "## We make a function that evaluates the policy by calculating its average reward over 10 episodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qabqiYdp9wDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_policy(policy, eval_episodes=10):\n",
        "  avg_reward = 0.\n",
        "  for _ in range(eval_episodes):\n",
        "    obs = env.reset()\n",
        "    # print(f'pickup{env.x1, env.y1}; drop{env.x2,env.y2}')\n",
        "    done = False\n",
        "    while not done:\n",
        "      action = policy.select_action(obs['surround'],obs['orientation'])\n",
        "      obs, reward, done, _ = env.step(action)\n",
        "      avg_reward += reward\n",
        "  avg_reward /= eval_episodes\n",
        "  print (\"---------------------------------------\")\n",
        "  print (\"Average Reward over the Evaluation Step: %f\" % (avg_reward))\n",
        "  print (\"---------------------------------------\")\n",
        "  return avg_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGuKmH_ijf7U",
        "colab_type": "text"
      },
      "source": [
        "## We set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFj6wbAo97lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_name = \"DabbeWala-v0\" # Name of a environment (set it to any Continous environment you want)\n",
        "save_models = True # Boolean checker whether or not to save the pre-trained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjwf2HCol3XP",
        "colab_type": "text"
      },
      "source": [
        "## We create a file name for the two saved models: the Actor and Critic models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fyH8N5z-o3o",
        "colab_type": "code",
        "outputId": "d8db11e8-7760-458d-9273-a5a1b8ba3681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "file_name = \"%s_%s\" % (\"TD3\", env_name)\n",
        "print (\"---------------------------------------\")\n",
        "print (\"Settings: %s\" % (file_name))\n",
        "print (\"---------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------\n",
            "Settings: TD3_DabbeWala-v0\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kop-C96Aml8O",
        "colab_type": "text"
      },
      "source": [
        "## We create a folder inside which will be saved the trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Src07lvY-zXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = os.path.join(env_dir,\"pytorch_models\")\n",
        "\n",
        "if not os.path.exists(\"./results\"):\n",
        "  os.makedirs(\"./results\")\n",
        "if save_models and not os.path.exists(model_path):\n",
        "  os.makedirs(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEAzOd47mv1Z",
        "colab_type": "text"
      },
      "source": [
        "## We create the PyBullet environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXTAPorL4LI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym_dabbewala\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyQXJUIs-6BV",
        "colab_type": "code",
        "outputId": "49c20442-929a-413b-9447-5c7ea641ed99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "env = gym.make(env_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YdPG4HXnNsh",
        "colab_type": "text"
      },
      "source": [
        "## We set seeds and we get the necessary information on the states and actions in the chosen environment\n",
        "\n",
        "## maybe don't seed\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3RufYec_ADj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# torch.manual_seed(seed)\n",
        "# np.random.seed(seed)\n",
        "state_dim = env.observation_space[\"surround\"].shape[2]\n",
        "action_dim = env.action_space.shape[0]\n",
        "max_action = float(env.action_space.high[0])\n",
        "min_action = float(env.action_space.low[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCXKcR3ozW7u",
        "colab_type": "code",
        "outputId": "8509e682-db95-47c7-95d0-55808567ca87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "action_dim, max_action, min_action"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 20.0, -20.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAtYgZAu-5YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_dim1 = env.observation_space[\"surround\"].shape\n",
        "state_dim2 = env.observation_space[\"orientation\"].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBPXe-2cTQ-W",
        "colab_type": "code",
        "outputId": "b4ace2b6-6ee1-443b-b6f0-8f0d5523975d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "state_dim, state_dim1, state_dim2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, (40, 40, 1), ())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWEgDAQxnbem",
        "colab_type": "text"
      },
      "source": [
        "## We create the policy network (the Actor model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTVvG7F8_EWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "policy = TD3(state_dim, action_dim, max_action)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI60VN2Unklh",
        "colab_type": "text"
      },
      "source": [
        "## We create the Experience Replay memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd-ZsdXR_LgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay_buffer = ReplayBuffer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYOpCyiDnw7s",
        "colab_type": "text"
      },
      "source": [
        "## We define a list where all the evaluation results over 10 episodes are stored"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhC_5XJ__Orp",
        "colab_type": "code",
        "outputId": "3d079959-e28b-4d97-ce5c-e2e385fe707d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "evaluations = [evaluate_policy(policy)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1311.781000\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm-4b3p6rglE",
        "colab_type": "text"
      },
      "source": [
        "## We create a new folder directory in which the final results (videos of the agent) will be populated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTL9uMd0ru03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mkdir(base, name):\n",
        "    path = os.path.join(base, name)\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "    return path\n",
        "work_dir = mkdir('exp', 'brs')\n",
        "monitor_dir = mkdir(work_dir, 'monitor')\n",
        "max_episode_steps = env._max_episode_steps\n",
        "save_env_vid = False\n",
        "if save_env_vid:\n",
        "  env = wrappers.Monitor(env, monitor_dir, force = True)\n",
        "  env.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31n5eb03p-Fm",
        "colab_type": "text"
      },
      "source": [
        "## We initialize the variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vN5EvxK_QhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_timesteps = 0\n",
        "timesteps_since_eval = 0\n",
        "episode_num = 0\n",
        "done = True\n",
        "t0 = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijd3BnL15Rbm",
        "colab_type": "text"
      },
      "source": [
        "###  parameteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkObvKfQ5VpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed = 0 # Random seed number\n",
        "start_timesteps = 2e4 # Number of iterations/timesteps before which the model randomly chooses an action, and after which it starts to use the policy network\n",
        "eval_freq = 5e3 # How often the evaluation step is performed (after how many timesteps)\n",
        "max_timesteps = 1e6 # Total number of iterations/timesteps\n",
        "save_models = True # Boolean checker whether or not to save the pre-trained model\n",
        "expl_noise = 0.15 # Exploration noise - STD value of exploration Gaussian noise\n",
        "batch_size = 128 # Size of the batch\n",
        "discount = 0.99 # Discount factor gamma, used in the calculation of the total discounted reward\n",
        "tau = 0.005 # Target network update rate\n",
        "policy_noise = 0.25 # STD of Gaussian noise added to the actions for the exploration purposes\n",
        "noise_clip = 0.5 # Maximum value of the Gaussian noise added to the actions (policy)\n",
        "policy_freq = 2 # Number of iterations to wait before the policy network (Actor model) is updated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9gsjvtPqLgT",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_ouY4NH_Y0I",
        "colab_type": "code",
        "outputId": "b1e961b0-3fff-4563-cfd0-da0f67d13810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We start the main loop over 500,000 timesteps\n",
        "while total_timesteps < max_timesteps:\n",
        "  \n",
        "  # If the episode is done\n",
        "  if done:\n",
        "\n",
        "    # If we are not at the very beginning, we start the training process of the model\n",
        "    if total_timesteps != 0:\n",
        "      # if total_timesteps%100 == 0:\n",
        "      print(\"Timesteps: {} Ep_Number: {} Reward: {:.2f} Cocaine: {} Mild_Cocaine {} Sadness: {} Death: {}\".format(total_timesteps, episode_num, episode_reward, cocaine, mild_cocaine, sadness, death))\n",
        "      policy.train(replay_buffer, episode_timesteps, batch_size, discount, tau, policy_noise, noise_clip, policy_freq)\n",
        "\n",
        "    # We evaluate the episode and we save the policy\n",
        "    if timesteps_since_eval >= eval_freq:\n",
        "      timesteps_since_eval %= eval_freq\n",
        "      evaluations.append(evaluate_policy(policy))\n",
        "      policy.save(file_name, directory=model_path)\n",
        "      np.save(\"./results/%s\" % (file_name), evaluations)\n",
        "    \n",
        "    # When the training step is done, we reset the state of the environment\n",
        "    obs = env.reset()\n",
        "    \n",
        "    # Set the Done to False\n",
        "    done = False\n",
        "    \n",
        "    # Set rewards and episode timesteps to zero\n",
        "    episode_reward = 0\n",
        "    episode_timesteps = 0\n",
        "    episode_num += 1\n",
        "\n",
        "    #pos and neg reward counter\n",
        "    cocaine = 0\n",
        "    sadness = 0\n",
        "    mild_cocaine = 0\n",
        "    death = 0\n",
        "  \n",
        "  # Before 10000 timesteps, we play random actions\n",
        "  if total_timesteps < start_timesteps:\n",
        "    action = env.action_space.sample()\n",
        "  else: # After 10000 timesteps, we switch to the model\n",
        "    # action = policy.select_action(np.array(obs))\n",
        "    action = policy.select_action(obs['surround'], obs['orientation'])\n",
        "    \n",
        "    # If the explore_noise parameter is not 0, we add noise to the action and we clip it\n",
        "    if expl_noise != 0:\n",
        "      action = (action + np.random.normal(0, expl_noise, size=env.action_space.shape[0])).clip(env.action_space.low, env.action_space.high)\n",
        "  \n",
        "  # The agent performs the action in the environment, then reaches the next state and receives the reward\n",
        "  new_obs, reward, done, _ = env.step(action)\n",
        "  \n",
        "  # We check if the episode is done\n",
        "  done_bool = 0 if episode_timesteps + 1 == env._max_episode_steps else float(done)\n",
        "  \n",
        "  # We increase the total reward\n",
        "  episode_reward += reward\n",
        "  \n",
        "  # see pos and neg reward counts\n",
        "  if reward > 0.00:\n",
        "    cocaine += 1  \n",
        "  elif reward == -0.01:\n",
        "    mild_cocaine += 1\n",
        "  elif reward < -0.6:\n",
        "    death += 1 \n",
        "  else:\n",
        "    sadness += 1 \n",
        "  \n",
        "  # We store the new transition into the Experience Replay memory (ReplayBuffer)\n",
        "  replay_buffer.add((obs['surround'], obs['orientation'], new_obs['surround'], new_obs['orientation'], action, reward, done_bool))\n",
        "\n",
        "  # We update the state, the episode timestep, the total timesteps, and the timesteps since the evaluation of the policy\n",
        "  obs = new_obs\n",
        "  episode_timesteps += 1\n",
        "  total_timesteps += 1\n",
        "  timesteps_since_eval += 1\n",
        "\n",
        "# We add the last policy evaluation to our list of evaluations and we save our model\n",
        "evaluations.append(evaluate_policy(policy))\n",
        "if save_models: policy.save(\"%s\" % (file_name), directory=model_path)\n",
        "np.save(\"./results/%s\" % (file_name), evaluations)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timesteps: 1000 Ep_Number: 1 Reward: -1452.85 Cocaine: 0 Mild_Cocaine 25 Sadness: 11 Death: 964\n",
            "Timesteps: 2000 Ep_Number: 2 Reward: -1390.47 Cocaine: 0 Mild_Cocaine 27 Sadness: 77 Death: 896\n",
            "Timesteps: 3000 Ep_Number: 3 Reward: -1400.15 Cocaine: 0 Mild_Cocaine 35 Sadness: 53 Death: 912\n",
            "Timesteps: 4000 Ep_Number: 4 Reward: -1424.79 Cocaine: 0 Mild_Cocaine 39 Sadness: 19 Death: 942\n",
            "Timesteps: 5000 Ep_Number: 5 Reward: -1229.41 Cocaine: 0 Mild_Cocaine 91 Sadness: 150 Death: 759\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1353.266000\n",
            "---------------------------------------\n",
            "Timesteps: 6000 Ep_Number: 6 Reward: -1209.01 Cocaine: 0 Mild_Cocaine 121 Sadness: 123 Death: 756\n",
            "Timesteps: 7000 Ep_Number: 7 Reward: -1206.93 Cocaine: 0 Mild_Cocaine 123 Sadness: 122 Death: 755\n",
            "Timesteps: 8000 Ep_Number: 8 Reward: -1255.01 Cocaine: 0 Mild_Cocaine 101 Sadness: 105 Death: 794\n",
            "Timesteps: 9000 Ep_Number: 9 Reward: -1404.24 Cocaine: 0 Mild_Cocaine 54 Sadness: 17 Death: 929\n",
            "Timesteps: 10000 Ep_Number: 10 Reward: -1405.12 Cocaine: 0 Mild_Cocaine 22 Sadness: 69 Death: 909\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1119.728000\n",
            "---------------------------------------\n",
            "Timesteps: 11000 Ep_Number: 11 Reward: -1352.32 Cocaine: 0 Mild_Cocaine 52 Sadness: 78 Death: 870\n",
            "Timesteps: 12000 Ep_Number: 12 Reward: -1365.94 Cocaine: 0 Mild_Cocaine 64 Sadness: 43 Death: 893\n",
            "Timesteps: 13000 Ep_Number: 13 Reward: -1459.25 Cocaine: 0 Mild_Cocaine 5 Sadness: 37 Death: 958\n",
            "Timesteps: 14000 Ep_Number: 14 Reward: -1381.00 Cocaine: 0 Mild_Cocaine 40 Sadness: 66 Death: 894\n",
            "Timesteps: 15000 Ep_Number: 15 Reward: -1292.13 Cocaine: 0 Mild_Cocaine 93 Sadness: 77 Death: 830\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1202.474000\n",
            "---------------------------------------\n",
            "Timesteps: 16000 Ep_Number: 16 Reward: -1388.70 Cocaine: 0 Mild_Cocaine 30 Sadness: 74 Death: 896\n",
            "Timesteps: 17000 Ep_Number: 17 Reward: -1307.47 Cocaine: 0 Mild_Cocaine 67 Sadness: 103 Death: 830\n",
            "Timesteps: 18000 Ep_Number: 18 Reward: -1293.12 Cocaine: 0 Mild_Cocaine 102 Sadness: 61 Death: 837\n",
            "Timesteps: 19000 Ep_Number: 19 Reward: -1305.97 Cocaine: 0 Mild_Cocaine 97 Sadness: 55 Death: 848\n",
            "Timesteps: 20000 Ep_Number: 20 Reward: -1459.37 Cocaine: 0 Mild_Cocaine 17 Sadness: 17 Death: 966\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1230.347000\n",
            "---------------------------------------\n",
            "Timesteps: 21000 Ep_Number: 21 Reward: -1219.16 Cocaine: 0 Mild_Cocaine 116 Sadness: 120 Death: 764\n",
            "Timesteps: 22000 Ep_Number: 22 Reward: -1492.24 Cocaine: 0 Mild_Cocaine 4 Sadness: 2 Death: 994\n",
            "Timesteps: 23000 Ep_Number: 23 Reward: -1450.99 Cocaine: 0 Mild_Cocaine 19 Sadness: 23 Death: 958\n",
            "Timesteps: 24000 Ep_Number: 24 Reward: -619.96 Cocaine: 0 Mild_Cocaine 526 Sadness: 107 Death: 367\n",
            "Timesteps: 25000 Ep_Number: 25 Reward: -1051.10 Cocaine: 0 Mild_Cocaine 230 Sadness: 118 Death: 652\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -881.307000\n",
            "---------------------------------------\n",
            "Timesteps: 26000 Ep_Number: 26 Reward: -1491.65 Cocaine: 0 Mild_Cocaine 5 Sadness: 1 Death: 994\n",
            "Timesteps: 26550 Ep_Number: 27 Reward: -638.18 Cocaine: 1 Mild_Cocaine 88 Sadness: 58 Death: 403\n",
            "Timesteps: 27550 Ep_Number: 28 Reward: -1473.90 Cocaine: 0 Mild_Cocaine 0 Sadness: 29 Death: 971\n",
            "Timesteps: 28550 Ep_Number: 29 Reward: -888.87 Cocaine: 0 Mild_Cocaine 267 Sadness: 237 Death: 496\n",
            "Timesteps: 29550 Ep_Number: 30 Reward: -1481.22 Cocaine: 0 Mild_Cocaine 12 Sadness: 1 Death: 987\n",
            "Timesteps: 29672 Ep_Number: 31 Reward: -143.65 Cocaine: 1 Mild_Cocaine 15 Sadness: 15 Death: 91\n",
            "Timesteps: 30672 Ep_Number: 32 Reward: -1305.29 Cocaine: 0 Mild_Cocaine 89 Sadness: 69 Death: 842\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -977.753000\n",
            "---------------------------------------\n",
            "Timesteps: 31672 Ep_Number: 33 Reward: -1363.20 Cocaine: 0 Mild_Cocaine 0 Sadness: 152 Death: 848\n",
            "Timesteps: 32672 Ep_Number: 34 Reward: -1379.26 Cocaine: 0 Mild_Cocaine 46 Sadness: 58 Death: 896\n",
            "Timesteps: 33672 Ep_Number: 35 Reward: -1177.57 Cocaine: 0 Mild_Cocaine 127 Sadness: 148 Death: 725\n",
            "Timesteps: 34672 Ep_Number: 36 Reward: -1175.37 Cocaine: 0 Mild_Cocaine 27 Sadness: 316 Death: 657\n",
            "Timesteps: 35672 Ep_Number: 37 Reward: -1468.09 Cocaine: 0 Mild_Cocaine 19 Sadness: 4 Death: 977\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1067.018000\n",
            "---------------------------------------\n",
            "Timesteps: 36672 Ep_Number: 38 Reward: -1410.17 Cocaine: 0 Mild_Cocaine 47 Sadness: 22 Death: 931\n",
            "Timesteps: 37672 Ep_Number: 39 Reward: -1250.10 Cocaine: 0 Mild_Cocaine 120 Sadness: 79 Death: 801\n",
            "Timesteps: 38672 Ep_Number: 40 Reward: -1325.84 Cocaine: 0 Mild_Cocaine 74 Sadness: 71 Death: 855\n",
            "Timesteps: 39672 Ep_Number: 41 Reward: -1282.71 Cocaine: 0 Mild_Cocaine 141 Sadness: 8 Death: 851\n",
            "Timesteps: 40672 Ep_Number: 42 Reward: -1432.24 Cocaine: 0 Mild_Cocaine 34 Sadness: 19 Death: 947\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -993.778000\n",
            "---------------------------------------\n",
            "Timesteps: 41672 Ep_Number: 43 Reward: -1156.52 Cocaine: 0 Mild_Cocaine 152 Sadness: 130 Death: 718\n",
            "Timesteps: 42672 Ep_Number: 44 Reward: -450.85 Cocaine: 0 Mild_Cocaine 445 Sadness: 429 Death: 126\n",
            "Timesteps: 43672 Ep_Number: 45 Reward: -981.68 Cocaine: 0 Mild_Cocaine 308 Sadness: 66 Death: 626\n",
            "Timesteps: 44672 Ep_Number: 46 Reward: -1500.00 Cocaine: 0 Mild_Cocaine 0 Sadness: 0 Death: 1000\n",
            "Timesteps: 45672 Ep_Number: 47 Reward: -1351.94 Cocaine: 0 Mild_Cocaine 74 Sadness: 42 Death: 884\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1090.726000\n",
            "---------------------------------------\n",
            "Timesteps: 46672 Ep_Number: 48 Reward: -1483.86 Cocaine: 0 Mild_Cocaine 6 Sadness: 8 Death: 986\n",
            "Timesteps: 47672 Ep_Number: 49 Reward: -1058.63 Cocaine: 0 Mild_Cocaine 83 Sadness: 353 Death: 564\n",
            "Timesteps: 48672 Ep_Number: 50 Reward: -1477.34 Cocaine: 0 Mild_Cocaine 14 Sadness: 2 Death: 984\n",
            "Timesteps: 49672 Ep_Number: 51 Reward: -1480.88 Cocaine: 0 Mild_Cocaine 8 Sadness: 8 Death: 984\n",
            "Timesteps: 50672 Ep_Number: 52 Reward: -1120.76 Cocaine: 0 Mild_Cocaine 176 Sadness: 130 Death: 694\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1094.296000\n",
            "---------------------------------------\n",
            "Timesteps: 51672 Ep_Number: 53 Reward: -817.89 Cocaine: 0 Mild_Cocaine 189 Sadness: 445 Death: 366\n",
            "Timesteps: 52672 Ep_Number: 54 Reward: -570.25 Cocaine: 0 Mild_Cocaine 415 Sadness: 346 Death: 239\n",
            "Timesteps: 53672 Ep_Number: 55 Reward: -1248.02 Cocaine: 0 Mild_Cocaine 122 Sadness: 78 Death: 800\n",
            "Timesteps: 54672 Ep_Number: 56 Reward: -765.30 Cocaine: 0 Mild_Cocaine 240 Sadness: 419 Death: 341\n",
            "Timesteps: 55672 Ep_Number: 57 Reward: -986.73 Cocaine: 0 Mild_Cocaine 243 Sadness: 168 Death: 589\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -945.344000\n",
            "---------------------------------------\n",
            "Timesteps: 56672 Ep_Number: 58 Reward: -1497.30 Cocaine: 0 Mild_Cocaine 0 Sadness: 3 Death: 997\n",
            "Timesteps: 57672 Ep_Number: 59 Reward: -1482.06 Cocaine: 0 Mild_Cocaine 6 Sadness: 10 Death: 984\n",
            "Timesteps: 58672 Ep_Number: 60 Reward: -1171.83 Cocaine: 0 Mild_Cocaine 213 Sadness: 12 Death: 775\n",
            "Timesteps: 59672 Ep_Number: 61 Reward: -1379.11 Cocaine: 0 Mild_Cocaine 31 Sadness: 83 Death: 886\n",
            "Timesteps: 60672 Ep_Number: 62 Reward: -677.98 Cocaine: 0 Mild_Cocaine 388 Sadness: 271 Death: 341\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1149.421000\n",
            "---------------------------------------\n",
            "Timesteps: 61672 Ep_Number: 63 Reward: -1357.43 Cocaine: 0 Mild_Cocaine 83 Sadness: 21 Death: 896\n",
            "Timesteps: 62672 Ep_Number: 64 Reward: -1485.63 Cocaine: 0 Mild_Cocaine 3 Sadness: 11 Death: 986\n",
            "Timesteps: 63672 Ep_Number: 65 Reward: -622.01 Cocaine: 0 Mild_Cocaine 431 Sadness: 262 Death: 307\n",
            "Timesteps: 64672 Ep_Number: 66 Reward: -1470.70 Cocaine: 0 Mild_Cocaine 10 Sadness: 16 Death: 974\n",
            "Timesteps: 65672 Ep_Number: 67 Reward: -914.55 Cocaine: 0 Mild_Cocaine 225 Sadness: 278 Death: 497\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1074.795000\n",
            "---------------------------------------\n",
            "Timesteps: 66672 Ep_Number: 68 Reward: -1135.56 Cocaine: 0 Mild_Cocaine 96 Sadness: 246 Death: 658\n",
            "Timesteps: 67672 Ep_Number: 69 Reward: -691.50 Cocaine: 0 Mild_Cocaine 330 Sadness: 352 Death: 318\n",
            "Timesteps: 68672 Ep_Number: 70 Reward: -1399.49 Cocaine: 0 Mild_Cocaine 59 Sadness: 14 Death: 927\n",
            "Timesteps: 69672 Ep_Number: 71 Reward: -794.42 Cocaine: 0 Mild_Cocaine 392 Sadness: 135 Death: 473\n",
            "Timesteps: 70672 Ep_Number: 72 Reward: -963.69 Cocaine: 0 Mild_Cocaine 99 Sadness: 432 Death: 469\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1035.088000\n",
            "---------------------------------------\n",
            "Timesteps: 71672 Ep_Number: 73 Reward: -721.88 Cocaine: 0 Mild_Cocaine 338 Sadness: 305 Death: 357\n",
            "Timesteps: 72672 Ep_Number: 74 Reward: -636.40 Cocaine: 0 Mild_Cocaine 370 Sadness: 347 Death: 283\n",
            "Timesteps: 73672 Ep_Number: 75 Reward: -1159.01 Cocaine: 0 Mild_Cocaine 131 Sadness: 162 Death: 707\n",
            "Timesteps: 74672 Ep_Number: 76 Reward: -1080.84 Cocaine: 0 Mild_Cocaine 204 Sadness: 128 Death: 668\n",
            "Timesteps: 75672 Ep_Number: 77 Reward: -918.69 Cocaine: 0 Mild_Cocaine 279 Sadness: 184 Death: 537\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -868.582000\n",
            "---------------------------------------\n",
            "Timesteps: 76672 Ep_Number: 78 Reward: -732.04 Cocaine: 0 Mild_Cocaine 304 Sadness: 350 Death: 346\n",
            "Timesteps: 77672 Ep_Number: 79 Reward: -1495.50 Cocaine: 0 Mild_Cocaine 0 Sadness: 5 Death: 995\n",
            "Timesteps: 78672 Ep_Number: 80 Reward: -757.01 Cocaine: 0 Mild_Cocaine 341 Sadness: 261 Death: 398\n",
            "Timesteps: 79672 Ep_Number: 81 Reward: -1241.44 Cocaine: 0 Mild_Cocaine 124 Sadness: 82 Death: 794\n",
            "Timesteps: 80672 Ep_Number: 82 Reward: -722.03 Cocaine: 0 Mild_Cocaine 353 Sadness: 280 Death: 367\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1074.804000\n",
            "---------------------------------------\n",
            "Timesteps: 81672 Ep_Number: 83 Reward: -1176.30 Cocaine: 0 Mild_Cocaine 210 Sadness: 12 Death: 778\n",
            "Timesteps: 82672 Ep_Number: 84 Reward: -1355.38 Cocaine: 0 Mild_Cocaine 88 Sadness: 15 Death: 897\n",
            "Timesteps: 83672 Ep_Number: 85 Reward: -1143.07 Cocaine: 0 Mild_Cocaine 187 Sadness: 87 Death: 726\n",
            "Timesteps: 84672 Ep_Number: 86 Reward: -714.30 Cocaine: 0 Mild_Cocaine 270 Sadness: 426 Death: 304\n",
            "Timesteps: 85672 Ep_Number: 87 Reward: -1229.77 Cocaine: 0 Mild_Cocaine 127 Sadness: 90 Death: 783\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -1137.207000\n",
            "---------------------------------------\n",
            "Timesteps: 86672 Ep_Number: 88 Reward: -735.10 Cocaine: 0 Mild_Cocaine 340 Sadness: 287 Death: 373\n",
            "Timesteps: 87672 Ep_Number: 89 Reward: -777.70 Cocaine: 0 Mild_Cocaine 280 Sadness: 339 Death: 381\n",
            "Timesteps: 88672 Ep_Number: 90 Reward: -721.14 Cocaine: 0 Mild_Cocaine 324 Sadness: 329 Death: 347\n",
            "Timesteps: 89672 Ep_Number: 91 Reward: -896.63 Cocaine: 0 Mild_Cocaine 263 Sadness: 235 Death: 502\n",
            "Timesteps: 90672 Ep_Number: 92 Reward: -790.31 Cocaine: 0 Mild_Cocaine 251 Sadness: 373 Death: 376\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -715.228000\n",
            "---------------------------------------\n",
            "Timesteps: 91672 Ep_Number: 93 Reward: -1156.64 Cocaine: 0 Mild_Cocaine 164 Sadness: 110 Death: 726\n",
            "Timesteps: 92672 Ep_Number: 94 Reward: -1194.65 Cocaine: 0 Mild_Cocaine 185 Sadness: 33 Death: 782\n",
            "Timesteps: 93672 Ep_Number: 95 Reward: -662.47 Cocaine: 0 Mild_Cocaine 277 Sadness: 472 Death: 251\n",
            "Timesteps: 94672 Ep_Number: 96 Reward: -676.91 Cocaine: 0 Mild_Cocaine 341 Sadness: 350 Death: 309\n",
            "Timesteps: 95672 Ep_Number: 97 Reward: -752.77 Cocaine: 0 Mild_Cocaine 217 Sadness: 471 Death: 312\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -945.681000\n",
            "---------------------------------------\n",
            "Timesteps: 96672 Ep_Number: 98 Reward: -754.44 Cocaine: 0 Mild_Cocaine 234 Sadness: 441 Death: 325\n",
            "Timesteps: 97672 Ep_Number: 99 Reward: -836.11 Cocaine: 0 Mild_Cocaine 271 Sadness: 289 Death: 440\n",
            "Timesteps: 98672 Ep_Number: 100 Reward: -684.05 Cocaine: 0 Mild_Cocaine 245 Sadness: 501 Death: 254\n",
            "Timesteps: 99672 Ep_Number: 101 Reward: -1489.82 Cocaine: 0 Mild_Cocaine 2 Sadness: 8 Death: 990\n",
            "Timesteps: 100672 Ep_Number: 102 Reward: -529.86 Cocaine: 0 Mild_Cocaine 276 Sadness: 621 Death: 103\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -748.880000\n",
            "---------------------------------------\n",
            "Timesteps: 101672 Ep_Number: 103 Reward: -1466.57 Cocaine: 0 Mild_Cocaine 17 Sadness: 9 Death: 974\n",
            "Timesteps: 102672 Ep_Number: 104 Reward: -1482.34 Cocaine: 0 Mild_Cocaine 4 Sadness: 13 Death: 983\n",
            "Timesteps: 103672 Ep_Number: 105 Reward: -511.67 Cocaine: 0 Mild_Cocaine 377 Sadness: 474 Death: 149\n",
            "Timesteps: 104672 Ep_Number: 106 Reward: -1448.88 Cocaine: 0 Mild_Cocaine 18 Sadness: 27 Death: 955\n",
            "Timesteps: 105672 Ep_Number: 107 Reward: -568.42 Cocaine: 0 Mild_Cocaine 322 Sadness: 502 Death: 176\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -943.429000\n",
            "---------------------------------------\n",
            "Timesteps: 106672 Ep_Number: 108 Reward: -671.85 Cocaine: 0 Mild_Cocaine 345 Sadness: 349 Death: 306\n",
            "Timesteps: 107672 Ep_Number: 109 Reward: -549.18 Cocaine: 0 Mild_Cocaine 318 Sadness: 530 Death: 152\n",
            "Timesteps: 108672 Ep_Number: 110 Reward: -569.26 Cocaine: 0 Mild_Cocaine 316 Sadness: 511 Death: 173\n",
            "Timesteps: 109672 Ep_Number: 111 Reward: -641.36 Cocaine: 0 Mild_Cocaine 296 Sadness: 464 Death: 240\n",
            "Timesteps: 110672 Ep_Number: 112 Reward: -423.95 Cocaine: 0 Mild_Cocaine 335 Sadness: 641 Death: 24\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -763.854000\n",
            "---------------------------------------\n",
            "Timesteps: 111672 Ep_Number: 113 Reward: -770.06 Cocaine: 0 Mild_Cocaine 206 Sadness: 470 Death: 324\n",
            "Timesteps: 112672 Ep_Number: 114 Reward: -464.74 Cocaine: 0 Mild_Cocaine 484 Sadness: 349 Death: 167\n",
            "Timesteps: 112846 Ep_Number: 115 Reward: -61.69 Cocaine: 1 Mild_Cocaine 129 Sadness: 4 Death: 40\n",
            "Timesteps: 113846 Ep_Number: 116 Reward: -714.31 Cocaine: 0 Mild_Cocaine 241 Sadness: 474 Death: 285\n",
            "Timesteps: 114846 Ep_Number: 117 Reward: -777.44 Cocaine: 0 Mild_Cocaine 224 Sadness: 432 Death: 344\n",
            "Timesteps: 115846 Ep_Number: 118 Reward: -1496.40 Cocaine: 0 Mild_Cocaine 0 Sadness: 4 Death: 996\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -733.432000\n",
            "---------------------------------------\n",
            "Timesteps: 116846 Ep_Number: 119 Reward: -830.86 Cocaine: 0 Mild_Cocaine 196 Sadness: 419 Death: 385\n",
            "Timesteps: 117846 Ep_Number: 120 Reward: -668.87 Cocaine: 0 Mild_Cocaine 257 Sadness: 498 Death: 245\n",
            "Timesteps: 118846 Ep_Number: 121 Reward: -623.53 Cocaine: 0 Mild_Cocaine 343 Sadness: 406 Death: 251\n",
            "Timesteps: 119846 Ep_Number: 122 Reward: -1146.51 Cocaine: 0 Mild_Cocaine 201 Sadness: 60 Death: 739\n",
            "Timesteps: 120846 Ep_Number: 123 Reward: -625.95 Cocaine: 0 Mild_Cocaine 345 Sadness: 400 Death: 255\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -847.865000\n",
            "---------------------------------------\n",
            "Timesteps: 121846 Ep_Number: 124 Reward: -1113.69 Cocaine: 0 Mild_Cocaine 159 Sadness: 166 Death: 675\n",
            "Timesteps: 122846 Ep_Number: 125 Reward: -790.30 Cocaine: 0 Mild_Cocaine 190 Sadness: 474 Death: 336\n",
            "Timesteps: 123846 Ep_Number: 126 Reward: -730.32 Cocaine: 0 Mild_Cocaine 252 Sadness: 438 Death: 310\n",
            "Timesteps: 124846 Ep_Number: 127 Reward: -607.87 Cocaine: 0 Mild_Cocaine 217 Sadness: 632 Death: 151\n",
            "Timesteps: 125846 Ep_Number: 128 Reward: -710.54 Cocaine: 0 Mild_Cocaine 374 Sadness: 258 Death: 368\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -776.044000\n",
            "---------------------------------------\n",
            "Timesteps: 126846 Ep_Number: 129 Reward: -1161.64 Cocaine: 0 Mild_Cocaine 154 Sadness: 121 Death: 725\n",
            "Timesteps: 127846 Ep_Number: 130 Reward: -537.59 Cocaine: 0 Mild_Cocaine 359 Sadness: 475 Death: 166\n",
            "Timesteps: 128846 Ep_Number: 131 Reward: -774.12 Cocaine: 0 Mild_Cocaine 222 Sadness: 439 Death: 339\n",
            "Timesteps: 129846 Ep_Number: 132 Reward: -517.51 Cocaine: 0 Mild_Cocaine 361 Sadness: 494 Death: 145\n",
            "Timesteps: 130846 Ep_Number: 133 Reward: -366.30 Cocaine: 0 Mild_Cocaine 570 Sadness: 316 Death: 114\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -623.749000\n",
            "---------------------------------------\n",
            "Timesteps: 131846 Ep_Number: 134 Reward: -717.14 Cocaine: 0 Mild_Cocaine 224 Sadness: 499 Death: 277\n",
            "Timesteps: 132846 Ep_Number: 135 Reward: -524.99 Cocaine: 0 Mild_Cocaine 359 Sadness: 489 Death: 152\n",
            "Timesteps: 133846 Ep_Number: 136 Reward: -1333.16 Cocaine: 0 Mild_Cocaine 86 Sadness: 43 Death: 871\n",
            "Timesteps: 134846 Ep_Number: 137 Reward: -806.00 Cocaine: 0 Mild_Cocaine 200 Sadness: 440 Death: 360\n",
            "Timesteps: 135846 Ep_Number: 138 Reward: -789.02 Cocaine: 0 Mild_Cocaine 212 Sadness: 439 Death: 349\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -735.777000\n",
            "---------------------------------------\n",
            "Timesteps: 136846 Ep_Number: 139 Reward: -484.10 Cocaine: 0 Mild_Cocaine 410 Sadness: 450 Death: 140\n",
            "Timesteps: 137846 Ep_Number: 140 Reward: -611.77 Cocaine: 0 Mild_Cocaine 247 Sadness: 578 Death: 175\n",
            "Timesteps: 138846 Ep_Number: 141 Reward: -1366.06 Cocaine: 0 Mild_Cocaine 76 Sadness: 23 Death: 901\n",
            "Timesteps: 139846 Ep_Number: 142 Reward: -1436.00 Cocaine: 0 Mild_Cocaine 20 Sadness: 38 Death: 942\n",
            "Timesteps: 140846 Ep_Number: 143 Reward: -1273.16 Cocaine: 0 Mild_Cocaine 116 Sadness: 60 Death: 824\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -760.957000\n",
            "---------------------------------------\n",
            "Timesteps: 141846 Ep_Number: 144 Reward: -1243.01 Cocaine: 0 Mild_Cocaine 161 Sadness: 19 Death: 820\n",
            "Timesteps: 142846 Ep_Number: 145 Reward: -983.46 Cocaine: 0 Mild_Cocaine 276 Sadness: 117 Death: 607\n",
            "Timesteps: 143846 Ep_Number: 146 Reward: -1089.28 Cocaine: 0 Mild_Cocaine 208 Sadness: 112 Death: 680\n",
            "Timesteps: 144846 Ep_Number: 147 Reward: -736.12 Cocaine: 0 Mild_Cocaine 442 Sadness: 117 Death: 441\n",
            "Timesteps: 145846 Ep_Number: 148 Reward: -616.19 Cocaine: 0 Mild_Cocaine 389 Sadness: 338 Death: 273\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -713.781000\n",
            "---------------------------------------\n",
            "Timesteps: 146846 Ep_Number: 149 Reward: -807.62 Cocaine: 0 Mild_Cocaine 272 Sadness: 319 Death: 409\n",
            "Timesteps: 147846 Ep_Number: 150 Reward: -455.96 Cocaine: 0 Mild_Cocaine 566 Sadness: 223 Death: 211\n",
            "Timesteps: 148846 Ep_Number: 151 Reward: -914.53 Cocaine: 0 Mild_Cocaine 373 Sadness: 33 Death: 594\n",
            "Timesteps: 149846 Ep_Number: 152 Reward: -594.95 Cocaine: 0 Mild_Cocaine 245 Sadness: 600 Death: 155\n",
            "Timesteps: 150846 Ep_Number: 153 Reward: -561.24 Cocaine: 0 Mild_Cocaine 444 Sadness: 308 Death: 248\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -645.169000\n",
            "---------------------------------------\n",
            "Timesteps: 151846 Ep_Number: 154 Reward: -1154.00 Cocaine: 0 Mild_Cocaine 170 Sadness: 103 Death: 727\n",
            "Timesteps: 152846 Ep_Number: 155 Reward: -485.79 Cocaine: 0 Mild_Cocaine 369 Sadness: 516 Death: 115\n",
            "Timesteps: 153846 Ep_Number: 156 Reward: -328.30 Cocaine: 0 Mild_Cocaine 520 Sadness: 441 Death: 39\n",
            "Timesteps: 154846 Ep_Number: 157 Reward: -372.22 Cocaine: 0 Mild_Cocaine 502 Sadness: 422 Death: 76\n",
            "Timesteps: 155846 Ep_Number: 158 Reward: -569.88 Cocaine: 0 Mild_Cocaine 408 Sadness: 358 Death: 234\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -530.265000\n",
            "---------------------------------------\n",
            "Timesteps: 156846 Ep_Number: 159 Reward: -1320.38 Cocaine: 0 Mild_Cocaine 68 Sadness: 87 Death: 845\n",
            "Timesteps: 157809 Ep_Number: 160 Reward: -332.21 Cocaine: 1 Mild_Cocaine 601 Sadness: 237 Death: 124\n",
            "Timesteps: 158809 Ep_Number: 161 Reward: -549.83 Cocaine: 0 Mild_Cocaine 413 Sadness: 372 Death: 215\n",
            "Timesteps: 159809 Ep_Number: 162 Reward: -463.11 Cocaine: 0 Mild_Cocaine 441 Sadness: 422 Death: 137\n",
            "Timesteps: 160809 Ep_Number: 163 Reward: -779.00 Cocaine: 0 Mild_Cocaine 290 Sadness: 321 Death: 389\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -724.211000\n",
            "---------------------------------------\n",
            "Timesteps: 161809 Ep_Number: 164 Reward: -847.17 Cocaine: 0 Mild_Cocaine 147 Sadness: 482 Death: 371\n",
            "Timesteps: 162809 Ep_Number: 165 Reward: -595.08 Cocaine: 0 Mild_Cocaine 498 Sadness: 181 Death: 321\n",
            "Timesteps: 163809 Ep_Number: 166 Reward: -577.75 Cocaine: 0 Mild_Cocaine 445 Sadness: 288 Death: 267\n",
            "Timesteps: 164809 Ep_Number: 167 Reward: -706.19 Cocaine: 0 Mild_Cocaine 299 Sadness: 387 Death: 314\n",
            "Timesteps: 165809 Ep_Number: 168 Reward: -586.01 Cocaine: 0 Mild_Cocaine 341 Sadness: 451 Death: 208\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -853.621000\n",
            "---------------------------------------\n",
            "Timesteps: 166809 Ep_Number: 169 Reward: -525.80 Cocaine: 0 Mild_Cocaine 350 Sadness: 503 Death: 147\n",
            "Timesteps: 167809 Ep_Number: 170 Reward: -878.01 Cocaine: 0 Mild_Cocaine 351 Sadness: 110 Death: 539\n",
            "Timesteps: 168809 Ep_Number: 171 Reward: -525.75 Cocaine: 0 Mild_Cocaine 405 Sadness: 412 Death: 183\n",
            "Timesteps: 169809 Ep_Number: 172 Reward: -606.64 Cocaine: 0 Mild_Cocaine 364 Sadness: 390 Death: 246\n",
            "Timesteps: 170809 Ep_Number: 173 Reward: -554.09 Cocaine: 0 Mild_Cocaine 479 Sadness: 258 Death: 263\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -836.704000\n",
            "---------------------------------------\n",
            "Timesteps: 171809 Ep_Number: 174 Reward: -397.41 Cocaine: 0 Mild_Cocaine 621 Sadness: 197 Death: 182\n",
            "Timesteps: 172809 Ep_Number: 175 Reward: -596.99 Cocaine: 0 Mild_Cocaine 269 Sadness: 558 Death: 173\n",
            "Timesteps: 173809 Ep_Number: 176 Reward: -449.41 Cocaine: 0 Mild_Cocaine 481 Sadness: 371 Death: 148\n",
            "Timesteps: 174809 Ep_Number: 177 Reward: -626.10 Cocaine: 0 Mild_Cocaine 360 Sadness: 375 Death: 265\n",
            "Timesteps: 175809 Ep_Number: 178 Reward: -545.37 Cocaine: 0 Mild_Cocaine 297 Sadness: 569 Death: 134\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -686.321000\n",
            "---------------------------------------\n",
            "Timesteps: 176809 Ep_Number: 179 Reward: -615.32 Cocaine: 0 Mild_Cocaine 212 Sadness: 632 Death: 156\n",
            "Timesteps: 177809 Ep_Number: 180 Reward: -473.38 Cocaine: 0 Mild_Cocaine 448 Sadness: 399 Death: 153\n",
            "Timesteps: 178809 Ep_Number: 181 Reward: -668.01 Cocaine: 0 Mild_Cocaine 411 Sadness: 244 Death: 345\n",
            "Timesteps: 179809 Ep_Number: 182 Reward: -1455.83 Cocaine: 0 Mild_Cocaine 23 Sadness: 11 Death: 966\n",
            "Timesteps: 180809 Ep_Number: 183 Reward: -580.14 Cocaine: 0 Mild_Cocaine 354 Sadness: 436 Death: 210\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -626.101000\n",
            "---------------------------------------\n",
            "Timesteps: 181809 Ep_Number: 184 Reward: -427.16 Cocaine: 0 Mild_Cocaine 566 Sadness: 255 Death: 179\n",
            "Timesteps: 182809 Ep_Number: 185 Reward: -703.96 Cocaine: 0 Mild_Cocaine 376 Sadness: 262 Death: 362\n",
            "Timesteps: 183809 Ep_Number: 186 Reward: -1284.18 Cocaine: 0 Mild_Cocaine 108 Sadness: 61 Death: 831\n",
            "Timesteps: 184809 Ep_Number: 187 Reward: -551.66 Cocaine: 0 Mild_Cocaine 416 Sadness: 365 Death: 219\n",
            "Timesteps: 185809 Ep_Number: 188 Reward: -337.02 Cocaine: 0 Mild_Cocaine 522 Sadness: 428 Death: 50\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -495.242000\n",
            "---------------------------------------\n",
            "Timesteps: 186809 Ep_Number: 189 Reward: -352.07 Cocaine: 0 Mild_Cocaine 527 Sadness: 403 Death: 70\n",
            "Timesteps: 187809 Ep_Number: 190 Reward: -402.30 Cocaine: 0 Mild_Cocaine 480 Sadness: 425 Death: 95\n",
            "Timesteps: 188809 Ep_Number: 191 Reward: -520.36 Cocaine: 0 Mild_Cocaine 556 Sadness: 168 Death: 276\n",
            "Timesteps: 189809 Ep_Number: 192 Reward: -1197.82 Cocaine: 0 Mild_Cocaine 172 Sadness: 51 Death: 777\n",
            "Timesteps: 190809 Ep_Number: 193 Reward: -410.22 Cocaine: 0 Mild_Cocaine 462 Sadness: 446 Death: 92\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -628.965000\n",
            "---------------------------------------\n",
            "Timesteps: 191809 Ep_Number: 194 Reward: -452.60 Cocaine: 0 Mild_Cocaine 500 Sadness: 336 Death: 164\n",
            "Timesteps: 192809 Ep_Number: 195 Reward: -630.46 Cocaine: 0 Mild_Cocaine 406 Sadness: 294 Death: 300\n",
            "Timesteps: 193809 Ep_Number: 196 Reward: -313.19 Cocaine: 0 Mild_Cocaine 509 Sadness: 476 Death: 15\n",
            "Timesteps: 194809 Ep_Number: 197 Reward: -763.82 Cocaine: 0 Mild_Cocaine 212 Sadness: 467 Death: 321\n",
            "Timesteps: 195809 Ep_Number: 198 Reward: -1016.78 Cocaine: 0 Mild_Cocaine 218 Sadness: 176 Death: 606\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -635.470000\n",
            "---------------------------------------\n",
            "Timesteps: 196809 Ep_Number: 199 Reward: -838.23 Cocaine: 0 Mild_Cocaine 153 Sadness: 482 Death: 365\n",
            "Timesteps: 197809 Ep_Number: 200 Reward: -614.76 Cocaine: 0 Mild_Cocaine 306 Sadness: 477 Death: 217\n",
            "Timesteps: 198809 Ep_Number: 201 Reward: -404.67 Cocaine: 0 Mild_Cocaine 537 Sadness: 328 Death: 135\n",
            "Timesteps: 199809 Ep_Number: 202 Reward: -274.66 Cocaine: 0 Mild_Cocaine 556 Sadness: 441 Death: 3\n",
            "Timesteps: 200809 Ep_Number: 203 Reward: -596.90 Cocaine: 0 Mild_Cocaine 530 Sadness: 126 Death: 344\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -380.591000\n",
            "---------------------------------------\n",
            "Timesteps: 201809 Ep_Number: 204 Reward: -623.54 Cocaine: 0 Mild_Cocaine 494 Sadness: 156 Death: 350\n",
            "Timesteps: 202809 Ep_Number: 205 Reward: -516.75 Cocaine: 0 Mild_Cocaine 405 Sadness: 422 Death: 173\n",
            "Timesteps: 203809 Ep_Number: 206 Reward: -282.58 Cocaine: 0 Mild_Cocaine 538 Sadness: 462 Death: 0\n",
            "Timesteps: 204809 Ep_Number: 207 Reward: -390.63 Cocaine: 0 Mild_Cocaine 483 Sadness: 433 Death: 84\n",
            "Timesteps: 205809 Ep_Number: 208 Reward: -721.45 Cocaine: 0 Mild_Cocaine 325 Sadness: 327 Death: 348\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -374.502000\n",
            "---------------------------------------\n",
            "Timesteps: 206809 Ep_Number: 209 Reward: -252.09 Cocaine: 0 Mild_Cocaine 669 Sadness: 279 Death: 52\n",
            "Timesteps: 207809 Ep_Number: 210 Reward: -290.27 Cocaine: 0 Mild_Cocaine 647 Sadness: 273 Death: 80\n",
            "Timesteps: 208809 Ep_Number: 211 Reward: -681.92 Cocaine: 0 Mild_Cocaine 302 Sadness: 409 Death: 289\n",
            "Timesteps: 209809 Ep_Number: 212 Reward: -513.54 Cocaine: 0 Mild_Cocaine 534 Sadness: 212 Death: 254\n",
            "Timesteps: 210809 Ep_Number: 213 Reward: -368.53 Cocaine: 0 Mild_Cocaine 403 Sadness: 590 Death: 7\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -491.366000\n",
            "---------------------------------------\n",
            "Timesteps: 211809 Ep_Number: 214 Reward: -370.23 Cocaine: 0 Mild_Cocaine 513 Sadness: 406 Death: 81\n",
            "Timesteps: 212809 Ep_Number: 215 Reward: -764.37 Cocaine: 0 Mild_Cocaine 237 Sadness: 425 Death: 338\n",
            "Timesteps: 213809 Ep_Number: 216 Reward: -689.67 Cocaine: 0 Mild_Cocaine 327 Sadness: 359 Death: 314\n",
            "Timesteps: 214809 Ep_Number: 217 Reward: -396.15 Cocaine: 0 Mild_Cocaine 585 Sadness: 258 Death: 157\n",
            "Timesteps: 215809 Ep_Number: 218 Reward: -318.18 Cocaine: 0 Mild_Cocaine 528 Sadness: 439 Death: 33\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -503.304000\n",
            "---------------------------------------\n",
            "Timesteps: 216809 Ep_Number: 219 Reward: -418.29 Cocaine: 0 Mild_Cocaine 549 Sadness: 293 Death: 158\n",
            "Timesteps: 217809 Ep_Number: 220 Reward: -446.27 Cocaine: 0 Mild_Cocaine 497 Sadness: 348 Death: 155\n",
            "Timesteps: 218809 Ep_Number: 221 Reward: -667.95 Cocaine: 0 Mild_Cocaine 315 Sadness: 403 Death: 282\n",
            "Timesteps: 219809 Ep_Number: 222 Reward: -434.78 Cocaine: 0 Mild_Cocaine 518 Sadness: 326 Death: 156\n",
            "Timesteps: 220809 Ep_Number: 223 Reward: -326.73 Cocaine: 0 Mild_Cocaine 573 Sadness: 355 Death: 72\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -418.004000\n",
            "---------------------------------------\n",
            "Timesteps: 221809 Ep_Number: 224 Reward: -446.21 Cocaine: 0 Mild_Cocaine 491 Sadness: 358 Death: 151\n",
            "Timesteps: 222809 Ep_Number: 225 Reward: -648.42 Cocaine: 0 Mild_Cocaine 342 Sadness: 380 Death: 278\n",
            "Timesteps: 223769 Ep_Number: 226 Reward: -366.09 Cocaine: 1 Mild_Cocaine 629 Sadness: 148 Death: 182\n",
            "Timesteps: 224769 Ep_Number: 227 Reward: -581.15 Cocaine: 0 Mild_Cocaine 305 Sadness: 516 Death: 179\n",
            "Timesteps: 225769 Ep_Number: 228 Reward: -688.10 Cocaine: 0 Mild_Cocaine 380 Sadness: 273 Death: 347\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -610.982000\n",
            "---------------------------------------\n",
            "Timesteps: 226734 Ep_Number: 229 Reward: -790.34 Cocaine: 1 Mild_Cocaine 394 Sadness: 74 Death: 496\n",
            "Timesteps: 227734 Ep_Number: 230 Reward: -433.57 Cocaine: 0 Mild_Cocaine 517 Sadness: 329 Death: 154\n",
            "Timesteps: 228734 Ep_Number: 231 Reward: -474.27 Cocaine: 0 Mild_Cocaine 477 Sadness: 350 Death: 173\n",
            "Timesteps: 229188 Ep_Number: 232 Reward: -100.54 Cocaine: 1 Mild_Cocaine 354 Sadness: 55 Death: 44\n",
            "Timesteps: 230188 Ep_Number: 233 Reward: -555.93 Cocaine: 0 Mild_Cocaine 453 Sadness: 299 Death: 248\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -461.333000\n",
            "---------------------------------------\n",
            "Timesteps: 231188 Ep_Number: 234 Reward: -324.49 Cocaine: 0 Mild_Cocaine 499 Sadness: 480 Death: 21\n",
            "Timesteps: 232188 Ep_Number: 235 Reward: -335.62 Cocaine: 0 Mild_Cocaine 532 Sadness: 413 Death: 55\n",
            "Timesteps: 233188 Ep_Number: 236 Reward: -684.98 Cocaine: 0 Mild_Cocaine 428 Sadness: 197 Death: 375\n",
            "Timesteps: 234188 Ep_Number: 237 Reward: -370.63 Cocaine: 0 Mild_Cocaine 523 Sadness: 389 Death: 88\n",
            "Timesteps: 235188 Ep_Number: 238 Reward: -515.95 Cocaine: 0 Mild_Cocaine 295 Sadness: 605 Death: 100\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -598.025000\n",
            "---------------------------------------\n",
            "Timesteps: 236188 Ep_Number: 239 Reward: -332.28 Cocaine: 0 Mild_Cocaine 588 Sadness: 324 Death: 88\n",
            "Timesteps: 237188 Ep_Number: 240 Reward: -417.41 Cocaine: 0 Mild_Cocaine 401 Sadness: 539 Death: 60\n",
            "Timesteps: 238188 Ep_Number: 241 Reward: -370.48 Cocaine: 0 Mild_Cocaine 508 Sadness: 414 Death: 78\n",
            "Timesteps: 239188 Ep_Number: 242 Reward: -549.60 Cocaine: 0 Mild_Cocaine 450 Sadness: 311 Death: 239\n",
            "Timesteps: 240188 Ep_Number: 243 Reward: -801.41 Cocaine: 0 Mild_Cocaine 281 Sadness: 311 Death: 408\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -740.821000\n",
            "---------------------------------------\n",
            "Timesteps: 241188 Ep_Number: 244 Reward: -499.54 Cocaine: 0 Mild_Cocaine 364 Sadness: 509 Death: 127\n",
            "Timesteps: 242188 Ep_Number: 245 Reward: -219.44 Cocaine: 0 Mild_Cocaine 674 Sadness: 307 Death: 19\n",
            "Timesteps: 243188 Ep_Number: 246 Reward: -335.44 Cocaine: 0 Mild_Cocaine 604 Sadness: 294 Death: 102\n",
            "Timesteps: 244188 Ep_Number: 247 Reward: -207.17 Cocaine: 0 Mild_Cocaine 707 Sadness: 266 Death: 27\n",
            "Timesteps: 245188 Ep_Number: 248 Reward: -354.61 Cocaine: 0 Mild_Cocaine 541 Sadness: 377 Death: 82\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -529.287000\n",
            "---------------------------------------\n",
            "Timesteps: 246188 Ep_Number: 249 Reward: -454.85 Cocaine: 0 Mild_Cocaine 365 Sadness: 557 Death: 78\n",
            "Timesteps: 247188 Ep_Number: 250 Reward: -385.37 Cocaine: 0 Mild_Cocaine 437 Sadness: 515 Death: 48\n",
            "Timesteps: 248188 Ep_Number: 251 Reward: -641.11 Cocaine: 0 Mild_Cocaine 301 Sadness: 456 Death: 243\n",
            "Timesteps: 249188 Ep_Number: 252 Reward: -287.38 Cocaine: 0 Mild_Cocaine 568 Sadness: 407 Death: 25\n",
            "Timesteps: 250188 Ep_Number: 253 Reward: -1007.27 Cocaine: 0 Mild_Cocaine 257 Sadness: 122 Death: 621\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -468.478000\n",
            "---------------------------------------\n",
            "Timesteps: 250507 Ep_Number: 254 Reward: -29.87 Cocaine: 1 Mild_Cocaine 277 Sadness: 36 Death: 5\n",
            "Timesteps: 251507 Ep_Number: 255 Reward: -395.06 Cocaine: 0 Mild_Cocaine 506 Sadness: 390 Death: 104\n",
            "Timesteps: 252507 Ep_Number: 256 Reward: -394.85 Cocaine: 0 Mild_Cocaine 485 Sadness: 425 Death: 90\n",
            "Timesteps: 253507 Ep_Number: 257 Reward: -197.46 Cocaine: 0 Mild_Cocaine 786 Sadness: 146 Death: 68\n",
            "Timesteps: 254507 Ep_Number: 258 Reward: -749.96 Cocaine: 0 Mild_Cocaine 266 Sadness: 393 Death: 341\n",
            "Timesteps: 255507 Ep_Number: 259 Reward: -775.94 Cocaine: 0 Mild_Cocaine 254 Sadness: 384 Death: 362\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -451.528000\n",
            "---------------------------------------\n",
            "Timesteps: 256507 Ep_Number: 260 Reward: -358.95 Cocaine: 0 Mild_Cocaine 465 Sadness: 498 Death: 37\n",
            "Timesteps: 257507 Ep_Number: 261 Reward: -345.33 Cocaine: 0 Mild_Cocaine 453 Sadness: 533 Death: 14\n",
            "Timesteps: 258507 Ep_Number: 262 Reward: -311.26 Cocaine: 0 Mild_Cocaine 526 Sadness: 450 Death: 24\n",
            "Timesteps: 259507 Ep_Number: 263 Reward: -269.36 Cocaine: 0 Mild_Cocaine 626 Sadness: 331 Death: 43\n",
            "Timesteps: 260467 Ep_Number: 264 Reward: -273.11 Cocaine: 1 Mild_Cocaine 631 Sadness: 248 Death: 80\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -429.157000\n",
            "---------------------------------------\n",
            "Timesteps: 261467 Ep_Number: 265 Reward: -335.02 Cocaine: 0 Mild_Cocaine 562 Sadness: 364 Death: 74\n",
            "Timesteps: 262467 Ep_Number: 266 Reward: -295.58 Cocaine: 0 Mild_Cocaine 638 Sadness: 282 Death: 80\n",
            "Timesteps: 262965 Ep_Number: 267 Reward: -111.57 Cocaine: 1 Mild_Cocaine 377 Sadness: 78 Death: 42\n",
            "Timesteps: 263965 Ep_Number: 268 Reward: -579.23 Cocaine: 0 Mild_Cocaine 383 Sadness: 389 Death: 228\n",
            "Timesteps: 264965 Ep_Number: 269 Reward: -876.16 Cocaine: 0 Mild_Cocaine 226 Sadness: 319 Death: 455\n",
            "Timesteps: 265965 Ep_Number: 270 Reward: -368.05 Cocaine: 0 Mild_Cocaine 625 Sadness: 223 Death: 152\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -327.931000\n",
            "---------------------------------------\n",
            "Timesteps: 266776 Ep_Number: 271 Reward: -303.93 Cocaine: 1 Mild_Cocaine 473 Sadness: 227 Death: 110\n",
            "Timesteps: 267776 Ep_Number: 272 Reward: -294.56 Cocaine: 0 Mild_Cocaine 716 Sadness: 154 Death: 130\n",
            "Timesteps: 268776 Ep_Number: 273 Reward: -641.00 Cocaine: 0 Mild_Cocaine 440 Sadness: 226 Death: 334\n",
            "Timesteps: 269776 Ep_Number: 274 Reward: -277.60 Cocaine: 0 Mild_Cocaine 580 Sadness: 398 Death: 22\n",
            "Timesteps: 270776 Ep_Number: 275 Reward: -434.90 Cocaine: 0 Mild_Cocaine 530 Sadness: 306 Death: 164\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -426.599000\n",
            "---------------------------------------\n",
            "Timesteps: 271776 Ep_Number: 276 Reward: -1166.43 Cocaine: 0 Mild_Cocaine 123 Sadness: 167 Death: 710\n",
            "Timesteps: 272776 Ep_Number: 277 Reward: -474.05 Cocaine: 0 Mild_Cocaine 485 Sadness: 337 Death: 178\n",
            "Timesteps: 273457 Ep_Number: 278 Reward: -247.19 Cocaine: 1 Mild_Cocaine 469 Sadness: 80 Death: 131\n",
            "Timesteps: 274457 Ep_Number: 279 Reward: -334.91 Cocaine: 0 Mild_Cocaine 611 Sadness: 283 Death: 106\n",
            "Timesteps: 275457 Ep_Number: 280 Reward: -182.41 Cocaine: 0 Mild_Cocaine 781 Sadness: 171 Death: 48\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -425.110000\n",
            "---------------------------------------\n",
            "Timesteps: 276457 Ep_Number: 281 Reward: -370.25 Cocaine: 0 Mild_Cocaine 455 Sadness: 502 Death: 43\n",
            "Timesteps: 277114 Ep_Number: 282 Reward: -119.68 Cocaine: 1 Mild_Cocaine 528 Sadness: 84 Death: 44\n",
            "Timesteps: 278114 Ep_Number: 283 Reward: -477.97 Cocaine: 0 Mild_Cocaine 367 Sadness: 528 Death: 105\n",
            "Timesteps: 279114 Ep_Number: 284 Reward: -1186.82 Cocaine: 0 Mild_Cocaine 122 Sadness: 146 Death: 732\n",
            "Timesteps: 280114 Ep_Number: 285 Reward: -309.51 Cocaine: 0 Mild_Cocaine 561 Sadness: 394 Death: 45\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -369.255000\n",
            "---------------------------------------\n",
            "Timesteps: 281114 Ep_Number: 286 Reward: -312.21 Cocaine: 0 Mild_Cocaine 561 Sadness: 391 Death: 48\n",
            "Timesteps: 282114 Ep_Number: 287 Reward: -313.17 Cocaine: 0 Mild_Cocaine 567 Sadness: 380 Death: 53\n",
            "Timesteps: 283114 Ep_Number: 288 Reward: -368.65 Cocaine: 0 Mild_Cocaine 505 Sadness: 421 Death: 74\n",
            "Timesteps: 284114 Ep_Number: 289 Reward: -504.61 Cocaine: 0 Mild_Cocaine 421 Sadness: 409 Death: 170\n",
            "Timesteps: 285114 Ep_Number: 290 Reward: -414.05 Cocaine: 0 Mild_Cocaine 515 Sadness: 354 Death: 131\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -432.044000\n",
            "---------------------------------------\n",
            "Timesteps: 286114 Ep_Number: 291 Reward: -737.49 Cocaine: 0 Mild_Cocaine 339 Sadness: 286 Death: 375\n",
            "Timesteps: 287114 Ep_Number: 292 Reward: -258.50 Cocaine: 0 Mild_Cocaine 620 Sadness: 353 Death: 27\n",
            "Timesteps: 288114 Ep_Number: 293 Reward: -296.59 Cocaine: 0 Mild_Cocaine 679 Sadness: 213 Death: 108\n",
            "Timesteps: 289114 Ep_Number: 294 Reward: -1487.46 Cocaine: 0 Mild_Cocaine 6 Sadness: 4 Death: 990\n",
            "Timesteps: 290114 Ep_Number: 295 Reward: -424.82 Cocaine: 0 Mild_Cocaine 512 Sadness: 347 Death: 141\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -377.973000\n",
            "---------------------------------------\n",
            "Timesteps: 291114 Ep_Number: 296 Reward: -88.71 Cocaine: 0 Mild_Cocaine 891 Sadness: 93 Death: 16\n",
            "Timesteps: 292114 Ep_Number: 297 Reward: -1473.99 Cocaine: 0 Mild_Cocaine 9 Sadness: 14 Death: 977\n",
            "Timesteps: 293114 Ep_Number: 298 Reward: -505.64 Cocaine: 0 Mild_Cocaine 584 Sadness: 138 Death: 278\n",
            "Timesteps: 294114 Ep_Number: 299 Reward: -351.55 Cocaine: 0 Mild_Cocaine 505 Sadness: 440 Death: 55\n",
            "Timesteps: 295114 Ep_Number: 300 Reward: -378.80 Cocaine: 0 Mild_Cocaine 500 Sadness: 418 Death: 82\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -352.465000\n",
            "---------------------------------------\n",
            "Timesteps: 296114 Ep_Number: 301 Reward: -427.59 Cocaine: 0 Mild_Cocaine 489 Sadness: 382 Death: 129\n",
            "Timesteps: 297114 Ep_Number: 302 Reward: -310.37 Cocaine: 0 Mild_Cocaine 497 Sadness: 499 Death: 4\n",
            "Timesteps: 298114 Ep_Number: 303 Reward: -284.66 Cocaine: 0 Mild_Cocaine 626 Sadness: 314 Death: 60\n",
            "Timesteps: 299114 Ep_Number: 304 Reward: -347.91 Cocaine: 0 Mild_Cocaine 531 Sadness: 401 Death: 68\n",
            "Timesteps: 300114 Ep_Number: 305 Reward: -592.65 Cocaine: 0 Mild_Cocaine 435 Sadness: 288 Death: 277\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -390.656000\n",
            "---------------------------------------\n",
            "Timesteps: 301114 Ep_Number: 306 Reward: -349.57 Cocaine: 0 Mild_Cocaine 577 Sadness: 323 Death: 100\n",
            "Timesteps: 302114 Ep_Number: 307 Reward: -270.32 Cocaine: 0 Mild_Cocaine 632 Sadness: 320 Death: 48\n",
            "Timesteps: 303114 Ep_Number: 308 Reward: -382.28 Cocaine: 0 Mild_Cocaine 488 Sadness: 434 Death: 78\n",
            "Timesteps: 304114 Ep_Number: 309 Reward: -349.33 Cocaine: 0 Mild_Cocaine 553 Sadness: 363 Death: 84\n",
            "Timesteps: 305114 Ep_Number: 310 Reward: -428.62 Cocaine: 0 Mild_Cocaine 562 Sadness: 260 Death: 178\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -444.149000\n",
            "---------------------------------------\n",
            "Timesteps: 306114 Ep_Number: 311 Reward: -405.27 Cocaine: 0 Mild_Cocaine 507 Sadness: 377 Death: 116\n",
            "Timesteps: 307114 Ep_Number: 312 Reward: -155.47 Cocaine: 0 Mild_Cocaine 787 Sadness: 191 Death: 22\n",
            "Timesteps: 308114 Ep_Number: 313 Reward: -1059.22 Cocaine: 0 Mild_Cocaine 172 Sadness: 205 Death: 623\n",
            "Timesteps: 309114 Ep_Number: 314 Reward: -511.10 Cocaine: 0 Mild_Cocaine 500 Sadness: 271 Death: 229\n",
            "Timesteps: 310114 Ep_Number: 315 Reward: -359.30 Cocaine: 0 Mild_Cocaine 530 Sadness: 390 Death: 80\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -468.538000\n",
            "---------------------------------------\n",
            "Timesteps: 311114 Ep_Number: 316 Reward: -455.00 Cocaine: 0 Mild_Cocaine 560 Sadness: 234 Death: 206\n",
            "Timesteps: 312114 Ep_Number: 317 Reward: -502.74 Cocaine: 0 Mild_Cocaine 444 Sadness: 373 Death: 183\n",
            "Timesteps: 313114 Ep_Number: 318 Reward: -296.38 Cocaine: 0 Mild_Cocaine 568 Sadness: 397 Death: 35\n",
            "Timesteps: 314114 Ep_Number: 319 Reward: -1335.98 Cocaine: 0 Mild_Cocaine 98 Sadness: 20 Death: 882\n",
            "Timesteps: 315114 Ep_Number: 320 Reward: -171.53 Cocaine: 0 Mild_Cocaine 743 Sadness: 246 Death: 11\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -481.235000\n",
            "---------------------------------------\n",
            "Timesteps: 315973 Ep_Number: 321 Reward: -285.26 Cocaine: 1 Mild_Cocaine 526 Sadness: 240 Death: 92\n",
            "Timesteps: 316973 Ep_Number: 322 Reward: -535.45 Cocaine: 0 Mild_Cocaine 445 Sadness: 335 Death: 220\n",
            "Timesteps: 317973 Ep_Number: 323 Reward: -1144.99 Cocaine: 0 Mild_Cocaine 199 Sadness: 65 Death: 736\n",
            "Timesteps: 318973 Ep_Number: 324 Reward: -323.06 Cocaine: 0 Mild_Cocaine 686 Sadness: 172 Death: 142\n",
            "Timesteps: 319871 Ep_Number: 325 Reward: -274.40 Cocaine: 1 Mild_Cocaine 610 Sadness: 178 Death: 109\n",
            "Timesteps: 320573 Ep_Number: 326 Reward: -204.37 Cocaine: 1 Mild_Cocaine 537 Sadness: 50 Death: 114\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -415.517000\n",
            "---------------------------------------\n",
            "Timesteps: 321573 Ep_Number: 327 Reward: -292.42 Cocaine: 0 Mild_Cocaine 712 Sadness: 163 Death: 125\n",
            "Timesteps: 322573 Ep_Number: 328 Reward: -466.24 Cocaine: 0 Mild_Cocaine 634 Sadness: 99 Death: 267\n",
            "Timesteps: 323573 Ep_Number: 329 Reward: -467.04 Cocaine: 0 Mild_Cocaine 564 Sadness: 214 Death: 222\n",
            "Timesteps: 324062 Ep_Number: 330 Reward: -89.06 Cocaine: 1 Mild_Cocaine 406 Sadness: 40 Death: 42\n",
            "Timesteps: 325062 Ep_Number: 331 Reward: -382.56 Cocaine: 0 Mild_Cocaine 666 Sadness: 139 Death: 195\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -313.442000\n",
            "---------------------------------------\n",
            "Timesteps: 326062 Ep_Number: 332 Reward: -149.08 Cocaine: 0 Mild_Cocaine 778 Sadness: 213 Death: 9\n",
            "Timesteps: 327062 Ep_Number: 333 Reward: -282.64 Cocaine: 0 Mild_Cocaine 544 Sadness: 452 Death: 4\n",
            "Timesteps: 328062 Ep_Number: 334 Reward: -271.83 Cocaine: 0 Mild_Cocaine 573 Sadness: 416 Death: 11\n",
            "Timesteps: 329062 Ep_Number: 335 Reward: -450.31 Cocaine: 0 Mild_Cocaine 481 Sadness: 370 Death: 149\n",
            "Timesteps: 330062 Ep_Number: 336 Reward: -432.19 Cocaine: 0 Mild_Cocaine 559 Sadness: 261 Death: 180\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -437.186000\n",
            "---------------------------------------\n",
            "Timesteps: 330798 Ep_Number: 337 Reward: -194.07 Cocaine: 1 Mild_Cocaine 467 Sadness: 234 Death: 34\n",
            "Timesteps: 331798 Ep_Number: 338 Reward: -293.07 Cocaine: 0 Mild_Cocaine 537 Sadness: 452 Death: 11\n",
            "Timesteps: 332798 Ep_Number: 339 Reward: -1170.83 Cocaine: 0 Mild_Cocaine 143 Sadness: 129 Death: 728\n",
            "Timesteps: 333798 Ep_Number: 340 Reward: -226.06 Cocaine: 0 Mild_Cocaine 646 Sadness: 346 Death: 8\n",
            "Timesteps: 334309 Ep_Number: 341 Reward: -44.02 Cocaine: 1 Mild_Cocaine 462 Sadness: 34 Death: 14\n",
            "Timesteps: 335309 Ep_Number: 342 Reward: -295.54 Cocaine: 0 Mild_Cocaine 574 Sadness: 388 Death: 38\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -235.275000\n",
            "---------------------------------------\n",
            "Timesteps: 336309 Ep_Number: 343 Reward: -342.88 Cocaine: 0 Mild_Cocaine 538 Sadness: 395 Death: 67\n",
            "Timesteps: 336708 Ep_Number: 344 Reward: -208.73 Cocaine: 1 Mild_Cocaine 223 Sadness: 60 Death: 115\n",
            "Timesteps: 337708 Ep_Number: 345 Reward: -369.31 Cocaine: 0 Mild_Cocaine 571 Sadness: 311 Death: 118\n",
            "Timesteps: 338708 Ep_Number: 346 Reward: -1360.44 Cocaine: 0 Mild_Cocaine 84 Sadness: 16 Death: 900\n",
            "Timesteps: 339708 Ep_Number: 347 Reward: -534.04 Cocaine: 0 Mild_Cocaine 484 Sadness: 272 Death: 244\n",
            "Timesteps: 340708 Ep_Number: 348 Reward: -308.90 Cocaine: 0 Mild_Cocaine 620 Sadness: 297 Death: 83\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -442.101000\n",
            "---------------------------------------\n",
            "Timesteps: 341162 Ep_Number: 349 Reward: -21.13 Cocaine: 1 Mild_Cocaine 423 Sadness: 29 Death: 1\n",
            "Timesteps: 342162 Ep_Number: 350 Reward: -464.66 Cocaine: 0 Mild_Cocaine 446 Sadness: 412 Death: 142\n",
            "Timesteps: 343162 Ep_Number: 351 Reward: -283.97 Cocaine: 0 Mild_Cocaine 557 Sadness: 429 Death: 14\n",
            "Timesteps: 344162 Ep_Number: 352 Reward: -596.15 Cocaine: 0 Mild_Cocaine 365 Sadness: 400 Death: 235\n",
            "Timesteps: 345162 Ep_Number: 353 Reward: -228.56 Cocaine: 0 Mild_Cocaine 686 Sadness: 277 Death: 37\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -497.405000\n",
            "---------------------------------------\n",
            "Timesteps: 346162 Ep_Number: 354 Reward: -215.30 Cocaine: 0 Mild_Cocaine 710 Sadness: 252 Death: 38\n",
            "Timesteps: 347162 Ep_Number: 355 Reward: -383.63 Cocaine: 0 Mild_Cocaine 443 Sadness: 507 Death: 50\n",
            "Timesteps: 348162 Ep_Number: 356 Reward: -350.72 Cocaine: 0 Mild_Cocaine 482 Sadness: 479 Death: 39\n",
            "Timesteps: 349162 Ep_Number: 357 Reward: -721.92 Cocaine: 0 Mild_Cocaine 402 Sadness: 199 Death: 399\n",
            "Timesteps: 350162 Ep_Number: 358 Reward: -525.73 Cocaine: 0 Mild_Cocaine 373 Sadness: 465 Death: 162\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -385.197000\n",
            "---------------------------------------\n",
            "Timesteps: 351162 Ep_Number: 359 Reward: -363.45 Cocaine: 0 Mild_Cocaine 465 Sadness: 493 Death: 42\n",
            "Timesteps: 352162 Ep_Number: 360 Reward: -728.78 Cocaine: 0 Mild_Cocaine 308 Sadness: 347 Death: 345\n",
            "Timesteps: 353162 Ep_Number: 361 Reward: -385.65 Cocaine: 0 Mild_Cocaine 435 Sadness: 518 Death: 47\n",
            "Timesteps: 354162 Ep_Number: 362 Reward: -340.57 Cocaine: 0 Mild_Cocaine 487 Sadness: 482 Death: 31\n",
            "Timesteps: 355162 Ep_Number: 363 Reward: -801.10 Cocaine: 0 Mild_Cocaine 460 Sadness: 15 Death: 525\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -483.474000\n",
            "---------------------------------------\n",
            "Timesteps: 356162 Ep_Number: 364 Reward: -1406.32 Cocaine: 0 Mild_Cocaine 52 Sadness: 18 Death: 930\n",
            "Timesteps: 357162 Ep_Number: 365 Reward: -362.85 Cocaine: 0 Mild_Cocaine 495 Sadness: 444 Death: 61\n",
            "Timesteps: 358162 Ep_Number: 366 Reward: -306.27 Cocaine: 0 Mild_Cocaine 597 Sadness: 338 Death: 65\n",
            "Timesteps: 359162 Ep_Number: 367 Reward: -351.45 Cocaine: 0 Mild_Cocaine 525 Sadness: 407 Death: 68\n",
            "Timesteps: 360162 Ep_Number: 368 Reward: -388.90 Cocaine: 0 Mild_Cocaine 640 Sadness: 175 Death: 185\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -433.270000\n",
            "---------------------------------------\n",
            "Timesteps: 361162 Ep_Number: 369 Reward: -271.81 Cocaine: 0 Mild_Cocaine 631 Sadness: 320 Death: 49\n",
            "Timesteps: 362162 Ep_Number: 370 Reward: -286.02 Cocaine: 0 Mild_Cocaine 732 Sadness: 137 Death: 131\n",
            "Timesteps: 363162 Ep_Number: 371 Reward: -432.93 Cocaine: 0 Mild_Cocaine 483 Sadness: 386 Death: 131\n",
            "Timesteps: 364162 Ep_Number: 372 Reward: -367.54 Cocaine: 0 Mild_Cocaine 484 Sadness: 457 Death: 59\n",
            "Timesteps: 365162 Ep_Number: 373 Reward: -160.40 Cocaine: 0 Mild_Cocaine 800 Sadness: 164 Death: 36\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -272.679000\n",
            "---------------------------------------\n",
            "Timesteps: 366162 Ep_Number: 374 Reward: -260.58 Cocaine: 0 Mild_Cocaine 618 Sadness: 354 Death: 28\n",
            "Timesteps: 367162 Ep_Number: 375 Reward: -321.81 Cocaine: 0 Mild_Cocaine 531 Sadness: 430 Death: 39\n",
            "Timesteps: 368162 Ep_Number: 376 Reward: -428.30 Cocaine: 0 Mild_Cocaine 410 Sadness: 512 Death: 78\n",
            "Timesteps: 368992 Ep_Number: 377 Reward: -153.41 Cocaine: 1 Mild_Cocaine 601 Sadness: 214 Death: 14\n",
            "Timesteps: 369992 Ep_Number: 378 Reward: -403.08 Cocaine: 0 Mild_Cocaine 468 Sadness: 444 Death: 88\n",
            "Timesteps: 370992 Ep_Number: 379 Reward: -592.42 Cocaine: 0 Mild_Cocaine 292 Sadness: 525 Death: 183\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -406.132000\n",
            "---------------------------------------\n",
            "Timesteps: 371992 Ep_Number: 380 Reward: -190.13 Cocaine: 0 Mild_Cocaine 803 Sadness: 126 Death: 71\n",
            "Timesteps: 372992 Ep_Number: 381 Reward: -398.56 Cocaine: 0 Mild_Cocaine 526 Sadness: 353 Death: 121\n",
            "Timesteps: 373641 Ep_Number: 382 Reward: -323.76 Cocaine: 1 Mild_Cocaine 386 Sadness: 79 Death: 183\n",
            "Timesteps: 374641 Ep_Number: 383 Reward: -450.81 Cocaine: 0 Mild_Cocaine 561 Sadness: 237 Death: 202\n",
            "Timesteps: 375641 Ep_Number: 384 Reward: -463.84 Cocaine: 0 Mild_Cocaine 484 Sadness: 350 Death: 166\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -569.545000\n",
            "---------------------------------------\n",
            "Timesteps: 376641 Ep_Number: 385 Reward: -561.50 Cocaine: 0 Mild_Cocaine 230 Sadness: 662 Death: 108\n",
            "Timesteps: 377641 Ep_Number: 386 Reward: -339.00 Cocaine: 0 Mild_Cocaine 630 Sadness: 247 Death: 123\n",
            "Timesteps: 378641 Ep_Number: 387 Reward: -384.54 Cocaine: 0 Mild_Cocaine 504 Sadness: 405 Death: 91\n",
            "Timesteps: 379641 Ep_Number: 388 Reward: -535.70 Cocaine: 0 Mild_Cocaine 440 Sadness: 343 Death: 217\n",
            "Timesteps: 380641 Ep_Number: 389 Reward: -537.30 Cocaine: 0 Mild_Cocaine 390 Sadness: 424 Death: 186\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -445.001000\n",
            "---------------------------------------\n",
            "Timesteps: 381641 Ep_Number: 390 Reward: -353.53 Cocaine: 0 Mild_Cocaine 523 Sadness: 408 Death: 69\n",
            "Timesteps: 382153 Ep_Number: 391 Reward: -246.89 Cocaine: 1 Mild_Cocaine 319 Sadness: 47 Death: 145\n",
            "Timesteps: 383069 Ep_Number: 392 Reward: -115.32 Cocaine: 1 Mild_Cocaine 782 Sadness: 100 Death: 33\n",
            "Timesteps: 383624 Ep_Number: 393 Reward: -450.94 Cocaine: 1 Mild_Cocaine 174 Sadness: 132 Death: 248\n",
            "Timesteps: 384624 Ep_Number: 394 Reward: -512.24 Cocaine: 0 Mild_Cocaine 434 Sadness: 379 Death: 187\n",
            "Timesteps: 385624 Ep_Number: 395 Reward: -305.03 Cocaine: 0 Mild_Cocaine 683 Sadness: 197 Death: 120\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -382.445000\n",
            "---------------------------------------\n",
            "Timesteps: 386624 Ep_Number: 396 Reward: -321.11 Cocaine: 0 Mild_Cocaine 671 Sadness: 199 Death: 130\n",
            "Timesteps: 387624 Ep_Number: 397 Reward: -829.38 Cocaine: 0 Mild_Cocaine 348 Sadness: 169 Death: 483\n",
            "Timesteps: 388624 Ep_Number: 398 Reward: -682.32 Cocaine: 0 Mild_Cocaine 492 Sadness: 94 Death: 414\n",
            "Timesteps: 389624 Ep_Number: 399 Reward: -271.78 Cocaine: 0 Mild_Cocaine 718 Sadness: 176 Death: 106\n",
            "Timesteps: 390624 Ep_Number: 400 Reward: -147.49 Cocaine: 0 Mild_Cocaine 799 Sadness: 180 Death: 21\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -505.104000\n",
            "---------------------------------------\n",
            "Timesteps: 391624 Ep_Number: 401 Reward: -694.37 Cocaine: 0 Mild_Cocaine 467 Sadness: 122 Death: 411\n",
            "Timesteps: 392624 Ep_Number: 402 Reward: -442.78 Cocaine: 0 Mild_Cocaine 538 Sadness: 284 Death: 178\n",
            "Timesteps: 393624 Ep_Number: 403 Reward: -246.41 Cocaine: 0 Mild_Cocaine 761 Sadness: 133 Death: 106\n",
            "Timesteps: 394624 Ep_Number: 404 Reward: -451.74 Cocaine: 0 Mild_Cocaine 564 Sadness: 231 Death: 205\n",
            "Timesteps: 395624 Ep_Number: 405 Reward: -358.66 Cocaine: 0 Mild_Cocaine 586 Sadness: 298 Death: 116\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -328.310000\n",
            "---------------------------------------\n",
            "Timesteps: 396624 Ep_Number: 406 Reward: -334.78 Cocaine: 0 Mild_Cocaine 538 Sadness: 404 Death: 58\n",
            "Timesteps: 397624 Ep_Number: 407 Reward: -218.38 Cocaine: 0 Mild_Cocaine 688 Sadness: 285 Death: 27\n",
            "Timesteps: 398624 Ep_Number: 408 Reward: -231.63 Cocaine: 0 Mild_Cocaine 693 Sadness: 262 Death: 45\n",
            "Timesteps: 399101 Ep_Number: 409 Reward: -296.54 Cocaine: 1 Mild_Cocaine 184 Sadness: 157 Death: 135\n",
            "Timesteps: 400101 Ep_Number: 410 Reward: -1481.22 Cocaine: 0 Mild_Cocaine 12 Sadness: 1 Death: 987\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -598.962000\n",
            "---------------------------------------\n",
            "Timesteps: 401101 Ep_Number: 411 Reward: -461.75 Cocaine: 0 Mild_Cocaine 515 Sadness: 301 Death: 184\n",
            "Timesteps: 402101 Ep_Number: 412 Reward: -321.52 Cocaine: 0 Mild_Cocaine 562 Sadness: 379 Death: 59\n",
            "Timesteps: 403101 Ep_Number: 413 Reward: -401.80 Cocaine: 0 Mild_Cocaine 490 Sadness: 409 Death: 101\n",
            "Timesteps: 404101 Ep_Number: 414 Reward: -386.98 Cocaine: 0 Mild_Cocaine 538 Sadness: 346 Death: 116\n",
            "Timesteps: 405101 Ep_Number: 415 Reward: -1296.97 Cocaine: 0 Mild_Cocaine 97 Sadness: 65 Death: 838\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -401.651000\n",
            "---------------------------------------\n",
            "Timesteps: 406101 Ep_Number: 416 Reward: -347.37 Cocaine: 0 Mild_Cocaine 567 Sadness: 342 Death: 91\n",
            "Timesteps: 407101 Ep_Number: 417 Reward: -209.64 Cocaine: 0 Mild_Cocaine 744 Sadness: 202 Death: 54\n",
            "Timesteps: 408101 Ep_Number: 418 Reward: -373.90 Cocaine: 0 Mild_Cocaine 490 Sadness: 440 Death: 70\n",
            "Timesteps: 409101 Ep_Number: 419 Reward: -562.56 Cocaine: 0 Mild_Cocaine 486 Sadness: 237 Death: 277\n",
            "Timesteps: 410101 Ep_Number: 420 Reward: -1212.57 Cocaine: 0 Mild_Cocaine 147 Sadness: 76 Death: 777\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -323.131000\n",
            "---------------------------------------\n",
            "Timesteps: 411101 Ep_Number: 421 Reward: -373.92 Cocaine: 0 Mild_Cocaine 612 Sadness: 238 Death: 150\n",
            "Timesteps: 412101 Ep_Number: 422 Reward: -322.15 Cocaine: 0 Mild_Cocaine 625 Sadness: 274 Death: 101\n",
            "Timesteps: 413101 Ep_Number: 423 Reward: -352.57 Cocaine: 0 Mild_Cocaine 607 Sadness: 270 Death: 123\n",
            "Timesteps: 414101 Ep_Number: 424 Reward: -464.25 Cocaine: 0 Mild_Cocaine 465 Sadness: 381 Death: 154\n",
            "Timesteps: 415101 Ep_Number: 425 Reward: -267.27 Cocaine: 0 Mild_Cocaine 747 Sadness: 133 Death: 120\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -285.833000\n",
            "---------------------------------------\n",
            "Timesteps: 415516 Ep_Number: 426 Reward: -24.71 Cocaine: 1 Mild_Cocaine 391 Sadness: 13 Death: 10\n",
            "Timesteps: 416476 Ep_Number: 427 Reward: -323.96 Cocaine: 1 Mild_Cocaine 676 Sadness: 117 Death: 166\n",
            "Timesteps: 417476 Ep_Number: 428 Reward: -759.85 Cocaine: 0 Mild_Cocaine 295 Sadness: 334 Death: 371\n",
            "Timesteps: 418476 Ep_Number: 429 Reward: -478.69 Cocaine: 0 Mild_Cocaine 439 Sadness: 408 Death: 153\n",
            "Timesteps: 419476 Ep_Number: 430 Reward: -375.86 Cocaine: 0 Mild_Cocaine 476 Sadness: 461 Death: 63\n",
            "Timesteps: 420476 Ep_Number: 431 Reward: -336.74 Cocaine: 0 Mild_Cocaine 524 Sadness: 425 Death: 51\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -273.440000\n",
            "---------------------------------------\n",
            "Timesteps: 420737 Ep_Number: 432 Reward: -1.19 Cocaine: 1 Mild_Cocaine 259 Sadness: 1 Death: 0\n",
            "Timesteps: 421737 Ep_Number: 433 Reward: -260.25 Cocaine: 0 Mild_Cocaine 585 Sadness: 409 Death: 6\n",
            "Timesteps: 422696 Ep_Number: 434 Reward: -286.04 Cocaine: 1 Mild_Cocaine 724 Sadness: 78 Death: 156\n",
            "Timesteps: 423696 Ep_Number: 435 Reward: -1396.79 Cocaine: 0 Mild_Cocaine 59 Sadness: 17 Death: 924\n",
            "Timesteps: 424696 Ep_Number: 436 Reward: -255.79 Cocaine: 0 Mild_Cocaine 649 Sadness: 308 Death: 43\n",
            "Timesteps: 425696 Ep_Number: 437 Reward: -362.29 Cocaine: 0 Mild_Cocaine 499 Sadness: 438 Death: 63\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -378.960000\n",
            "---------------------------------------\n",
            "Timesteps: 426156 Ep_Number: 438 Reward: -166.88 Cocaine: 1 Mild_Cocaine 298 Sadness: 84 Death: 77\n",
            "Timesteps: 427156 Ep_Number: 439 Reward: -343.74 Cocaine: 0 Mild_Cocaine 564 Sadness: 351 Death: 85\n",
            "Timesteps: 428156 Ep_Number: 440 Reward: -320.22 Cocaine: 0 Mild_Cocaine 642 Sadness: 248 Death: 110\n",
            "Timesteps: 429156 Ep_Number: 441 Reward: -296.38 Cocaine: 0 Mild_Cocaine 658 Sadness: 248 Death: 94\n",
            "Timesteps: 429482 Ep_Number: 442 Reward: -20.72 Cocaine: 1 Mild_Cocaine 292 Sadness: 33 Death: 0\n",
            "Timesteps: 430482 Ep_Number: 443 Reward: -241.69 Cocaine: 0 Mild_Cocaine 679 Sadness: 274 Death: 47\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -276.125000\n",
            "---------------------------------------\n",
            "Timesteps: 431482 Ep_Number: 444 Reward: -301.45 Cocaine: 0 Mild_Cocaine 625 Sadness: 297 Death: 78\n",
            "Timesteps: 432152 Ep_Number: 445 Reward: -90.37 Cocaine: 1 Mild_Cocaine 597 Sadness: 24 Death: 48\n",
            "Timesteps: 433152 Ep_Number: 446 Reward: -299.42 Cocaine: 0 Mild_Cocaine 752 Sadness: 89 Death: 159\n",
            "Timesteps: 434152 Ep_Number: 447 Reward: -303.86 Cocaine: 0 Mild_Cocaine 566 Sadness: 392 Death: 42\n",
            "Timesteps: 435152 Ep_Number: 448 Reward: -360.13 Cocaine: 0 Mild_Cocaine 553 Sadness: 351 Death: 96\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -330.820000\n",
            "---------------------------------------\n",
            "Timesteps: 436152 Ep_Number: 449 Reward: -357.10 Cocaine: 0 Mild_Cocaine 610 Sadness: 260 Death: 130\n",
            "Timesteps: 436793 Ep_Number: 450 Reward: -219.71 Cocaine: 1 Mild_Cocaine 391 Sadness: 173 Death: 76\n",
            "Timesteps: 437793 Ep_Number: 451 Reward: -631.96 Cocaine: 0 Mild_Cocaine 466 Sadness: 193 Death: 341\n",
            "Timesteps: 438793 Ep_Number: 452 Reward: -380.82 Cocaine: 0 Mild_Cocaine 492 Sadness: 429 Death: 79\n",
            "Timesteps: 439793 Ep_Number: 453 Reward: -400.41 Cocaine: 0 Mild_Cocaine 651 Sadness: 144 Death: 205\n",
            "Timesteps: 440380 Ep_Number: 454 Reward: -297.94 Cocaine: 1 Mild_Cocaine 324 Sadness: 107 Death: 155\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -246.633000\n",
            "---------------------------------------\n",
            "Timesteps: 441195 Ep_Number: 455 Reward: -243.60 Cocaine: 1 Mild_Cocaine 590 Sadness: 107 Death: 117\n",
            "Timesteps: 442195 Ep_Number: 456 Reward: -1421.70 Cocaine: 0 Mild_Cocaine 0 Sadness: 87 Death: 913\n",
            "Timesteps: 443195 Ep_Number: 457 Reward: -289.56 Cocaine: 0 Mild_Cocaine 636 Sadness: 292 Death: 72\n",
            "Timesteps: 443946 Ep_Number: 458 Reward: -257.65 Cocaine: 1 Mild_Cocaine 495 Sadness: 142 Death: 113\n",
            "Timesteps: 444946 Ep_Number: 459 Reward: -1034.23 Cocaine: 0 Mild_Cocaine 103 Sadness: 347 Death: 550\n",
            "Timesteps: 445946 Ep_Number: 460 Reward: -523.09 Cocaine: 0 Mild_Cocaine 379 Sadness: 458 Death: 163\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -417.363000\n",
            "---------------------------------------\n",
            "Timesteps: 446262 Ep_Number: 461 Reward: -144.98 Cocaine: 1 Mild_Cocaine 178 Sadness: 67 Death: 70\n",
            "Timesteps: 447262 Ep_Number: 462 Reward: -232.77 Cocaine: 0 Mild_Cocaine 717 Sadness: 221 Death: 62\n",
            "Timesteps: 448262 Ep_Number: 463 Reward: -264.67 Cocaine: 0 Mild_Cocaine 727 Sadness: 169 Death: 104\n",
            "Timesteps: 449262 Ep_Number: 464 Reward: -406.35 Cocaine: 0 Mild_Cocaine 345 Sadness: 644 Death: 11\n",
            "Timesteps: 449668 Ep_Number: 465 Reward: -63.58 Cocaine: 1 Mild_Cocaine 348 Sadness: 26 Death: 31\n",
            "Timesteps: 450239 Ep_Number: 466 Reward: -110.25 Cocaine: 1 Mild_Cocaine 455 Sadness: 72 Death: 43\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -459.216000\n",
            "---------------------------------------\n",
            "Timesteps: 451239 Ep_Number: 467 Reward: -258.59 Cocaine: 0 Mild_Cocaine 629 Sadness: 338 Death: 33\n",
            "Timesteps: 452239 Ep_Number: 468 Reward: -607.39 Cocaine: 0 Mild_Cocaine 439 Sadness: 265 Death: 296\n",
            "Timesteps: 453239 Ep_Number: 469 Reward: -294.35 Cocaine: 0 Mild_Cocaine 605 Sadness: 338 Death: 57\n",
            "Timesteps: 454239 Ep_Number: 470 Reward: -1437.49 Cocaine: 0 Mild_Cocaine 19 Sadness: 38 Death: 943\n",
            "Timesteps: 455206 Ep_Number: 471 Reward: -289.47 Cocaine: 1 Mild_Cocaine 647 Sadness: 215 Death: 104\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -269.844000\n",
            "---------------------------------------\n",
            "Timesteps: 456206 Ep_Number: 472 Reward: -1476.10 Cocaine: 0 Mild_Cocaine 10 Sadness: 10 Death: 980\n",
            "Timesteps: 457206 Ep_Number: 473 Reward: -321.04 Cocaine: 0 Mild_Cocaine 604 Sadness: 310 Death: 86\n",
            "Timesteps: 458206 Ep_Number: 474 Reward: -386.68 Cocaine: 0 Mild_Cocaine 598 Sadness: 247 Death: 155\n",
            "Timesteps: 458675 Ep_Number: 475 Reward: -36.31 Cocaine: 1 Mild_Cocaine 411 Sadness: 57 Death: 0\n",
            "Timesteps: 459675 Ep_Number: 476 Reward: -395.42 Cocaine: 0 Mild_Cocaine 542 Sadness: 330 Death: 128\n",
            "Timesteps: 460675 Ep_Number: 477 Reward: -539.83 Cocaine: 0 Mild_Cocaine 523 Sadness: 201 Death: 276\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -293.104000\n",
            "---------------------------------------\n",
            "Timesteps: 461675 Ep_Number: 478 Reward: -455.47 Cocaine: 0 Mild_Cocaine 367 Sadness: 553 Death: 80\n",
            "Timesteps: 462675 Ep_Number: 479 Reward: -1006.35 Cocaine: 0 Mild_Cocaine 315 Sadness: 27 Death: 658\n",
            "Timesteps: 463675 Ep_Number: 480 Reward: -842.57 Cocaine: 0 Mild_Cocaine 257 Sadness: 305 Death: 438\n",
            "Timesteps: 464344 Ep_Number: 481 Reward: -229.92 Cocaine: 1 Mild_Cocaine 422 Sadness: 157 Death: 89\n",
            "Timesteps: 465344 Ep_Number: 482 Reward: -279.36 Cocaine: 0 Mild_Cocaine 606 Sadness: 353 Death: 41\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -262.337000\n",
            "---------------------------------------\n",
            "Timesteps: 466344 Ep_Number: 483 Reward: -250.51 Cocaine: 0 Mild_Cocaine 751 Sadness: 145 Death: 104\n",
            "Timesteps: 467344 Ep_Number: 484 Reward: -434.92 Cocaine: 0 Mild_Cocaine 562 Sadness: 253 Death: 185\n",
            "Timesteps: 468344 Ep_Number: 485 Reward: -386.96 Cocaine: 0 Mild_Cocaine 506 Sadness: 399 Death: 95\n",
            "Timesteps: 469344 Ep_Number: 486 Reward: -330.94 Cocaine: 0 Mild_Cocaine 514 Sadness: 448 Death: 38\n",
            "Timesteps: 470344 Ep_Number: 487 Reward: -463.01 Cocaine: 0 Mild_Cocaine 551 Sadness: 240 Death: 209\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -265.946000\n",
            "---------------------------------------\n",
            "Timesteps: 471344 Ep_Number: 488 Reward: -266.60 Cocaine: 0 Mild_Cocaine 620 Sadness: 344 Death: 36\n",
            "Timesteps: 472344 Ep_Number: 489 Reward: -337.36 Cocaine: 0 Mild_Cocaine 616 Sadness: 272 Death: 112\n",
            "Timesteps: 473344 Ep_Number: 490 Reward: -374.37 Cocaine: 0 Mild_Cocaine 567 Sadness: 312 Death: 121\n",
            "Timesteps: 474344 Ep_Number: 491 Reward: -433.85 Cocaine: 0 Mild_Cocaine 515 Sadness: 332 Death: 153\n",
            "Timesteps: 475344 Ep_Number: 492 Reward: -624.94 Cocaine: 0 Mild_Cocaine 484 Sadness: 171 Death: 345\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -304.301000\n",
            "---------------------------------------\n",
            "Timesteps: 476344 Ep_Number: 493 Reward: -341.00 Cocaine: 0 Mild_Cocaine 590 Sadness: 311 Death: 99\n",
            "Timesteps: 477344 Ep_Number: 494 Reward: -838.61 Cocaine: 0 Mild_Cocaine 401 Sadness: 71 Death: 528\n",
            "Timesteps: 478344 Ep_Number: 495 Reward: -1463.34 Cocaine: 0 Mild_Cocaine 24 Sadness: 1 Death: 975\n",
            "Timesteps: 478712 Ep_Number: 496 Reward: -65.63 Cocaine: 1 Mild_Cocaine 283 Sadness: 68 Death: 16\n",
            "Timesteps: 479712 Ep_Number: 497 Reward: -354.48 Cocaine: 0 Mild_Cocaine 648 Sadness: 200 Death: 152\n",
            "Timesteps: 480712 Ep_Number: 498 Reward: -373.48 Cocaine: 0 Mild_Cocaine 448 Sadness: 510 Death: 42\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -269.160000\n",
            "---------------------------------------\n",
            "Timesteps: 481712 Ep_Number: 499 Reward: -621.32 Cocaine: 0 Mild_Cocaine 362 Sadness: 377 Death: 261\n",
            "Timesteps: 482712 Ep_Number: 500 Reward: -402.89 Cocaine: 0 Mild_Cocaine 569 Sadness: 277 Death: 154\n",
            "Timesteps: 483205 Ep_Number: 501 Reward: -44.00 Cocaine: 1 Mild_Cocaine 430 Sadness: 57 Death: 5\n",
            "Timesteps: 484205 Ep_Number: 502 Reward: -1087.71 Cocaine: 0 Mild_Cocaine 261 Sadness: 26 Death: 713\n",
            "Timesteps: 485205 Ep_Number: 503 Reward: -488.76 Cocaine: 0 Mild_Cocaine 486 Sadness: 319 Death: 195\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -330.250000\n",
            "---------------------------------------\n",
            "Timesteps: 486205 Ep_Number: 504 Reward: -251.94 Cocaine: 0 Mild_Cocaine 744 Sadness: 155 Death: 101\n",
            "Timesteps: 487205 Ep_Number: 505 Reward: -478.03 Cocaine: 0 Mild_Cocaine 553 Sadness: 220 Death: 227\n",
            "Timesteps: 488205 Ep_Number: 506 Reward: -135.84 Cocaine: 0 Mild_Cocaine 834 Sadness: 135 Death: 31\n",
            "Timesteps: 489205 Ep_Number: 507 Reward: -400.30 Cocaine: 0 Mild_Cocaine 520 Sadness: 361 Death: 119\n",
            "Timesteps: 490205 Ep_Number: 508 Reward: -923.64 Cocaine: 0 Mild_Cocaine 324 Sadness: 104 Death: 572\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -430.313000\n",
            "---------------------------------------\n",
            "Timesteps: 491205 Ep_Number: 509 Reward: -316.66 Cocaine: 0 Mild_Cocaine 616 Sadness: 295 Death: 89\n",
            "Timesteps: 491859 Ep_Number: 510 Reward: -89.75 Cocaine: 1 Mild_Cocaine 565 Sadness: 51 Death: 37\n",
            "Timesteps: 492859 Ep_Number: 511 Reward: -305.49 Cocaine: 0 Mild_Cocaine 519 Sadness: 468 Death: 13\n",
            "Timesteps: 493859 Ep_Number: 512 Reward: -540.76 Cocaine: 0 Mild_Cocaine 436 Sadness: 344 Death: 220\n",
            "Timesteps: 494859 Ep_Number: 513 Reward: -167.73 Cocaine: 0 Mild_Cocaine 873 Sadness: 35 Death: 92\n",
            "Timesteps: 495430 Ep_Number: 514 Reward: -113.62 Cocaine: 1 Mild_Cocaine 402 Sadness: 156 Death: 12\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -324.982000\n",
            "---------------------------------------\n",
            "Timesteps: 496430 Ep_Number: 515 Reward: -761.48 Cocaine: 0 Mild_Cocaine 338 Sadness: 261 Death: 401\n",
            "Timesteps: 497430 Ep_Number: 516 Reward: -347.59 Cocaine: 0 Mild_Cocaine 469 Sadness: 504 Death: 27\n",
            "Timesteps: 498430 Ep_Number: 517 Reward: -258.51 Cocaine: 0 Mild_Cocaine 591 Sadness: 401 Death: 8\n",
            "Timesteps: 499430 Ep_Number: 518 Reward: -267.64 Cocaine: 0 Mild_Cocaine 574 Sadness: 419 Death: 7\n",
            "Timesteps: 500159 Ep_Number: 519 Reward: -56.14 Cocaine: 1 Mild_Cocaine 654 Sadness: 66 Death: 8\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -495.158000\n",
            "---------------------------------------\n",
            "Timesteps: 501159 Ep_Number: 520 Reward: -574.73 Cocaine: 0 Mild_Cocaine 473 Sadness: 245 Death: 282\n",
            "Timesteps: 502159 Ep_Number: 521 Reward: -407.70 Cocaine: 0 Mild_Cocaine 570 Sadness: 270 Death: 160\n",
            "Timesteps: 503159 Ep_Number: 522 Reward: -417.30 Cocaine: 0 Mild_Cocaine 540 Sadness: 309 Death: 151\n",
            "Timesteps: 504159 Ep_Number: 523 Reward: -423.65 Cocaine: 0 Mild_Cocaine 485 Sadness: 393 Death: 122\n",
            "Timesteps: 505159 Ep_Number: 524 Reward: -1314.47 Cocaine: 0 Mild_Cocaine 107 Sadness: 29 Death: 864\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -501.893000\n",
            "---------------------------------------\n",
            "Timesteps: 506159 Ep_Number: 525 Reward: -351.11 Cocaine: 0 Mild_Cocaine 521 Sadness: 414 Death: 65\n",
            "Timesteps: 507130 Ep_Number: 526 Reward: -75.60 Cocaine: 1 Mild_Cocaine 890 Sadness: 57 Death: 23\n",
            "Timesteps: 508130 Ep_Number: 527 Reward: -211.92 Cocaine: 0 Mild_Cocaine 702 Sadness: 269 Death: 29\n",
            "Timesteps: 509130 Ep_Number: 528 Reward: -327.45 Cocaine: 0 Mild_Cocaine 555 Sadness: 384 Death: 61\n",
            "Timesteps: 510130 Ep_Number: 529 Reward: -181.78 Cocaine: 0 Mild_Cocaine 808 Sadness: 127 Death: 65\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -353.703000\n",
            "---------------------------------------\n",
            "Timesteps: 511130 Ep_Number: 530 Reward: -332.83 Cocaine: 0 Mild_Cocaine 523 Sadness: 431 Death: 46\n",
            "Timesteps: 512130 Ep_Number: 531 Reward: -345.73 Cocaine: 0 Mild_Cocaine 463 Sadness: 516 Death: 21\n",
            "Timesteps: 513130 Ep_Number: 532 Reward: -362.56 Cocaine: 0 Mild_Cocaine 526 Sadness: 393 Death: 81\n",
            "Timesteps: 514130 Ep_Number: 533 Reward: -233.66 Cocaine: 0 Mild_Cocaine 656 Sadness: 321 Death: 23\n",
            "Timesteps: 515130 Ep_Number: 534 Reward: -349.55 Cocaine: 0 Mild_Cocaine 545 Sadness: 376 Death: 79\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -284.397000\n",
            "---------------------------------------\n",
            "Timesteps: 515951 Ep_Number: 535 Reward: -146.92 Cocaine: 1 Mild_Cocaine 612 Sadness: 188 Death: 20\n",
            "Timesteps: 516681 Ep_Number: 536 Reward: -108.81 Cocaine: 1 Mild_Cocaine 581 Sadness: 130 Death: 18\n",
            "Timesteps: 517636 Ep_Number: 537 Reward: -94.44 Cocaine: 1 Mild_Cocaine 854 Sadness: 69 Death: 31\n",
            "Timesteps: 518636 Ep_Number: 538 Reward: -161.43 Cocaine: 0 Mild_Cocaine 873 Sadness: 42 Death: 85\n",
            "Timesteps: 519507 Ep_Number: 539 Reward: -183.21 Cocaine: 1 Mild_Cocaine 641 Sadness: 183 Death: 46\n",
            "Timesteps: 520507 Ep_Number: 540 Reward: -420.48 Cocaine: 0 Mild_Cocaine 588 Sadness: 226 Death: 186\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -274.231000\n",
            "---------------------------------------\n",
            "Timesteps: 521507 Ep_Number: 541 Reward: -251.01 Cocaine: 0 Mild_Cocaine 741 Sadness: 161 Death: 98\n",
            "Timesteps: 522507 Ep_Number: 542 Reward: -144.15 Cocaine: 0 Mild_Cocaine 855 Sadness: 91 Death: 54\n",
            "Timesteps: 523507 Ep_Number: 543 Reward: -342.15 Cocaine: 0 Mild_Cocaine 675 Sadness: 169 Death: 156\n",
            "Timesteps: 524019 Ep_Number: 544 Reward: -128.77 Cocaine: 1 Mild_Cocaine 327 Sadness: 165 Death: 19\n",
            "Timesteps: 525019 Ep_Number: 545 Reward: -1279.84 Cocaine: 0 Mild_Cocaine 94 Sadness: 89 Death: 817\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -262.005000\n",
            "---------------------------------------\n",
            "Timesteps: 526019 Ep_Number: 546 Reward: -369.48 Cocaine: 0 Mild_Cocaine 528 Sadness: 382 Death: 90\n",
            "Timesteps: 527019 Ep_Number: 547 Reward: -197.80 Cocaine: 0 Mild_Cocaine 700 Sadness: 288 Death: 12\n",
            "Timesteps: 527358 Ep_Number: 548 Reward: -193.63 Cocaine: 1 Mild_Cocaine 183 Sadness: 43 Death: 112\n",
            "Timesteps: 528358 Ep_Number: 549 Reward: -1016.74 Cocaine: 0 Mild_Cocaine 244 Sadness: 133 Death: 623\n",
            "Timesteps: 529358 Ep_Number: 550 Reward: -503.22 Cocaine: 0 Mild_Cocaine 492 Sadness: 293 Death: 215\n",
            "Timesteps: 530358 Ep_Number: 551 Reward: -344.08 Cocaine: 0 Mild_Cocaine 568 Sadness: 344 Death: 88\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -355.816000\n",
            "---------------------------------------\n",
            "Timesteps: 531075 Ep_Number: 552 Reward: -41.27 Cocaine: 1 Mild_Cocaine 667 Sadness: 41 Death: 8\n",
            "Timesteps: 531861 Ep_Number: 553 Reward: -135.45 Cocaine: 1 Mild_Cocaine 605 Sadness: 154 Death: 26\n",
            "Timesteps: 532861 Ep_Number: 554 Reward: -727.17 Cocaine: 0 Mild_Cocaine 387 Sadness: 218 Death: 395\n",
            "Timesteps: 533861 Ep_Number: 555 Reward: -272.17 Cocaine: 0 Mild_Cocaine 577 Sadness: 409 Death: 14\n",
            "Timesteps: 534861 Ep_Number: 556 Reward: -366.73 Cocaine: 0 Mild_Cocaine 493 Sadness: 443 Death: 64\n",
            "Timesteps: 535861 Ep_Number: 557 Reward: -1261.20 Cocaine: 0 Mild_Cocaine 150 Sadness: 17 Death: 833\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -522.525000\n",
            "---------------------------------------\n",
            "Timesteps: 536861 Ep_Number: 558 Reward: -249.05 Cocaine: 0 Mild_Cocaine 665 Sadness: 289 Death: 46\n",
            "Timesteps: 537861 Ep_Number: 559 Reward: -429.96 Cocaine: 0 Mild_Cocaine 636 Sadness: 136 Death: 228\n",
            "Timesteps: 538861 Ep_Number: 560 Reward: -464.43 Cocaine: 0 Mild_Cocaine 483 Sadness: 351 Death: 166\n",
            "Timesteps: 539861 Ep_Number: 561 Reward: -533.28 Cocaine: 0 Mild_Cocaine 438 Sadness: 349 Death: 213\n",
            "Timesteps: 540561 Ep_Number: 562 Reward: -180.18 Cocaine: 1 Mild_Cocaine 428 Sadness: 254 Death: 17\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -636.637000\n",
            "---------------------------------------\n",
            "Timesteps: 541561 Ep_Number: 563 Reward: -350.75 Cocaine: 0 Mild_Cocaine 575 Sadness: 325 Death: 100\n",
            "Timesteps: 542561 Ep_Number: 564 Reward: -587.70 Cocaine: 0 Mild_Cocaine 480 Sadness: 219 Death: 301\n",
            "Timesteps: 543561 Ep_Number: 565 Reward: -532.55 Cocaine: 0 Mild_Cocaine 395 Sadness: 421 Death: 184\n",
            "Timesteps: 544561 Ep_Number: 566 Reward: -208.42 Cocaine: 0 Mild_Cocaine 682 Sadness: 306 Death: 12\n",
            "Timesteps: 545561 Ep_Number: 567 Reward: -414.60 Cocaine: 0 Mild_Cocaine 450 Sadness: 461 Death: 89\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -542.571000\n",
            "---------------------------------------\n",
            "Timesteps: 546561 Ep_Number: 568 Reward: -564.66 Cocaine: 0 Mild_Cocaine 426 Sadness: 334 Death: 240\n",
            "Timesteps: 547561 Ep_Number: 569 Reward: -314.13 Cocaine: 0 Mild_Cocaine 573 Sadness: 369 Death: 58\n",
            "Timesteps: 548561 Ep_Number: 570 Reward: -734.86 Cocaine: 0 Mild_Cocaine 316 Sadness: 327 Death: 357\n",
            "Timesteps: 549561 Ep_Number: 571 Reward: -525.93 Cocaine: 0 Mild_Cocaine 423 Sadness: 382 Death: 195\n",
            "Timesteps: 550561 Ep_Number: 572 Reward: -281.70 Cocaine: 0 Mild_Cocaine 570 Sadness: 410 Death: 20\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -425.646000\n",
            "---------------------------------------\n",
            "Timesteps: 551561 Ep_Number: 573 Reward: -588.22 Cocaine: 0 Mild_Cocaine 412 Sadness: 331 Death: 257\n",
            "Timesteps: 552561 Ep_Number: 574 Reward: -399.61 Cocaine: 0 Mild_Cocaine 541 Sadness: 327 Death: 132\n",
            "Timesteps: 553561 Ep_Number: 575 Reward: -393.28 Cocaine: 0 Mild_Cocaine 718 Sadness: 41 Death: 241\n",
            "Timesteps: 554561 Ep_Number: 576 Reward: -288.10 Cocaine: 0 Mild_Cocaine 550 Sadness: 436 Death: 14\n",
            "Timesteps: 555561 Ep_Number: 577 Reward: -280.07 Cocaine: 0 Mild_Cocaine 617 Sadness: 334 Death: 49\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -514.878000\n",
            "---------------------------------------\n",
            "Timesteps: 556153 Ep_Number: 578 Reward: -66.47 Cocaine: 1 Mild_Cocaine 517 Sadness: 53 Death: 21\n",
            "Timesteps: 557009 Ep_Number: 579 Reward: -155.60 Cocaine: 1 Mild_Cocaine 700 Sadness: 91 Death: 64\n",
            "Timesteps: 558009 Ep_Number: 580 Reward: -1168.48 Cocaine: 0 Mild_Cocaine 208 Sadness: 24 Death: 768\n",
            "Timesteps: 559009 Ep_Number: 581 Reward: -547.65 Cocaine: 0 Mild_Cocaine 435 Sadness: 338 Death: 227\n",
            "Timesteps: 560009 Ep_Number: 582 Reward: -681.67 Cocaine: 0 Mild_Cocaine 397 Sadness: 252 Death: 351\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -297.036000\n",
            "---------------------------------------\n",
            "Timesteps: 561009 Ep_Number: 583 Reward: -299.84 Cocaine: 0 Mild_Cocaine 524 Sadness: 466 Death: 10\n",
            "Timesteps: 562009 Ep_Number: 584 Reward: -350.14 Cocaine: 0 Mild_Cocaine 544 Sadness: 377 Death: 79\n",
            "Timesteps: 563009 Ep_Number: 585 Reward: -304.03 Cocaine: 0 Mild_Cocaine 523 Sadness: 463 Death: 14\n",
            "Timesteps: 564009 Ep_Number: 586 Reward: -448.48 Cocaine: 0 Mild_Cocaine 568 Sadness: 228 Death: 204\n",
            "Timesteps: 565009 Ep_Number: 587 Reward: -316.98 Cocaine: 0 Mild_Cocaine 588 Sadness: 341 Death: 71\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -475.235000\n",
            "---------------------------------------\n",
            "Timesteps: 566009 Ep_Number: 588 Reward: -341.79 Cocaine: 0 Mild_Cocaine 459 Sadness: 527 Death: 14\n",
            "Timesteps: 567009 Ep_Number: 589 Reward: -281.23 Cocaine: 0 Mild_Cocaine 583 Sadness: 389 Death: 28\n",
            "Timesteps: 568009 Ep_Number: 590 Reward: -281.02 Cocaine: 0 Mild_Cocaine 562 Sadness: 424 Death: 14\n",
            "Timesteps: 568741 Ep_Number: 591 Reward: -159.20 Cocaine: 1 Mild_Cocaine 580 Sadness: 79 Death: 72\n",
            "Timesteps: 569741 Ep_Number: 592 Reward: -397.34 Cocaine: 0 Mild_Cocaine 554 Sadness: 308 Death: 138\n",
            "Timesteps: 570741 Ep_Number: 593 Reward: -304.55 Cocaine: 0 Mild_Cocaine 545 Sadness: 426 Death: 29\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -284.517000\n",
            "---------------------------------------\n",
            "Timesteps: 571741 Ep_Number: 594 Reward: -293.93 Cocaine: 0 Mild_Cocaine 563 Sadness: 408 Death: 29\n",
            "Timesteps: 572741 Ep_Number: 595 Reward: -552.10 Cocaine: 0 Mild_Cocaine 490 Sadness: 242 Death: 268\n",
            "Timesteps: 573741 Ep_Number: 596 Reward: -210.26 Cocaine: 0 Mild_Cocaine 746 Sadness: 198 Death: 56\n",
            "Timesteps: 574741 Ep_Number: 597 Reward: -233.98 Cocaine: 0 Mild_Cocaine 628 Sadness: 367 Death: 5\n",
            "Timesteps: 575741 Ep_Number: 598 Reward: -281.97 Cocaine: 0 Mild_Cocaine 597 Sadness: 365 Death: 38\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -393.647000\n",
            "---------------------------------------\n",
            "Timesteps: 576741 Ep_Number: 599 Reward: -294.15 Cocaine: 0 Mild_Cocaine 555 Sadness: 421 Death: 24\n",
            "Timesteps: 577741 Ep_Number: 600 Reward: -303.77 Cocaine: 0 Mild_Cocaine 647 Sadness: 258 Death: 95\n",
            "Timesteps: 578280 Ep_Number: 601 Reward: -82.82 Cocaine: 1 Mild_Cocaine 472 Sadness: 21 Death: 45\n",
            "Timesteps: 579280 Ep_Number: 602 Reward: -305.52 Cocaine: 0 Mild_Cocaine 612 Sadness: 314 Death: 74\n",
            "Timesteps: 580280 Ep_Number: 603 Reward: -226.05 Cocaine: 0 Mild_Cocaine 675 Sadness: 298 Death: 27\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -405.401000\n",
            "---------------------------------------\n",
            "Timesteps: 581280 Ep_Number: 604 Reward: -298.59 Cocaine: 0 Mild_Cocaine 639 Sadness: 277 Death: 84\n",
            "Timesteps: 581649 Ep_Number: 605 Reward: -28.13 Cocaine: 1 Mild_Cocaine 343 Sadness: 12 Death: 13\n",
            "Timesteps: 582649 Ep_Number: 606 Reward: -543.76 Cocaine: 0 Mild_Cocaine 466 Sadness: 291 Death: 243\n",
            "Timesteps: 583150 Ep_Number: 607 Reward: -28.37 Cocaine: 1 Mild_Cocaine 457 Sadness: 43 Death: 0\n",
            "Timesteps: 584150 Ep_Number: 608 Reward: -832.50 Cocaine: 0 Mild_Cocaine 390 Sadness: 96 Death: 514\n",
            "Timesteps: 585150 Ep_Number: 609 Reward: -367.82 Cocaine: 0 Mild_Cocaine 572 Sadness: 311 Death: 117\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -285.441000\n",
            "---------------------------------------\n",
            "Timesteps: 586150 Ep_Number: 610 Reward: -78.37 Cocaine: 0 Mild_Cocaine 907 Sadness: 78 Death: 15\n",
            "Timesteps: 587150 Ep_Number: 611 Reward: -404.72 Cocaine: 0 Mild_Cocaine 482 Sadness: 419 Death: 99\n",
            "Timesteps: 588150 Ep_Number: 612 Reward: -574.80 Cocaine: 0 Mild_Cocaine 450 Sadness: 283 Death: 267\n",
            "Timesteps: 589150 Ep_Number: 613 Reward: -425.39 Cocaine: 0 Mild_Cocaine 479 Sadness: 401 Death: 120\n",
            "Timesteps: 590150 Ep_Number: 614 Reward: -280.82 Cocaine: 0 Mild_Cocaine 602 Sadness: 358 Death: 40\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -329.766000\n",
            "---------------------------------------\n",
            "Timesteps: 591150 Ep_Number: 615 Reward: -316.14 Cocaine: 0 Mild_Cocaine 504 Sadness: 481 Death: 15\n",
            "Timesteps: 591321 Ep_Number: 616 Reward: -129.92 Cocaine: 1 Mild_Cocaine 82 Sadness: 1 Death: 87\n",
            "Timesteps: 591995 Ep_Number: 617 Reward: -95.53 Cocaine: 1 Mild_Cocaine 603 Sadness: 15 Death: 55\n",
            "Timesteps: 592995 Ep_Number: 618 Reward: -499.51 Cocaine: 0 Mild_Cocaine 541 Sadness: 216 Death: 243\n",
            "Timesteps: 593995 Ep_Number: 619 Reward: -363.44 Cocaine: 0 Mild_Cocaine 584 Sadness: 296 Death: 120\n",
            "Timesteps: 594995 Ep_Number: 620 Reward: -126.91 Cocaine: 0 Mild_Cocaine 811 Sadness: 183 Death: 6\n",
            "Timesteps: 595995 Ep_Number: 621 Reward: -225.68 Cocaine: 0 Mild_Cocaine 668 Sadness: 310 Death: 22\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -496.630000\n",
            "---------------------------------------\n",
            "Timesteps: 596995 Ep_Number: 622 Reward: -409.19 Cocaine: 0 Mild_Cocaine 659 Sadness: 121 Death: 220\n",
            "Timesteps: 597995 Ep_Number: 623 Reward: -458.24 Cocaine: 0 Mild_Cocaine 524 Sadness: 290 Death: 186\n",
            "Timesteps: 598995 Ep_Number: 624 Reward: -1005.09 Cocaine: 0 Mild_Cocaine 279 Sadness: 88 Death: 633\n",
            "Timesteps: 599995 Ep_Number: 625 Reward: -1305.68 Cocaine: 0 Mild_Cocaine 128 Sadness: 4 Death: 868\n",
            "Timesteps: 600995 Ep_Number: 626 Reward: -432.46 Cocaine: 0 Mild_Cocaine 496 Sadness: 365 Death: 139\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -362.345000\n",
            "---------------------------------------\n",
            "Timesteps: 601995 Ep_Number: 627 Reward: -502.28 Cocaine: 0 Mild_Cocaine 518 Sadness: 251 Death: 231\n",
            "Timesteps: 602995 Ep_Number: 628 Reward: -321.08 Cocaine: 0 Mild_Cocaine 578 Sadness: 353 Death: 69\n",
            "Timesteps: 603995 Ep_Number: 629 Reward: -991.99 Cocaine: 0 Mild_Cocaine 289 Sadness: 86 Death: 625\n",
            "Timesteps: 604995 Ep_Number: 630 Reward: -330.57 Cocaine: 0 Mild_Cocaine 597 Sadness: 311 Death: 92\n",
            "Timesteps: 605995 Ep_Number: 631 Reward: -643.43 Cocaine: 0 Mild_Cocaine 503 Sadness: 119 Death: 378\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -370.252000\n",
            "---------------------------------------\n",
            "Timesteps: 606995 Ep_Number: 632 Reward: -1195.69 Cocaine: 0 Mild_Cocaine 139 Sadness: 108 Death: 753\n",
            "Timesteps: 607995 Ep_Number: 633 Reward: -119.94 Cocaine: 0 Mild_Cocaine 864 Sadness: 103 Death: 33\n",
            "Timesteps: 608995 Ep_Number: 634 Reward: -413.73 Cocaine: 0 Mild_Cocaine 453 Sadness: 457 Death: 90\n",
            "Timesteps: 609995 Ep_Number: 635 Reward: -366.23 Cocaine: 0 Mild_Cocaine 593 Sadness: 278 Death: 129\n",
            "Timesteps: 610995 Ep_Number: 636 Reward: -388.52 Cocaine: 0 Mild_Cocaine 482 Sadness: 437 Death: 81\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -494.680000\n",
            "---------------------------------------\n",
            "Timesteps: 611995 Ep_Number: 637 Reward: -146.16 Cocaine: 0 Mild_Cocaine 786 Sadness: 203 Death: 11\n",
            "Timesteps: 612995 Ep_Number: 638 Reward: -305.84 Cocaine: 0 Mild_Cocaine 584 Sadness: 360 Death: 56\n",
            "Timesteps: 613916 Ep_Number: 639 Reward: -165.31 Cocaine: 1 Mild_Cocaine 681 Sadness: 220 Death: 19\n",
            "Timesteps: 614916 Ep_Number: 640 Reward: -388.84 Cocaine: 0 Mild_Cocaine 544 Sadness: 334 Death: 122\n",
            "Timesteps: 615916 Ep_Number: 641 Reward: -549.40 Cocaine: 0 Mild_Cocaine 580 Sadness: 96 Death: 324\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -619.555000\n",
            "---------------------------------------\n",
            "Timesteps: 616916 Ep_Number: 642 Reward: -347.31 Cocaine: 0 Mild_Cocaine 471 Sadness: 501 Death: 28\n",
            "Timesteps: 617916 Ep_Number: 643 Reward: -391.91 Cocaine: 0 Mild_Cocaine 551 Sadness: 319 Death: 130\n",
            "Timesteps: 618916 Ep_Number: 644 Reward: -305.77 Cocaine: 0 Mild_Cocaine 517 Sadness: 471 Death: 12\n",
            "Timesteps: 619916 Ep_Number: 645 Reward: -268.80 Cocaine: 0 Mild_Cocaine 630 Sadness: 325 Death: 45\n",
            "Timesteps: 620916 Ep_Number: 646 Reward: -237.23 Cocaine: 0 Mild_Cocaine 653 Sadness: 322 Death: 25\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -228.339000\n",
            "---------------------------------------\n",
            "Timesteps: 621515 Ep_Number: 647 Reward: -49.15 Cocaine: 1 Mild_Cocaine 555 Sadness: 21 Death: 22\n",
            "Timesteps: 622515 Ep_Number: 648 Reward: -642.33 Cocaine: 0 Mild_Cocaine 273 Sadness: 501 Death: 226\n",
            "Timesteps: 623515 Ep_Number: 649 Reward: -277.58 Cocaine: 0 Mild_Cocaine 548 Sadness: 451 Death: 1\n",
            "Timesteps: 624515 Ep_Number: 650 Reward: -1317.45 Cocaine: 0 Mild_Cocaine 105 Sadness: 29 Death: 866\n",
            "Timesteps: 625515 Ep_Number: 651 Reward: -339.41 Cocaine: 0 Mild_Cocaine 611 Sadness: 278 Death: 111\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -313.213000\n",
            "---------------------------------------\n",
            "Timesteps: 626515 Ep_Number: 652 Reward: -365.06 Cocaine: 0 Mild_Cocaine 566 Sadness: 324 Death: 110\n",
            "Timesteps: 627361 Ep_Number: 653 Reward: -657.85 Cocaine: 1 Mild_Cocaine 345 Sadness: 104 Death: 396\n",
            "Timesteps: 628361 Ep_Number: 654 Reward: -309.19 Cocaine: 0 Mild_Cocaine 499 Sadness: 497 Death: 4\n",
            "Timesteps: 629361 Ep_Number: 655 Reward: -310.02 Cocaine: 0 Mild_Cocaine 522 Sadness: 458 Death: 20\n",
            "Timesteps: 630361 Ep_Number: 656 Reward: -296.34 Cocaine: 0 Mild_Cocaine 594 Sadness: 354 Death: 52\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -497.902000\n",
            "---------------------------------------\n",
            "Timesteps: 631361 Ep_Number: 657 Reward: -375.55 Cocaine: 0 Mild_Cocaine 475 Sadness: 463 Death: 62\n",
            "Timesteps: 632361 Ep_Number: 658 Reward: -658.21 Cocaine: 0 Mild_Cocaine 481 Sadness: 139 Death: 380\n",
            "Timesteps: 633361 Ep_Number: 659 Reward: -1346.66 Cocaine: 0 Mild_Cocaine 86 Sadness: 28 Death: 886\n",
            "Timesteps: 634361 Ep_Number: 660 Reward: -232.52 Cocaine: 0 Mild_Cocaine 632 Sadness: 362 Death: 6\n",
            "Timesteps: 635361 Ep_Number: 661 Reward: -260.72 Cocaine: 0 Mild_Cocaine 662 Sadness: 281 Death: 57\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -241.582000\n",
            "---------------------------------------\n",
            "Timesteps: 635630 Ep_Number: 662 Reward: -2.45 Cocaine: 1 Mild_Cocaine 265 Sadness: 3 Death: 0\n",
            "Timesteps: 636630 Ep_Number: 663 Reward: -375.59 Cocaine: 0 Mild_Cocaine 539 Sadness: 357 Death: 104\n",
            "Timesteps: 637630 Ep_Number: 664 Reward: -219.66 Cocaine: 0 Mild_Cocaine 666 Sadness: 320 Death: 14\n",
            "Timesteps: 638630 Ep_Number: 665 Reward: -323.21 Cocaine: 0 Mild_Cocaine 611 Sadness: 296 Death: 93\n",
            "Timesteps: 639630 Ep_Number: 666 Reward: -368.85 Cocaine: 0 Mild_Cocaine 555 Sadness: 338 Death: 107\n",
            "Timesteps: 640630 Ep_Number: 667 Reward: -271.12 Cocaine: 0 Mild_Cocaine 652 Sadness: 286 Death: 62\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -348.572000\n",
            "---------------------------------------\n",
            "Timesteps: 640904 Ep_Number: 668 Reward: -12.03 Cocaine: 1 Mild_Cocaine 263 Sadness: 4 Death: 6\n",
            "Timesteps: 641904 Ep_Number: 669 Reward: -468.76 Cocaine: 0 Mild_Cocaine 436 Sadness: 424 Death: 140\n",
            "Timesteps: 642904 Ep_Number: 670 Reward: -342.09 Cocaine: 0 Mild_Cocaine 489 Sadness: 477 Death: 34\n",
            "Timesteps: 643904 Ep_Number: 671 Reward: -362.59 Cocaine: 0 Mild_Cocaine 529 Sadness: 388 Death: 83\n",
            "Timesteps: 644904 Ep_Number: 672 Reward: -507.33 Cocaine: 0 Mild_Cocaine 453 Sadness: 353 Death: 194\n",
            "Timesteps: 645904 Ep_Number: 673 Reward: -341.99 Cocaine: 0 Mild_Cocaine 599 Sadness: 295 Death: 106\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -577.815000\n",
            "---------------------------------------\n",
            "Timesteps: 646904 Ep_Number: 674 Reward: -314.84 Cocaine: 0 Mild_Cocaine 494 Sadness: 499 Death: 7\n",
            "Timesteps: 647904 Ep_Number: 675 Reward: -404.19 Cocaine: 0 Mild_Cocaine 579 Sadness: 259 Death: 162\n",
            "Timesteps: 648904 Ep_Number: 676 Reward: -773.17 Cocaine: 0 Mild_Cocaine 367 Sadness: 200 Death: 433\n",
            "Timesteps: 649904 Ep_Number: 677 Reward: -395.36 Cocaine: 0 Mild_Cocaine 626 Sadness: 191 Death: 183\n",
            "Timesteps: 650904 Ep_Number: 678 Reward: -792.00 Cocaine: 0 Mild_Cocaine 390 Sadness: 141 Death: 469\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -403.657000\n",
            "---------------------------------------\n",
            "Timesteps: 651904 Ep_Number: 679 Reward: -313.77 Cocaine: 0 Mild_Cocaine 537 Sadness: 429 Death: 34\n",
            "Timesteps: 652904 Ep_Number: 680 Reward: -281.96 Cocaine: 0 Mild_Cocaine 626 Sadness: 317 Death: 57\n",
            "Timesteps: 653904 Ep_Number: 681 Reward: -1094.86 Cocaine: 0 Mild_Cocaine 226 Sadness: 76 Death: 698\n",
            "Timesteps: 654904 Ep_Number: 682 Reward: -352.25 Cocaine: 0 Mild_Cocaine 455 Sadness: 522 Death: 23\n",
            "Timesteps: 655904 Ep_Number: 683 Reward: -589.89 Cocaine: 0 Mild_Cocaine 429 Sadness: 301 Death: 270\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -420.694000\n",
            "---------------------------------------\n",
            "Timesteps: 656904 Ep_Number: 684 Reward: -539.91 Cocaine: 0 Mild_Cocaine 381 Sadness: 436 Death: 183\n",
            "Timesteps: 657662 Ep_Number: 685 Reward: -154.74 Cocaine: 1 Mild_Cocaine 524 Sadness: 220 Death: 13\n",
            "Timesteps: 658662 Ep_Number: 686 Reward: -271.53 Cocaine: 0 Mild_Cocaine 633 Sadness: 317 Death: 50\n",
            "Timesteps: 659662 Ep_Number: 687 Reward: -622.79 Cocaine: 0 Mild_Cocaine 419 Sadness: 281 Death: 300\n",
            "Timesteps: 660662 Ep_Number: 688 Reward: -252.75 Cocaine: 0 Mild_Cocaine 645 Sadness: 318 Death: 37\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -276.247000\n",
            "---------------------------------------\n",
            "Timesteps: 661662 Ep_Number: 689 Reward: -144.67 Cocaine: 0 Mild_Cocaine 787 Sadness: 203 Death: 10\n",
            "Timesteps: 662662 Ep_Number: 690 Reward: -371.03 Cocaine: 0 Mild_Cocaine 443 Sadness: 521 Death: 36\n",
            "Timesteps: 663662 Ep_Number: 691 Reward: -243.14 Cocaine: 0 Mild_Cocaine 614 Sadness: 380 Death: 6\n",
            "Timesteps: 664662 Ep_Number: 692 Reward: -429.81 Cocaine: 0 Mild_Cocaine 441 Sadness: 459 Death: 100\n",
            "Timesteps: 665662 Ep_Number: 693 Reward: -377.98 Cocaine: 0 Mild_Cocaine 628 Sadness: 207 Death: 165\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -442.177000\n",
            "---------------------------------------\n",
            "Timesteps: 666662 Ep_Number: 694 Reward: -354.54 Cocaine: 0 Mild_Cocaine 744 Sadness: 41 Death: 215\n",
            "Timesteps: 667662 Ep_Number: 695 Reward: -270.27 Cocaine: 0 Mild_Cocaine 597 Sadness: 378 Death: 25\n",
            "Timesteps: 668662 Ep_Number: 696 Reward: -466.25 Cocaine: 0 Mild_Cocaine 425 Sadness: 445 Death: 130\n",
            "Timesteps: 669662 Ep_Number: 697 Reward: -288.88 Cocaine: 0 Mild_Cocaine 538 Sadness: 455 Death: 7\n",
            "Timesteps: 670662 Ep_Number: 698 Reward: -363.04 Cocaine: 0 Mild_Cocaine 484 Sadness: 462 Death: 54\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -351.014000\n",
            "---------------------------------------\n",
            "Timesteps: 671662 Ep_Number: 699 Reward: -285.28 Cocaine: 0 Mild_Cocaine 538 Sadness: 459 Death: 3\n",
            "Timesteps: 672662 Ep_Number: 700 Reward: -363.54 Cocaine: 0 Mild_Cocaine 474 Sadness: 478 Death: 48\n",
            "Timesteps: 673662 Ep_Number: 701 Reward: -1328.26 Cocaine: 0 Mild_Cocaine 76 Sadness: 65 Death: 859\n",
            "Timesteps: 674662 Ep_Number: 702 Reward: -254.04 Cocaine: 0 Mild_Cocaine 684 Sadness: 252 Death: 64\n",
            "Timesteps: 675662 Ep_Number: 703 Reward: -293.57 Cocaine: 0 Mild_Cocaine 527 Sadness: 468 Death: 5\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -377.784000\n",
            "---------------------------------------\n",
            "Timesteps: 676662 Ep_Number: 704 Reward: -1031.57 Cocaine: 0 Mild_Cocaine 167 Sadness: 244 Death: 589\n",
            "Timesteps: 677662 Ep_Number: 705 Reward: -263.66 Cocaine: 0 Mild_Cocaine 596 Sadness: 387 Death: 17\n",
            "Timesteps: 678662 Ep_Number: 706 Reward: -296.52 Cocaine: 0 Mild_Cocaine 522 Sadness: 473 Death: 5\n",
            "Timesteps: 679662 Ep_Number: 707 Reward: -257.21 Cocaine: 0 Mild_Cocaine 581 Sadness: 419 Death: 0\n",
            "Timesteps: 680662 Ep_Number: 708 Reward: -321.54 Cocaine: 0 Mild_Cocaine 504 Sadness: 475 Death: 21\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -261.596000\n",
            "---------------------------------------\n",
            "Timesteps: 681662 Ep_Number: 709 Reward: -231.17 Cocaine: 0 Mild_Cocaine 677 Sadness: 289 Death: 34\n",
            "Timesteps: 682662 Ep_Number: 710 Reward: -619.40 Cocaine: 0 Mild_Cocaine 350 Sadness: 399 Death: 251\n",
            "Timesteps: 683662 Ep_Number: 711 Reward: -337.26 Cocaine: 0 Mild_Cocaine 456 Sadness: 537 Death: 7\n",
            "Timesteps: 684662 Ep_Number: 712 Reward: -150.51 Cocaine: 0 Mild_Cocaine 771 Sadness: 223 Death: 6\n",
            "Timesteps: 685662 Ep_Number: 713 Reward: -233.44 Cocaine: 0 Mild_Cocaine 664 Sadness: 308 Death: 28\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -419.148000\n",
            "---------------------------------------\n",
            "Timesteps: 686662 Ep_Number: 714 Reward: -478.99 Cocaine: 0 Mild_Cocaine 469 Sadness: 358 Death: 173\n",
            "Timesteps: 687662 Ep_Number: 715 Reward: -255.71 Cocaine: 0 Mild_Cocaine 611 Sadness: 371 Death: 18\n",
            "Timesteps: 688662 Ep_Number: 716 Reward: -292.36 Cocaine: 0 Mild_Cocaine 526 Sadness: 471 Death: 3\n",
            "Timesteps: 689662 Ep_Number: 717 Reward: -477.82 Cocaine: 0 Mild_Cocaine 442 Sadness: 404 Death: 154\n",
            "Timesteps: 690662 Ep_Number: 718 Reward: -1258.22 Cocaine: 0 Mild_Cocaine 152 Sadness: 17 Death: 831\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -319.088000\n",
            "---------------------------------------\n",
            "Timesteps: 691662 Ep_Number: 719 Reward: -353.83 Cocaine: 0 Mild_Cocaine 463 Sadness: 507 Death: 30\n",
            "Timesteps: 692662 Ep_Number: 720 Reward: -315.43 Cocaine: 0 Mild_Cocaine 583 Sadness: 351 Death: 66\n",
            "Timesteps: 693662 Ep_Number: 721 Reward: -1151.05 Cocaine: 0 Mild_Cocaine 175 Sadness: 98 Death: 727\n",
            "Timesteps: 694662 Ep_Number: 722 Reward: -245.90 Cocaine: 0 Mild_Cocaine 620 Sadness: 367 Death: 13\n",
            "Timesteps: 695662 Ep_Number: 723 Reward: -302.22 Cocaine: 0 Mild_Cocaine 552 Sadness: 417 Death: 31\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -372.756000\n",
            "---------------------------------------\n",
            "Timesteps: 696662 Ep_Number: 724 Reward: -286.64 Cocaine: 0 Mild_Cocaine 554 Sadness: 431 Death: 15\n",
            "Timesteps: 697662 Ep_Number: 725 Reward: -368.00 Cocaine: 0 Mild_Cocaine 410 Sadness: 579 Death: 11\n",
            "Timesteps: 698662 Ep_Number: 726 Reward: -162.57 Cocaine: 0 Mild_Cocaine 807 Sadness: 150 Death: 43\n",
            "Timesteps: 699662 Ep_Number: 727 Reward: -376.44 Cocaine: 0 Mild_Cocaine 684 Sadness: 116 Death: 200\n",
            "Timesteps: 700662 Ep_Number: 728 Reward: -265.42 Cocaine: 0 Mild_Cocaine 622 Sadness: 342 Death: 36\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -403.480000\n",
            "---------------------------------------\n",
            "Timesteps: 701662 Ep_Number: 729 Reward: -463.81 Cocaine: 0 Mild_Cocaine 481 Sadness: 355 Death: 164\n",
            "Timesteps: 702662 Ep_Number: 730 Reward: -332.48 Cocaine: 0 Mild_Cocaine 548 Sadness: 390 Death: 62\n",
            "Timesteps: 703662 Ep_Number: 731 Reward: -83.71 Cocaine: 0 Mild_Cocaine 901 Sadness: 82 Death: 17\n",
            "Timesteps: 704662 Ep_Number: 732 Reward: -563.43 Cocaine: 0 Mild_Cocaine 393 Sadness: 390 Death: 217\n",
            "Timesteps: 705662 Ep_Number: 733 Reward: -237.49 Cocaine: 0 Mild_Cocaine 619 Sadness: 378 Death: 3\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -363.133000\n",
            "---------------------------------------\n",
            "Timesteps: 706662 Ep_Number: 734 Reward: -422.78 Cocaine: 0 Mild_Cocaine 398 Sadness: 538 Death: 64\n",
            "Timesteps: 707662 Ep_Number: 735 Reward: -488.00 Cocaine: 0 Mild_Cocaine 440 Sadness: 396 Death: 164\n",
            "Timesteps: 708662 Ep_Number: 736 Reward: -350.55 Cocaine: 0 Mild_Cocaine 615 Sadness: 259 Death: 126\n",
            "Timesteps: 709662 Ep_Number: 737 Reward: -480.89 Cocaine: 0 Mild_Cocaine 539 Sadness: 240 Death: 221\n",
            "Timesteps: 710662 Ep_Number: 738 Reward: -310.70 Cocaine: 0 Mild_Cocaine 530 Sadness: 444 Death: 26\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -459.192000\n",
            "---------------------------------------\n",
            "Timesteps: 711657 Ep_Number: 739 Reward: -116.87 Cocaine: 1 Mild_Cocaine 817 Sadness: 172 Death: 5\n",
            "Timesteps: 712657 Ep_Number: 740 Reward: -567.78 Cocaine: 0 Mild_Cocaine 468 Sadness: 261 Death: 271\n",
            "Timesteps: 713657 Ep_Number: 741 Reward: -559.80 Cocaine: 0 Mild_Cocaine 300 Sadness: 548 Death: 152\n",
            "Timesteps: 714657 Ep_Number: 742 Reward: -329.92 Cocaine: 0 Mild_Cocaine 502 Sadness: 469 Death: 29\n",
            "Timesteps: 715657 Ep_Number: 743 Reward: -217.27 Cocaine: 0 Mild_Cocaine 667 Sadness: 321 Death: 12\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -366.971000\n",
            "---------------------------------------\n",
            "Timesteps: 716657 Ep_Number: 744 Reward: -210.38 Cocaine: 0 Mild_Cocaine 668 Sadness: 327 Death: 5\n",
            "Timesteps: 717657 Ep_Number: 745 Reward: -248.81 Cocaine: 0 Mild_Cocaine 641 Sadness: 329 Death: 30\n",
            "Timesteps: 718657 Ep_Number: 746 Reward: -475.95 Cocaine: 0 Mild_Cocaine 555 Sadness: 219 Death: 226\n",
            "Timesteps: 719657 Ep_Number: 747 Reward: -237.95 Cocaine: 0 Mild_Cocaine 635 Sadness: 351 Death: 14\n",
            "Timesteps: 720657 Ep_Number: 748 Reward: -270.16 Cocaine: 0 Mild_Cocaine 646 Sadness: 297 Death: 57\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -496.778000\n",
            "---------------------------------------\n",
            "Timesteps: 721657 Ep_Number: 749 Reward: -522.29 Cocaine: 0 Mild_Cocaine 449 Sadness: 343 Death: 208\n",
            "Timesteps: 722657 Ep_Number: 750 Reward: -241.15 Cocaine: 0 Mild_Cocaine 715 Sadness: 215 Death: 70\n",
            "Timesteps: 723657 Ep_Number: 751 Reward: -262.35 Cocaine: 0 Mild_Cocaine 615 Sadness: 357 Death: 28\n",
            "Timesteps: 724657 Ep_Number: 752 Reward: -197.78 Cocaine: 0 Mild_Cocaine 848 Sadness: 43 Death: 109\n",
            "Timesteps: 725657 Ep_Number: 753 Reward: -523.75 Cocaine: 0 Mild_Cocaine 445 Sadness: 348 Death: 207\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -402.643000\n",
            "---------------------------------------\n",
            "Timesteps: 726657 Ep_Number: 754 Reward: -1024.43 Cocaine: 0 Mild_Cocaine 173 Sadness: 242 Death: 585\n",
            "Timesteps: 727657 Ep_Number: 755 Reward: -1476.66 Cocaine: 0 Mild_Cocaine 6 Sadness: 16 Death: 978\n",
            "Timesteps: 728145 Ep_Number: 756 Reward: -48.17 Cocaine: 1 Mild_Cocaine 427 Sadness: 49 Death: 11\n",
            "Timesteps: 729145 Ep_Number: 757 Reward: -403.18 Cocaine: 0 Mild_Cocaine 538 Sadness: 328 Death: 134\n",
            "Timesteps: 730145 Ep_Number: 758 Reward: -250.40 Cocaine: 0 Mild_Cocaine 620 Sadness: 362 Death: 18\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -277.562000\n",
            "---------------------------------------\n",
            "Timesteps: 731145 Ep_Number: 759 Reward: -248.35 Cocaine: 0 Mild_Cocaine 625 Sadness: 356 Death: 19\n",
            "Timesteps: 732145 Ep_Number: 760 Reward: -358.65 Cocaine: 0 Mild_Cocaine 525 Sadness: 399 Death: 76\n",
            "Timesteps: 733145 Ep_Number: 761 Reward: -547.91 Cocaine: 0 Mild_Cocaine 491 Sadness: 245 Death: 264\n",
            "Timesteps: 734145 Ep_Number: 762 Reward: -372.27 Cocaine: 0 Mild_Cocaine 537 Sadness: 364 Death: 99\n",
            "Timesteps: 735145 Ep_Number: 763 Reward: -630.37 Cocaine: 0 Mild_Cocaine 397 Sadness: 309 Death: 294\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -368.345000\n",
            "---------------------------------------\n",
            "Timesteps: 736145 Ep_Number: 764 Reward: -238.98 Cocaine: 0 Mild_Cocaine 618 Sadness: 378 Death: 4\n",
            "Timesteps: 737145 Ep_Number: 765 Reward: -510.99 Cocaine: 0 Mild_Cocaine 549 Sadness: 190 Death: 261\n",
            "Timesteps: 738145 Ep_Number: 766 Reward: -1041.22 Cocaine: 0 Mild_Cocaine 82 Sadness: 374 Death: 544\n",
            "Timesteps: 739145 Ep_Number: 767 Reward: -109.72 Cocaine: 0 Mild_Cocaine 892 Sadness: 68 Death: 40\n",
            "Timesteps: 740145 Ep_Number: 768 Reward: -663.33 Cocaine: 0 Mild_Cocaine 393 Sadness: 279 Death: 328\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -230.241000\n",
            "---------------------------------------\n",
            "Timesteps: 741145 Ep_Number: 769 Reward: -1493.14 Cocaine: 0 Mild_Cocaine 4 Sadness: 1 Death: 995\n",
            "Timesteps: 742145 Ep_Number: 770 Reward: -158.22 Cocaine: 0 Mild_Cocaine 822 Sadness: 130 Death: 48\n",
            "Timesteps: 743145 Ep_Number: 771 Reward: -300.67 Cocaine: 0 Mild_Cocaine 637 Sadness: 278 Death: 85\n",
            "Timesteps: 743251 Ep_Number: 772 Reward: -19.60 Cocaine: 1 Mild_Cocaine 90 Sadness: 2 Death: 13\n",
            "Timesteps: 743742 Ep_Number: 773 Reward: -153.60 Cocaine: 1 Mild_Cocaine 320 Sadness: 114 Death: 56\n",
            "Timesteps: 744742 Ep_Number: 774 Reward: -263.17 Cocaine: 0 Mild_Cocaine 667 Sadness: 270 Death: 63\n",
            "Timesteps: 745742 Ep_Number: 775 Reward: -139.95 Cocaine: 0 Mild_Cocaine 885 Sadness: 46 Death: 69\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -292.483000\n",
            "---------------------------------------\n",
            "Timesteps: 746742 Ep_Number: 776 Reward: -439.33 Cocaine: 0 Mild_Cocaine 643 Sadness: 114 Death: 243\n",
            "Timesteps: 747478 Ep_Number: 777 Reward: -105.56 Cocaine: 1 Mild_Cocaine 646 Sadness: 36 Death: 53\n",
            "Timesteps: 748362 Ep_Number: 778 Reward: -614.82 Cocaine: 1 Mild_Cocaine 362 Sadness: 187 Death: 334\n",
            "Timesteps: 749362 Ep_Number: 779 Reward: -403.31 Cocaine: 0 Mild_Cocaine 611 Sadness: 207 Death: 182\n",
            "Timesteps: 750362 Ep_Number: 780 Reward: -463.70 Cocaine: 0 Mild_Cocaine 620 Sadness: 125 Death: 255\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -236.228000\n",
            "---------------------------------------\n",
            "Timesteps: 751362 Ep_Number: 781 Reward: -202.43 Cocaine: 0 Mild_Cocaine 683 Sadness: 311 Death: 6\n",
            "Timesteps: 752362 Ep_Number: 782 Reward: -230.56 Cocaine: 0 Mild_Cocaine 736 Sadness: 192 Death: 72\n",
            "Timesteps: 753362 Ep_Number: 783 Reward: -202.14 Cocaine: 0 Mild_Cocaine 714 Sadness: 260 Death: 26\n",
            "Timesteps: 754362 Ep_Number: 784 Reward: -707.04 Cocaine: 0 Mild_Cocaine 444 Sadness: 146 Death: 410\n",
            "Timesteps: 755362 Ep_Number: 785 Reward: -657.73 Cocaine: 0 Mild_Cocaine 433 Sadness: 219 Death: 348\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -250.998000\n",
            "---------------------------------------\n",
            "Timesteps: 756362 Ep_Number: 786 Reward: -278.60 Cocaine: 0 Mild_Cocaine 560 Sadness: 430 Death: 10\n",
            "Timesteps: 757072 Ep_Number: 787 Reward: -359.42 Cocaine: 1 Mild_Cocaine 412 Sadness: 98 Death: 199\n",
            "Timesteps: 757567 Ep_Number: 788 Reward: -6.48 Cocaine: 1 Mild_Cocaine 488 Sadness: 6 Death: 0\n",
            "Timesteps: 758117 Ep_Number: 789 Reward: -58.94 Cocaine: 1 Mild_Cocaine 484 Sadness: 46 Death: 19\n",
            "Timesteps: 759113 Ep_Number: 790 Reward: -236.80 Cocaine: 1 Mild_Cocaine 720 Sadness: 201 Death: 74\n",
            "Timesteps: 759963 Ep_Number: 791 Reward: -34.81 Cocaine: 1 Mild_Cocaine 801 Sadness: 48 Death: 0\n",
            "Timesteps: 760768 Ep_Number: 792 Reward: -303.92 Cocaine: 1 Mild_Cocaine 502 Sadness: 169 Death: 133\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -349.399000\n",
            "---------------------------------------\n",
            "Timesteps: 761749 Ep_Number: 793 Reward: -483.54 Cocaine: 1 Mild_Cocaine 584 Sadness: 127 Death: 269\n",
            "Timesteps: 762343 Ep_Number: 794 Reward: -147.01 Cocaine: 1 Mild_Cocaine 381 Sadness: 192 Death: 20\n",
            "Timesteps: 763291 Ep_Number: 795 Reward: -452.41 Cocaine: 1 Mild_Cocaine 501 Sadness: 244 Death: 202\n",
            "Timesteps: 764291 Ep_Number: 796 Reward: -329.81 Cocaine: 0 Mild_Cocaine 731 Sadness: 90 Death: 179\n",
            "Timesteps: 765291 Ep_Number: 797 Reward: -502.08 Cocaine: 0 Mild_Cocaine 468 Sadness: 334 Death: 198\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -228.288000\n",
            "---------------------------------------\n",
            "Timesteps: 765969 Ep_Number: 798 Reward: -530.23 Cocaine: 1 Mild_Cocaine 273 Sadness: 85 Death: 319\n",
            "Timesteps: 766969 Ep_Number: 799 Reward: -205.16 Cocaine: 0 Mild_Cocaine 776 Sadness: 154 Death: 70\n",
            "Timesteps: 767831 Ep_Number: 800 Reward: -416.79 Cocaine: 1 Mild_Cocaine 509 Sadness: 127 Death: 225\n",
            "Timesteps: 768831 Ep_Number: 801 Reward: -187.59 Cocaine: 0 Mild_Cocaine 699 Sadness: 301 Death: 0\n",
            "Timesteps: 769429 Ep_Number: 802 Reward: -108.02 Cocaine: 1 Mild_Cocaine 442 Sadness: 141 Death: 14\n",
            "Timesteps: 770429 Ep_Number: 803 Reward: -335.37 Cocaine: 0 Mild_Cocaine 717 Sadness: 107 Death: 176\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -370.443000\n",
            "---------------------------------------\n",
            "Timesteps: 771429 Ep_Number: 804 Reward: -1316.56 Cocaine: 0 Mild_Cocaine 76 Sadness: 78 Death: 846\n",
            "Timesteps: 772289 Ep_Number: 805 Reward: -568.97 Cocaine: 1 Mild_Cocaine 397 Sadness: 140 Death: 322\n",
            "Timesteps: 773289 Ep_Number: 806 Reward: -387.78 Cocaine: 0 Mild_Cocaine 558 Sadness: 312 Death: 130\n",
            "Timesteps: 774289 Ep_Number: 807 Reward: -227.21 Cocaine: 0 Mild_Cocaine 821 Sadness: 55 Death: 124\n",
            "Timesteps: 775289 Ep_Number: 808 Reward: -766.40 Cocaine: 0 Mild_Cocaine 380 Sadness: 186 Death: 434\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -539.985000\n",
            "---------------------------------------\n",
            "Timesteps: 776289 Ep_Number: 809 Reward: -295.39 Cocaine: 0 Mild_Cocaine 559 Sadness: 413 Death: 28\n",
            "Timesteps: 776961 Ep_Number: 810 Reward: -430.90 Cocaine: 1 Mild_Cocaine 330 Sadness: 91 Death: 250\n",
            "Timesteps: 777175 Ep_Number: 811 Reward: -31.98 Cocaine: 1 Mild_Cocaine 188 Sadness: 6 Death: 19\n",
            "Timesteps: 778175 Ep_Number: 812 Reward: -404.93 Cocaine: 0 Mild_Cocaine 683 Sadness: 86 Death: 231\n",
            "Timesteps: 779175 Ep_Number: 813 Reward: -393.22 Cocaine: 0 Mild_Cocaine 442 Sadness: 498 Death: 60\n",
            "Timesteps: 780175 Ep_Number: 814 Reward: -306.39 Cocaine: 0 Mild_Cocaine 699 Sadness: 169 Death: 132\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -238.022000\n",
            "---------------------------------------\n",
            "Timesteps: 781175 Ep_Number: 815 Reward: -1100.44 Cocaine: 0 Mild_Cocaine 244 Sadness: 40 Death: 716\n",
            "Timesteps: 781954 Ep_Number: 816 Reward: -240.77 Cocaine: 1 Mild_Cocaine 517 Sadness: 171 Death: 90\n",
            "Timesteps: 782954 Ep_Number: 817 Reward: -1244.94 Cocaine: 0 Mild_Cocaine 144 Sadness: 45 Death: 811\n",
            "Timesteps: 783954 Ep_Number: 818 Reward: -1230.27 Cocaine: 0 Mild_Cocaine 117 Sadness: 106 Death: 777\n",
            "Timesteps: 784954 Ep_Number: 819 Reward: -202.43 Cocaine: 0 Mild_Cocaine 683 Sadness: 311 Death: 6\n",
            "Timesteps: 785954 Ep_Number: 820 Reward: -494.45 Cocaine: 0 Mild_Cocaine 365 Sadness: 513 Death: 122\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -297.951000\n",
            "---------------------------------------\n",
            "Timesteps: 786768 Ep_Number: 821 Reward: -531.87 Cocaine: 1 Mild_Cocaine 317 Sadness: 237 Death: 259\n",
            "Timesteps: 787306 Ep_Number: 822 Reward: -188.03 Cocaine: 1 Mild_Cocaine 343 Sadness: 116 Death: 78\n",
            "Timesteps: 788161 Ep_Number: 823 Reward: -505.64 Cocaine: 1 Mild_Cocaine 394 Sadness: 207 Death: 253\n",
            "Timesteps: 789161 Ep_Number: 824 Reward: -199.98 Cocaine: 0 Mild_Cocaine 768 Sadness: 173 Death: 59\n",
            "Timesteps: 790161 Ep_Number: 825 Reward: -49.46 Cocaine: 0 Mild_Cocaine 956 Sadness: 29 Death: 15\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -384.685000\n",
            "---------------------------------------\n",
            "Timesteps: 791161 Ep_Number: 826 Reward: -436.48 Cocaine: 0 Mild_Cocaine 538 Sadness: 291 Death: 171\n",
            "Timesteps: 792161 Ep_Number: 827 Reward: -289.04 Cocaine: 0 Mild_Cocaine 704 Sadness: 180 Death: 116\n",
            "Timesteps: 793161 Ep_Number: 828 Reward: -310.93 Cocaine: 0 Mild_Cocaine 493 Sadness: 505 Death: 2\n",
            "Timesteps: 793593 Ep_Number: 829 Reward: -148.16 Cocaine: 1 Mild_Cocaine 286 Sadness: 78 Death: 67\n",
            "Timesteps: 794107 Ep_Number: 830 Reward: -184.93 Cocaine: 1 Mild_Cocaine 333 Sadness: 96 Death: 84\n",
            "Timesteps: 795107 Ep_Number: 831 Reward: -219.04 Cocaine: 0 Mild_Cocaine 754 Sadness: 175 Death: 71\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -457.591000\n",
            "---------------------------------------\n",
            "Timesteps: 796107 Ep_Number: 832 Reward: -379.64 Cocaine: 0 Mild_Cocaine 584 Sadness: 278 Death: 138\n",
            "Timesteps: 797107 Ep_Number: 833 Reward: -488.89 Cocaine: 0 Mild_Cocaine 559 Sadness: 198 Death: 243\n",
            "Timesteps: 798107 Ep_Number: 834 Reward: -434.87 Cocaine: 0 Mild_Cocaine 527 Sadness: 311 Death: 162\n",
            "Timesteps: 799107 Ep_Number: 835 Reward: -352.22 Cocaine: 0 Mild_Cocaine 542 Sadness: 378 Death: 80\n",
            "Timesteps: 799764 Ep_Number: 836 Reward: -185.90 Cocaine: 1 Mild_Cocaine 460 Sadness: 123 Death: 73\n",
            "Timesteps: 800764 Ep_Number: 837 Reward: -293.83 Cocaine: 0 Mild_Cocaine 673 Sadness: 226 Death: 101\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -255.515000\n",
            "---------------------------------------\n",
            "Timesteps: 801764 Ep_Number: 838 Reward: -438.21 Cocaine: 0 Mild_Cocaine 561 Sadness: 251 Death: 188\n",
            "Timesteps: 802764 Ep_Number: 839 Reward: -200.97 Cocaine: 0 Mild_Cocaine 687 Sadness: 306 Death: 7\n",
            "Timesteps: 803435 Ep_Number: 840 Reward: -232.15 Cocaine: 1 Mild_Cocaine 495 Sadness: 37 Death: 138\n",
            "Timesteps: 804435 Ep_Number: 841 Reward: -342.98 Cocaine: 0 Mild_Cocaine 698 Sadness: 130 Death: 172\n",
            "Timesteps: 805435 Ep_Number: 842 Reward: -273.53 Cocaine: 0 Mild_Cocaine 593 Sadness: 381 Death: 26\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -470.306000\n",
            "---------------------------------------\n",
            "Timesteps: 806263 Ep_Number: 843 Reward: -9.22 Cocaine: 1 Mild_Cocaine 822 Sadness: 5 Death: 0\n",
            "Timesteps: 807263 Ep_Number: 844 Reward: -1255.32 Cocaine: 0 Mild_Cocaine 102 Sadness: 103 Death: 795\n",
            "Timesteps: 808242 Ep_Number: 845 Reward: -265.12 Cocaine: 1 Mild_Cocaine 702 Sadness: 171 Death: 105\n",
            "Timesteps: 808382 Ep_Number: 846 Reward: -41.67 Cocaine: 1 Mild_Cocaine 107 Sadness: 6 Death: 26\n",
            "Timesteps: 809063 Ep_Number: 847 Reward: -423.68 Cocaine: 1 Mild_Cocaine 388 Sadness: 18 Death: 274\n",
            "Timesteps: 810063 Ep_Number: 848 Reward: -517.54 Cocaine: 0 Mild_Cocaine 544 Sadness: 191 Death: 265\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -380.848000\n",
            "---------------------------------------\n",
            "Timesteps: 810693 Ep_Number: 849 Reward: -359.20 Cocaine: 1 Mild_Cocaine 360 Sadness: 51 Death: 218\n",
            "Timesteps: 811693 Ep_Number: 850 Reward: -291.04 Cocaine: 0 Mild_Cocaine 664 Sadness: 244 Death: 92\n",
            "Timesteps: 812545 Ep_Number: 851 Reward: -187.56 Cocaine: 1 Mild_Cocaine 596 Sadness: 221 Death: 34\n",
            "Timesteps: 813545 Ep_Number: 852 Reward: -358.72 Cocaine: 0 Mild_Cocaine 502 Sadness: 437 Death: 61\n",
            "Timesteps: 814545 Ep_Number: 853 Reward: -522.55 Cocaine: 0 Mild_Cocaine 505 Sadness: 250 Death: 245\n",
            "Timesteps: 815545 Ep_Number: 854 Reward: -327.31 Cocaine: 0 Mild_Cocaine 601 Sadness: 308 Death: 91\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -410.776000\n",
            "---------------------------------------\n",
            "Timesteps: 816545 Ep_Number: 855 Reward: -191.68 Cocaine: 0 Mild_Cocaine 718 Sadness: 265 Death: 17\n",
            "Timesteps: 817545 Ep_Number: 856 Reward: -182.69 Cocaine: 0 Mild_Cocaine 779 Sadness: 174 Death: 47\n",
            "Timesteps: 818243 Ep_Number: 857 Reward: -141.03 Cocaine: 1 Mild_Cocaine 593 Sadness: 21 Death: 83\n",
            "Timesteps: 819243 Ep_Number: 858 Reward: -370.75 Cocaine: 0 Mild_Cocaine 625 Sadness: 220 Death: 155\n",
            "Timesteps: 820243 Ep_Number: 859 Reward: -310.24 Cocaine: 0 Mild_Cocaine 514 Sadness: 471 Death: 15\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -318.953000\n",
            "---------------------------------------\n",
            "Timesteps: 820389 Ep_Number: 860 Reward: -12.55 Cocaine: 1 Mild_Cocaine 135 Sadness: 2 Death: 8\n",
            "Timesteps: 821063 Ep_Number: 861 Reward: -169.26 Cocaine: 1 Mild_Cocaine 536 Sadness: 44 Death: 93\n",
            "Timesteps: 822063 Ep_Number: 862 Reward: -262.61 Cocaine: 0 Mild_Cocaine 761 Sadness: 115 Death: 124\n",
            "Timesteps: 823063 Ep_Number: 863 Reward: -279.56 Cocaine: 0 Mild_Cocaine 566 Sadness: 419 Death: 15\n",
            "Timesteps: 824063 Ep_Number: 864 Reward: -316.21 Cocaine: 0 Mild_Cocaine 481 Sadness: 519 Death: 0\n",
            "Timesteps: 825063 Ep_Number: 865 Reward: -315.25 Cocaine: 0 Mild_Cocaine 565 Sadness: 381 Death: 54\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -353.662000\n",
            "---------------------------------------\n",
            "Timesteps: 826063 Ep_Number: 866 Reward: -317.13 Cocaine: 0 Mild_Cocaine 603 Sadness: 316 Death: 81\n",
            "Timesteps: 826931 Ep_Number: 867 Reward: -171.26 Cocaine: 1 Mild_Cocaine 736 Sadness: 34 Death: 97\n",
            "Timesteps: 827645 Ep_Number: 868 Reward: -240.50 Cocaine: 1 Mild_Cocaine 520 Sadness: 58 Death: 135\n",
            "Timesteps: 828645 Ep_Number: 869 Reward: -251.79 Cocaine: 0 Mild_Cocaine 639 Sadness: 329 Death: 32\n",
            "Timesteps: 829562 Ep_Number: 870 Reward: -190.69 Cocaine: 1 Mild_Cocaine 759 Sadness: 56 Death: 101\n",
            "Timesteps: 830562 Ep_Number: 871 Reward: -344.08 Cocaine: 0 Mild_Cocaine 568 Sadness: 344 Death: 88\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -371.073000\n",
            "---------------------------------------\n",
            "Timesteps: 831562 Ep_Number: 872 Reward: -318.82 Cocaine: 0 Mild_Cocaine 652 Sadness: 233 Death: 115\n",
            "Timesteps: 832386 Ep_Number: 873 Reward: -407.99 Cocaine: 1 Mild_Cocaine 409 Sadness: 239 Death: 175\n",
            "Timesteps: 833386 Ep_Number: 874 Reward: -390.98 Cocaine: 0 Mild_Cocaine 548 Sadness: 325 Death: 127\n",
            "Timesteps: 833642 Ep_Number: 875 Reward: -291.94 Cocaine: 1 Mild_Cocaine 54 Sadness: 9 Death: 192\n",
            "Timesteps: 834167 Ep_Number: 876 Reward: -91.65 Cocaine: 1 Mild_Cocaine 455 Sadness: 16 Death: 53\n",
            "Timesteps: 835167 Ep_Number: 877 Reward: -363.39 Cocaine: 0 Mild_Cocaine 639 Sadness: 205 Death: 156\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -324.300000\n",
            "---------------------------------------\n",
            "Timesteps: 836167 Ep_Number: 878 Reward: -526.67 Cocaine: 0 Mild_Cocaine 527 Sadness: 209 Death: 264\n",
            "Timesteps: 837082 Ep_Number: 879 Reward: -225.50 Cocaine: 1 Mild_Cocaine 640 Sadness: 211 Death: 63\n",
            "Timesteps: 838082 Ep_Number: 880 Reward: -202.87 Cocaine: 0 Mild_Cocaine 847 Sadness: 39 Death: 114\n",
            "Timesteps: 838522 Ep_Number: 881 Reward: -91.65 Cocaine: 1 Mild_Cocaine 335 Sadness: 73 Death: 31\n",
            "Timesteps: 839522 Ep_Number: 882 Reward: -303.47 Cocaine: 0 Mild_Cocaine 527 Sadness: 457 Death: 16\n",
            "Timesteps: 840522 Ep_Number: 883 Reward: -401.10 Cocaine: 0 Mild_Cocaine 450 Sadness: 476 Death: 74\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -379.161000\n",
            "---------------------------------------\n",
            "Timesteps: 841522 Ep_Number: 884 Reward: -329.24 Cocaine: 0 Mild_Cocaine 494 Sadness: 483 Death: 23\n",
            "Timesteps: 842522 Ep_Number: 885 Reward: -659.60 Cocaine: 0 Mild_Cocaine 320 Sadness: 404 Death: 276\n",
            "Timesteps: 843241 Ep_Number: 886 Reward: -96.16 Cocaine: 1 Mild_Cocaine 576 Sadness: 134 Death: 8\n",
            "Timesteps: 844221 Ep_Number: 887 Reward: -265.61 Cocaine: 1 Mild_Cocaine 751 Sadness: 91 Death: 137\n",
            "Timesteps: 845221 Ep_Number: 888 Reward: -394.50 Cocaine: 0 Mild_Cocaine 510 Sadness: 384 Death: 106\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -395.976000\n",
            "---------------------------------------\n",
            "Timesteps: 846221 Ep_Number: 889 Reward: -604.66 Cocaine: 0 Mild_Cocaine 436 Sadness: 273 Death: 291\n",
            "Timesteps: 847221 Ep_Number: 890 Reward: -268.09 Cocaine: 0 Mild_Cocaine 619 Sadness: 344 Death: 37\n",
            "Timesteps: 847665 Ep_Number: 891 Reward: -139.30 Cocaine: 1 Mild_Cocaine 330 Sadness: 35 Death: 78\n",
            "Timesteps: 848665 Ep_Number: 892 Reward: -399.69 Cocaine: 0 Mild_Cocaine 579 Sadness: 264 Death: 157\n",
            "Timesteps: 849665 Ep_Number: 893 Reward: -477.24 Cocaine: 0 Mild_Cocaine 414 Sadness: 451 Death: 135\n",
            "Timesteps: 850665 Ep_Number: 894 Reward: -329.23 Cocaine: 0 Mild_Cocaine 523 Sadness: 435 Death: 42\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -406.103000\n",
            "---------------------------------------\n",
            "Timesteps: 851665 Ep_Number: 895 Reward: -257.24 Cocaine: 0 Mild_Cocaine 584 Sadness: 414 Death: 2\n",
            "Timesteps: 852137 Ep_Number: 896 Reward: -249.29 Cocaine: 1 Mild_Cocaine 259 Sadness: 77 Death: 135\n",
            "Timesteps: 852811 Ep_Number: 897 Reward: -304.55 Cocaine: 1 Mild_Cocaine 325 Sadness: 243 Death: 105\n",
            "Timesteps: 853427 Ep_Number: 898 Reward: -198.10 Cocaine: 1 Mild_Cocaine 390 Sadness: 157 Death: 68\n",
            "Timesteps: 854427 Ep_Number: 899 Reward: -272.54 Cocaine: 0 Mild_Cocaine 674 Sadness: 248 Death: 78\n",
            "Timesteps: 855226 Ep_Number: 900 Reward: -476.52 Cocaine: 1 Mild_Cocaine 362 Sadness: 199 Death: 237\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -274.478000\n",
            "---------------------------------------\n",
            "Timesteps: 856003 Ep_Number: 901 Reward: -331.45 Cocaine: 1 Mild_Cocaine 465 Sadness: 153 Death: 158\n",
            "Timesteps: 857003 Ep_Number: 902 Reward: -312.86 Cocaine: 0 Mild_Cocaine 566 Sadness: 382 Death: 52\n",
            "Timesteps: 857831 Ep_Number: 903 Reward: -249.83 Cocaine: 1 Mild_Cocaine 643 Sadness: 34 Death: 150\n",
            "Timesteps: 858831 Ep_Number: 904 Reward: -159.37 Cocaine: 0 Mild_Cocaine 817 Sadness: 137 Death: 46\n",
            "Timesteps: 859831 Ep_Number: 905 Reward: -362.68 Cocaine: 0 Mild_Cocaine 538 Sadness: 373 Death: 89\n",
            "Timesteps: 860831 Ep_Number: 906 Reward: -350.34 Cocaine: 0 Mild_Cocaine 504 Sadness: 443 Death: 53\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -368.441000\n",
            "---------------------------------------\n",
            "Timesteps: 861390 Ep_Number: 907 Reward: -85.34 Cocaine: 1 Mild_Cocaine 424 Sadness: 131 Death: 3\n",
            "Timesteps: 861952 Ep_Number: 908 Reward: -217.52 Cocaine: 1 Mild_Cocaine 412 Sadness: 9 Death: 140\n",
            "Timesteps: 862952 Ep_Number: 909 Reward: -762.64 Cocaine: 0 Mild_Cocaine 394 Sadness: 167 Death: 439\n",
            "Timesteps: 863952 Ep_Number: 910 Reward: -384.37 Cocaine: 0 Mild_Cocaine 547 Sadness: 334 Death: 119\n",
            "Timesteps: 864952 Ep_Number: 911 Reward: -213.18 Cocaine: 0 Mild_Cocaine 828 Sadness: 59 Death: 113\n",
            "Timesteps: 865840 Ep_Number: 912 Reward: -472.04 Cocaine: 1 Mild_Cocaine 454 Sadness: 200 Death: 233\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -343.780000\n",
            "---------------------------------------\n",
            "Timesteps: 866840 Ep_Number: 913 Reward: -682.07 Cocaine: 0 Mild_Cocaine 407 Sadness: 235 Death: 358\n",
            "Timesteps: 867840 Ep_Number: 914 Reward: -542.93 Cocaine: 0 Mild_Cocaine 443 Sadness: 330 Death: 227\n",
            "Timesteps: 868661 Ep_Number: 915 Reward: -214.68 Cocaine: 1 Mild_Cocaine 668 Sadness: 20 Death: 132\n",
            "Timesteps: 868841 Ep_Number: 916 Reward: -61.57 Cocaine: 1 Mild_Cocaine 117 Sadness: 34 Death: 28\n",
            "Timesteps: 869841 Ep_Number: 917 Reward: -277.12 Cocaine: 0 Mild_Cocaine 712 Sadness: 180 Death: 108\n",
            "Timesteps: 870841 Ep_Number: 918 Reward: -301.22 Cocaine: 0 Mild_Cocaine 572 Sadness: 385 Death: 43\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -401.390000\n",
            "---------------------------------------\n",
            "Timesteps: 871841 Ep_Number: 919 Reward: -203.38 Cocaine: 0 Mild_Cocaine 718 Sadness: 252 Death: 30\n",
            "Timesteps: 872841 Ep_Number: 920 Reward: -583.59 Cocaine: 0 Mild_Cocaine 339 Sadness: 457 Death: 204\n",
            "Timesteps: 873490 Ep_Number: 921 Reward: -171.03 Cocaine: 1 Mild_Cocaine 503 Sadness: 55 Death: 90\n",
            "Timesteps: 874490 Ep_Number: 922 Reward: -241.06 Cocaine: 0 Mild_Cocaine 616 Sadness: 379 Death: 5\n",
            "Timesteps: 875490 Ep_Number: 923 Reward: -441.48 Cocaine: 0 Mild_Cocaine 438 Sadness: 451 Death: 111\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -449.115000\n",
            "---------------------------------------\n",
            "Timesteps: 876197 Ep_Number: 924 Reward: -124.89 Cocaine: 1 Mild_Cocaine 599 Sadness: 44 Death: 63\n",
            "Timesteps: 876799 Ep_Number: 925 Reward: -124.21 Cocaine: 1 Mild_Cocaine 411 Sadness: 181 Death: 9\n",
            "Timesteps: 877799 Ep_Number: 926 Reward: -1161.65 Cocaine: 0 Mild_Cocaine 215 Sadness: 20 Death: 765\n",
            "Timesteps: 878799 Ep_Number: 927 Reward: -210.60 Cocaine: 0 Mild_Cocaine 660 Sadness: 340 Death: 0\n",
            "Timesteps: 879799 Ep_Number: 928 Reward: -260.89 Cocaine: 0 Mild_Cocaine 619 Sadness: 352 Death: 29\n",
            "Timesteps: 880434 Ep_Number: 929 Reward: -307.04 Cocaine: 1 Mild_Cocaine 394 Sadness: 61 Death: 179\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -416.027000\n",
            "---------------------------------------\n",
            "Timesteps: 881434 Ep_Number: 930 Reward: -313.32 Cocaine: 0 Mild_Cocaine 582 Sadness: 355 Death: 63\n",
            "Timesteps: 882434 Ep_Number: 931 Reward: -438.54 Cocaine: 0 Mild_Cocaine 504 Sadness: 345 Death: 151\n",
            "Timesteps: 883434 Ep_Number: 932 Reward: -231.65 Cocaine: 0 Mild_Cocaine 635 Sadness: 358 Death: 7\n",
            "Timesteps: 884434 Ep_Number: 933 Reward: -326.82 Cocaine: 0 Mild_Cocaine 492 Sadness: 489 Death: 19\n",
            "Timesteps: 885434 Ep_Number: 934 Reward: -271.01 Cocaine: 0 Mild_Cocaine 791 Sadness: 56 Death: 153\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -395.736000\n",
            "---------------------------------------\n",
            "Timesteps: 886247 Ep_Number: 935 Reward: -305.78 Cocaine: 1 Mild_Cocaine 568 Sadness: 71 Death: 173\n",
            "Timesteps: 887247 Ep_Number: 936 Reward: -348.88 Cocaine: 0 Mild_Cocaine 688 Sadness: 140 Death: 172\n",
            "Timesteps: 888247 Ep_Number: 937 Reward: -322.12 Cocaine: 0 Mild_Cocaine 622 Sadness: 279 Death: 99\n",
            "Timesteps: 889247 Ep_Number: 938 Reward: -445.76 Cocaine: 0 Mild_Cocaine 536 Sadness: 284 Death: 180\n",
            "Timesteps: 889596 Ep_Number: 939 Reward: -90.97 Cocaine: 1 Mild_Cocaine 207 Sadness: 134 Death: 7\n",
            "Timesteps: 890596 Ep_Number: 940 Reward: -404.10 Cocaine: 0 Mild_Cocaine 390 Sadness: 572 Death: 38\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -290.772000\n",
            "---------------------------------------\n",
            "Timesteps: 891088 Ep_Number: 941 Reward: -16.01 Cocaine: 1 Mild_Cocaine 481 Sadness: 2 Death: 8\n",
            "Timesteps: 891805 Ep_Number: 942 Reward: -190.02 Cocaine: 1 Mild_Cocaine 482 Sadness: 182 Death: 52\n",
            "Timesteps: 892805 Ep_Number: 943 Reward: -441.32 Cocaine: 0 Mild_Cocaine 542 Sadness: 279 Death: 179\n",
            "Timesteps: 893805 Ep_Number: 944 Reward: -289.81 Cocaine: 0 Mild_Cocaine 541 Sadness: 449 Death: 10\n",
            "Timesteps: 894805 Ep_Number: 945 Reward: -356.28 Cocaine: 0 Mild_Cocaine 468 Sadness: 496 Death: 36\n",
            "Timesteps: 895805 Ep_Number: 946 Reward: -315.57 Cocaine: 0 Mild_Cocaine 537 Sadness: 427 Death: 36\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -537.083000\n",
            "---------------------------------------\n",
            "Timesteps: 896805 Ep_Number: 947 Reward: -314.89 Cocaine: 0 Mild_Cocaine 529 Sadness: 441 Death: 30\n",
            "Timesteps: 897805 Ep_Number: 948 Reward: -616.58 Cocaine: 0 Mild_Cocaine 428 Sadness: 273 Death: 299\n",
            "Timesteps: 898805 Ep_Number: 949 Reward: -318.64 Cocaine: 0 Mild_Cocaine 634 Sadness: 263 Death: 103\n",
            "Timesteps: 899313 Ep_Number: 950 Reward: -118.16 Cocaine: 1 Mild_Cocaine 376 Sadness: 89 Death: 42\n",
            "Timesteps: 900017 Ep_Number: 951 Reward: -179.25 Cocaine: 1 Mild_Cocaine 545 Sadness: 68 Death: 90\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -551.115000\n",
            "---------------------------------------\n",
            "Timesteps: 901017 Ep_Number: 952 Reward: -701.74 Cocaine: 0 Mild_Cocaine 334 Sadness: 334 Death: 332\n",
            "Timesteps: 902017 Ep_Number: 953 Reward: -251.74 Cocaine: 0 Mild_Cocaine 604 Sadness: 387 Death: 9\n",
            "Timesteps: 902344 Ep_Number: 954 Reward: -49.41 Cocaine: 1 Mild_Cocaine 281 Sadness: 21 Death: 24\n",
            "Timesteps: 903160 Ep_Number: 955 Reward: -97.32 Cocaine: 1 Mild_Cocaine 662 Sadness: 152 Death: 1\n",
            "Timesteps: 903934 Ep_Number: 956 Reward: -170.74 Cocaine: 1 Mild_Cocaine 594 Sadness: 113 Death: 66\n",
            "Timesteps: 904715 Ep_Number: 957 Reward: -285.51 Cocaine: 1 Mild_Cocaine 521 Sadness: 118 Death: 141\n",
            "Timesteps: 905715 Ep_Number: 958 Reward: -241.08 Cocaine: 0 Mild_Cocaine 648 Sadness: 326 Death: 26\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -392.984000\n",
            "---------------------------------------\n",
            "Timesteps: 906715 Ep_Number: 959 Reward: -200.22 Cocaine: 0 Mild_Cocaine 702 Sadness: 282 Death: 16\n",
            "Timesteps: 907048 Ep_Number: 960 Reward: -244.07 Cocaine: 1 Mild_Cocaine 157 Sadness: 20 Death: 155\n",
            "Timesteps: 908048 Ep_Number: 961 Reward: -511.35 Cocaine: 0 Mild_Cocaine 495 Sadness: 279 Death: 226\n",
            "Timesteps: 909048 Ep_Number: 962 Reward: -186.40 Cocaine: 0 Mild_Cocaine 820 Sadness: 102 Death: 78\n",
            "Timesteps: 910048 Ep_Number: 963 Reward: -323.87 Cocaine: 0 Mild_Cocaine 497 Sadness: 484 Death: 19\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -265.259000\n",
            "---------------------------------------\n",
            "Timesteps: 911048 Ep_Number: 964 Reward: -126.97 Cocaine: 0 Mild_Cocaine 817 Sadness: 173 Death: 10\n",
            "Timesteps: 911844 Ep_Number: 965 Reward: -184.10 Cocaine: 1 Mild_Cocaine 580 Sadness: 158 Death: 57\n",
            "Timesteps: 912844 Ep_Number: 966 Reward: -477.67 Cocaine: 0 Mild_Cocaine 427 Sadness: 429 Death: 144\n",
            "Timesteps: 913844 Ep_Number: 967 Reward: -206.81 Cocaine: 0 Mild_Cocaine 761 Sadness: 177 Death: 62\n",
            "Timesteps: 914245 Ep_Number: 968 Reward: -101.26 Cocaine: 1 Mild_Cocaine 276 Sadness: 95 Death: 29\n",
            "Timesteps: 915245 Ep_Number: 969 Reward: -657.18 Cocaine: 0 Mild_Cocaine 408 Sadness: 261 Death: 331\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -253.177000\n",
            "---------------------------------------\n",
            "Timesteps: 916245 Ep_Number: 970 Reward: -386.76 Cocaine: 0 Mild_Cocaine 636 Sadness: 184 Death: 180\n",
            "Timesteps: 917245 Ep_Number: 971 Reward: -614.67 Cocaine: 0 Mild_Cocaine 567 Sadness: 45 Death: 388\n",
            "Timesteps: 917723 Ep_Number: 972 Reward: -246.12 Cocaine: 1 Mild_Cocaine 272 Sadness: 69 Death: 136\n",
            "Timesteps: 918723 Ep_Number: 973 Reward: -609.88 Cocaine: 0 Mild_Cocaine 418 Sadness: 297 Death: 285\n",
            "Timesteps: 919723 Ep_Number: 974 Reward: -285.70 Cocaine: 0 Mild_Cocaine 580 Sadness: 389 Death: 31\n",
            "Timesteps: 920723 Ep_Number: 975 Reward: -471.35 Cocaine: 0 Mild_Cocaine 485 Sadness: 340 Death: 175\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -332.275000\n",
            "---------------------------------------\n",
            "Timesteps: 921723 Ep_Number: 976 Reward: -1198.03 Cocaine: 0 Mild_Cocaine 193 Sadness: 16 Death: 791\n",
            "Timesteps: 922322 Ep_Number: 977 Reward: -68.01 Cocaine: 1 Mild_Cocaine 491 Sadness: 106 Death: 1\n",
            "Timesteps: 923322 Ep_Number: 978 Reward: -508.81 Cocaine: 0 Mild_Cocaine 391 Sadness: 454 Death: 155\n",
            "Timesteps: 924035 Ep_Number: 979 Reward: -219.38 Cocaine: 1 Mild_Cocaine 538 Sadness: 50 Death: 124\n",
            "Timesteps: 924257 Ep_Number: 980 Reward: -7.63 Cocaine: 1 Mild_Cocaine 213 Sadness: 5 Death: 3\n",
            "Timesteps: 925257 Ep_Number: 981 Reward: -205.15 Cocaine: 0 Mild_Cocaine 715 Sadness: 255 Death: 30\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -318.298000\n",
            "---------------------------------------\n",
            "Timesteps: 926257 Ep_Number: 982 Reward: -474.51 Cocaine: 0 Mild_Cocaine 501 Sadness: 310 Death: 189\n",
            "Timesteps: 926791 Ep_Number: 983 Reward: -122.60 Cocaine: 1 Mild_Cocaine 430 Sadness: 38 Death: 65\n",
            "Timesteps: 927791 Ep_Number: 984 Reward: -955.52 Cocaine: 0 Mild_Cocaine 212 Sadness: 254 Death: 534\n",
            "Timesteps: 928791 Ep_Number: 985 Reward: -102.80 Cocaine: 0 Mild_Cocaine 890 Sadness: 79 Death: 31\n",
            "Timesteps: 929791 Ep_Number: 986 Reward: -384.30 Cocaine: 0 Mild_Cocaine 480 Sadness: 445 Death: 75\n",
            "Timesteps: 930791 Ep_Number: 987 Reward: -340.40 Cocaine: 0 Mild_Cocaine 530 Sadness: 411 Death: 59\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -291.546000\n",
            "---------------------------------------\n",
            "Timesteps: 931791 Ep_Number: 988 Reward: -398.52 Cocaine: 0 Mild_Cocaine 642 Sadness: 161 Death: 197\n",
            "Timesteps: 932611 Ep_Number: 989 Reward: -456.32 Cocaine: 1 Mild_Cocaine 442 Sadness: 124 Death: 253\n",
            "Timesteps: 932996 Ep_Number: 990 Reward: -25.28 Cocaine: 1 Mild_Cocaine 358 Sadness: 17 Death: 9\n",
            "Timesteps: 933996 Ep_Number: 991 Reward: -272.67 Cocaine: 0 Mild_Cocaine 567 Sadness: 425 Death: 8\n",
            "Timesteps: 934996 Ep_Number: 992 Reward: -456.51 Cocaine: 0 Mild_Cocaine 411 Sadness: 479 Death: 110\n",
            "Timesteps: 935996 Ep_Number: 993 Reward: -433.80 Cocaine: 0 Mild_Cocaine 480 Sadness: 390 Death: 130\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -391.504000\n",
            "---------------------------------------\n",
            "Timesteps: 936668 Ep_Number: 994 Reward: -187.27 Cocaine: 1 Mild_Cocaine 447 Sadness: 168 Death: 56\n",
            "Timesteps: 937668 Ep_Number: 995 Reward: -314.94 Cocaine: 0 Mild_Cocaine 654 Sadness: 234 Death: 112\n",
            "Timesteps: 938668 Ep_Number: 996 Reward: -465.02 Cocaine: 0 Mild_Cocaine 482 Sadness: 352 Death: 166\n",
            "Timesteps: 939154 Ep_Number: 997 Reward: -84.98 Cocaine: 1 Mild_Cocaine 358 Sadness: 119 Death: 8\n",
            "Timesteps: 940154 Ep_Number: 998 Reward: -357.98 Cocaine: 0 Mild_Cocaine 488 Sadness: 461 Death: 51\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -285.073000\n",
            "---------------------------------------\n",
            "Timesteps: 941154 Ep_Number: 999 Reward: -908.02 Cocaine: 0 Mild_Cocaine 262 Sadness: 224 Death: 514\n",
            "Timesteps: 942154 Ep_Number: 1000 Reward: -400.10 Cocaine: 0 Mild_Cocaine 380 Sadness: 593 Death: 27\n",
            "Timesteps: 943154 Ep_Number: 1001 Reward: -1258.89 Cocaine: 0 Mild_Cocaine 99 Sadness: 104 Death: 797\n",
            "Timesteps: 944154 Ep_Number: 1002 Reward: -232.35 Cocaine: 0 Mild_Cocaine 675 Sadness: 291 Death: 34\n",
            "Timesteps: 944900 Ep_Number: 1003 Reward: -158.21 Cocaine: 1 Mild_Cocaine 541 Sadness: 168 Death: 36\n",
            "Timesteps: 945900 Ep_Number: 1004 Reward: -339.33 Cocaine: 0 Mild_Cocaine 573 Sadness: 341 Death: 86\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -216.342000\n",
            "---------------------------------------\n",
            "Timesteps: 946690 Ep_Number: 1005 Reward: -449.78 Cocaine: 1 Mild_Cocaine 418 Sadness: 121 Death: 250\n",
            "Timesteps: 947690 Ep_Number: 1006 Reward: -279.12 Cocaine: 0 Mild_Cocaine 672 Sadness: 244 Death: 84\n",
            "Timesteps: 948417 Ep_Number: 1007 Reward: -120.65 Cocaine: 1 Mild_Cocaine 535 Sadness: 188 Death: 3\n",
            "Timesteps: 949417 Ep_Number: 1008 Reward: -253.26 Cocaine: 0 Mild_Cocaine 696 Sadness: 233 Death: 71\n",
            "Timesteps: 950417 Ep_Number: 1009 Reward: -299.47 Cocaine: 0 Mild_Cocaine 517 Sadness: 478 Death: 5\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -254.160000\n",
            "---------------------------------------\n",
            "Timesteps: 951417 Ep_Number: 1010 Reward: -112.28 Cocaine: 0 Mild_Cocaine 848 Sadness: 138 Death: 14\n",
            "Timesteps: 952417 Ep_Number: 1011 Reward: -326.55 Cocaine: 0 Mild_Cocaine 555 Sadness: 385 Death: 60\n",
            "Timesteps: 953417 Ep_Number: 1012 Reward: -164.38 Cocaine: 0 Mild_Cocaine 868 Sadness: 47 Death: 85\n",
            "Timesteps: 954417 Ep_Number: 1013 Reward: -981.97 Cocaine: 0 Mild_Cocaine 277 Sadness: 117 Death: 606\n",
            "Timesteps: 955417 Ep_Number: 1014 Reward: -746.45 Cocaine: 0 Mild_Cocaine 365 Sadness: 233 Death: 402\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -272.661000\n",
            "---------------------------------------\n",
            "Timesteps: 956417 Ep_Number: 1015 Reward: -248.51 Cocaine: 0 Mild_Cocaine 611 Sadness: 379 Death: 10\n",
            "Timesteps: 957417 Ep_Number: 1016 Reward: -146.49 Cocaine: 0 Mild_Cocaine 819 Sadness: 148 Death: 33\n",
            "Timesteps: 958417 Ep_Number: 1017 Reward: -183.64 Cocaine: 0 Mild_Cocaine 724 Sadness: 264 Death: 12\n",
            "Timesteps: 959417 Ep_Number: 1018 Reward: -286.04 Cocaine: 0 Mild_Cocaine 584 Sadness: 382 Death: 34\n",
            "Timesteps: 960417 Ep_Number: 1019 Reward: -329.00 Cocaine: 0 Mild_Cocaine 560 Sadness: 374 Death: 66\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -604.405000\n",
            "---------------------------------------\n",
            "Timesteps: 961048 Ep_Number: 1020 Reward: -70.81 Cocaine: 1 Mild_Cocaine 531 Sadness: 90 Death: 9\n",
            "Timesteps: 962048 Ep_Number: 1021 Reward: -419.28 Cocaine: 0 Mild_Cocaine 468 Sadness: 426 Death: 106\n",
            "Timesteps: 963048 Ep_Number: 1022 Reward: -1375.81 Cocaine: 0 Mild_Cocaine 61 Sadness: 37 Death: 902\n",
            "Timesteps: 964010 Ep_Number: 1023 Reward: -365.57 Cocaine: 1 Mild_Cocaine 577 Sadness: 238 Death: 146\n",
            "Timesteps: 965010 Ep_Number: 1024 Reward: -319.65 Cocaine: 0 Mild_Cocaine 495 Sadness: 492 Death: 13\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -332.791000\n",
            "---------------------------------------\n",
            "Timesteps: 966010 Ep_Number: 1025 Reward: -287.21 Cocaine: 0 Mild_Cocaine 611 Sadness: 336 Death: 53\n",
            "Timesteps: 966740 Ep_Number: 1026 Reward: -256.52 Cocaine: 1 Mild_Cocaine 532 Sadness: 47 Death: 150\n",
            "Timesteps: 967621 Ep_Number: 1027 Reward: -170.61 Cocaine: 1 Mild_Cocaine 671 Sadness: 164 Death: 45\n",
            "Timesteps: 968430 Ep_Number: 1028 Reward: -74.29 Cocaine: 1 Mild_Cocaine 729 Sadness: 55 Death: 24\n",
            "Timesteps: 969430 Ep_Number: 1029 Reward: -245.87 Cocaine: 0 Mild_Cocaine 617 Sadness: 372 Death: 11\n",
            "Timesteps: 970430 Ep_Number: 1030 Reward: -254.99 Cocaine: 0 Mild_Cocaine 629 Sadness: 342 Death: 29\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -590.673000\n",
            "---------------------------------------\n",
            "Timesteps: 971191 Ep_Number: 1031 Reward: -53.39 Cocaine: 1 Mild_Cocaine 679 Sadness: 81 Death: 0\n",
            "Timesteps: 972011 Ep_Number: 1032 Reward: -411.77 Cocaine: 1 Mild_Cocaine 397 Sadness: 248 Death: 174\n",
            "Timesteps: 972360 Ep_Number: 1033 Reward: -64.11 Cocaine: 1 Mild_Cocaine 251 Sadness: 91 Death: 6\n",
            "Timesteps: 973360 Ep_Number: 1034 Reward: -123.03 Cocaine: 0 Mild_Cocaine 813 Sadness: 184 Death: 3\n",
            "Timesteps: 974138 Ep_Number: 1035 Reward: -321.27 Cocaine: 1 Mild_Cocaine 497 Sadness: 113 Death: 167\n",
            "Timesteps: 975138 Ep_Number: 1036 Reward: -665.45 Cocaine: 0 Mild_Cocaine 455 Sadness: 174 Death: 371\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -247.370000\n",
            "---------------------------------------\n",
            "Timesteps: 976138 Ep_Number: 1037 Reward: -581.73 Cocaine: 0 Mild_Cocaine 333 Sadness: 469 Death: 198\n",
            "Timesteps: 977138 Ep_Number: 1038 Reward: -192.45 Cocaine: 0 Mild_Cocaine 735 Sadness: 236 Death: 29\n",
            "Timesteps: 978138 Ep_Number: 1039 Reward: -1454.59 Cocaine: 0 Mild_Cocaine 19 Sadness: 19 Death: 962\n",
            "Timesteps: 979138 Ep_Number: 1040 Reward: -307.81 Cocaine: 0 Mild_Cocaine 541 Sadness: 429 Death: 30\n",
            "Timesteps: 980138 Ep_Number: 1041 Reward: -213.16 Cocaine: 0 Mild_Cocaine 706 Sadness: 261 Death: 33\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -477.788000\n",
            "---------------------------------------\n",
            "Timesteps: 981138 Ep_Number: 1042 Reward: -307.81 Cocaine: 0 Mild_Cocaine 541 Sadness: 429 Death: 30\n",
            "Timesteps: 982138 Ep_Number: 1043 Reward: -1011.00 Cocaine: 0 Mild_Cocaine 240 Sadness: 146 Death: 614\n",
            "Timesteps: 982857 Ep_Number: 1044 Reward: -183.79 Cocaine: 1 Mild_Cocaine 519 Sadness: 131 Death: 68\n",
            "Timesteps: 983850 Ep_Number: 1045 Reward: -406.11 Cocaine: 1 Mild_Cocaine 671 Sadness: 89 Death: 232\n",
            "Timesteps: 984850 Ep_Number: 1046 Reward: -1356.56 Cocaine: 0 Mild_Cocaine 86 Sadness: 17 Death: 897\n",
            "Timesteps: 985850 Ep_Number: 1047 Reward: -529.66 Cocaine: 0 Mild_Cocaine 586 Sadness: 108 Death: 306\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -595.033000\n",
            "---------------------------------------\n",
            "Timesteps: 986850 Ep_Number: 1048 Reward: -353.96 Cocaine: 0 Mild_Cocaine 626 Sadness: 237 Death: 137\n",
            "Timesteps: 987374 Ep_Number: 1049 Reward: -126.24 Cocaine: 1 Mild_Cocaine 374 Sadness: 110 Death: 39\n",
            "Timesteps: 988374 Ep_Number: 1050 Reward: -369.10 Cocaine: 0 Mild_Cocaine 550 Sadness: 346 Death: 104\n",
            "Timesteps: 989374 Ep_Number: 1051 Reward: -614.09 Cocaine: 0 Mild_Cocaine 449 Sadness: 241 Death: 310\n",
            "Timesteps: 990374 Ep_Number: 1052 Reward: -370.12 Cocaine: 0 Mild_Cocaine 562 Sadness: 325 Death: 113\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -276.577000\n",
            "---------------------------------------\n",
            "Timesteps: 991374 Ep_Number: 1053 Reward: -326.24 Cocaine: 0 Mild_Cocaine 554 Sadness: 387 Death: 59\n",
            "Timesteps: 992374 Ep_Number: 1054 Reward: -1080.11 Cocaine: 0 Mild_Cocaine 161 Sadness: 200 Death: 639\n",
            "Timesteps: 993374 Ep_Number: 1055 Reward: -921.05 Cocaine: 0 Mild_Cocaine 365 Sadness: 39 Death: 596\n",
            "Timesteps: 994374 Ep_Number: 1056 Reward: -1246.81 Cocaine: 0 Mild_Cocaine 121 Sadness: 81 Death: 798\n",
            "Timesteps: 995256 Ep_Number: 1057 Reward: -197.16 Cocaine: 1 Mild_Cocaine 656 Sadness: 161 Death: 64\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -311.798000\n",
            "---------------------------------------\n",
            "Timesteps: 996256 Ep_Number: 1058 Reward: -480.39 Cocaine: 0 Mild_Cocaine 459 Sadness: 373 Death: 168\n",
            "Timesteps: 997256 Ep_Number: 1059 Reward: -257.95 Cocaine: 0 Mild_Cocaine 685 Sadness: 246 Death: 69\n",
            "Timesteps: 998256 Ep_Number: 1060 Reward: -645.03 Cocaine: 0 Mild_Cocaine 363 Sadness: 349 Death: 288\n",
            "Timesteps: 999256 Ep_Number: 1061 Reward: -419.80 Cocaine: 0 Mild_Cocaine 670 Sadness: 91 Death: 239\n",
            "---------------------------------------\n",
            "Average Reward over the Evaluation Step: -423.616000\n",
            "---------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}